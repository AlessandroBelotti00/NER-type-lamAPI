{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b4fc3a-0dce-4366-907b-927dac9615af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: tf-keras in /opt/conda/lib/python3.11/site-packages (2.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /opt/conda/lib/python3.11/site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.24.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.24.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2be3fbb-0e7a-44c2-8807-381e580db097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 14:25:35.163752: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-11 14:25:35.260679: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-11 14:25:35.578441: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 14:25:37.438383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from transformers import pipeline\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ec340f-ef96-4940-9e89-a8be6c17a3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForSequenceClassification: ['model.decoder.version', 'model.encoder.version']\n",
      "- This IS expected if you are initializing TFBartForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "median_lengths = []\n",
    "median_token_counts = []\n",
    "columns = []\n",
    "target = []\n",
    "average_numeric_counts = []\n",
    "\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "\n",
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round1_T2D_f3_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R1_sorted_mentions = json.load(file)\n",
    "\n",
    "R1_cea = [item[0]for item in R1_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b5aa8b-e43e-49c1-9ab2-99df78ebf217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dainik Jagran-Dainik Bhaskar-Aajtak TV-CNN Editions (International)-Dinakaran-Malayala Manorama-Divya Bhaskar-Dinamalar-Huffington Post-foxnews-bbc Hindi-indosiar-Softpedia-Dina Thanthi-CNN-People's Daily (Renmin Ri Bao)-USA Today-Navbharat Times-Sahara Samay english-Punjab Kesari-More Media >>\n",
      "________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/64 [00:12<13:31, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTHERS\n",
      "Donkey Kong Country-F-Zero-SimCity-Super Castlevania IV-Street Fighter II: The World Warrior-Super Probotector: Alien Rebels-Super Mario World-R-Type III: The Third Lightning-Super Ghouls'n Ghosts-The Legend of Zelda: A Link to the Past-The Legend of the Mystical Ninja-ActRaiser-Final Fight-Donkey Kong Country 2: Diddy's Kong Quest-Kirby's Dream Course-Street Fighter II' Turbo: Hyper Fighting-Kirby's Ghost Trap-Breath of Fire II-Vegas Stakes-Mario's Super Picross (900 Wii Points)-Gradius III (900 Wii Points)-Axelay-Super Metroid-Cybernator-Donkey Kong Country 3: Dixie Kong's Double Trouble!-Harvest Moon-Super Street Fighter II: The New Challengers-Super Turrican-Super R-Type-Pac-Attack-Super Mario RPG: Legend of the Seven Stars (900 Wii Points)-DoReMi Fantasy: Milon's DokiDoki Adventure (900 Wii Points)-Space Invaders: The Original Game-Secret of Mana-Super Punch-Out!!-Ogre Battle: The March of the Black Queen (900 Wii Points)-Kirby's Dream Land 3 (900 Wii Points)-Pilotwings-Super Star Wars-Super Star Wars: The Empire Strikes Back-Final Fight 2-Super Star Wars: Return of the Jedi-Zombies-Street Fighter Alpha 2-Final Fight 3-Super Mario Kart-Indiana Jones' Greatest Adventures-Ghoul Patrol-Kirby's Fun Pak-Final Fantasy II (900 Wii Points)-Aero the Acro-Bat-Aero the Acro-Bat 2-Wild Guns-Mystic Quest Legend-Rival Turf!-Super E.D.F.: Earth Defense Force-Super Bonk (900 Wii Points)-Natsume Championship Wrestling (900 Wii Points)-Final Fantasy III (900 Wii Points)-Brawl Brothers-The Ignition Factor (900 Wii Points)-Super Adventure Island-Chrono Trigger (900 Wii Points)-Super Adventure Island II-Prince of Persia\n",
      "________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/64 [00:25<13:03, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG\n",
      "Pink-backed pelican-Little grebe-Great cormorant-Long-tailed cormorant-African darter-African finfoot-Little bittern-Black-crowned night-heron-Cattle egret-Common squacco heron-Madagascar pond-heron-Striated heron-Rufous-bellied heron-Little egret-Intermediate egret-Great egret-Goliath heron-Purple heron-Grey heron-Black-headed heron-Hamerkop-Yellow-billed stork-Wooly-necked stork-African open-billed stork-Saddle-billed stork-Marabou stork-Shoebill-Sacred ibis-Hadada ibis-Glossy ibis-African spoonbill-Egyptian goose-Spur-winged goose-Knob-billed duck-African pygmy-goose-White-faced whistling-duck-Hottentot teal-Yellow-billed duck-Black kite-Black-shouldered kite-African fish-eagle-Palm-nut vulture-Osprey-Hooded vulture-White-headed vulture-African white-backed vulture-Ruppell's griffon vulture-Lappet-faced vulture-Black-chested snake-eagle-Brown snake-eagle-Western banded snake-eagle-African marsh harrier-Eurasian marsh harrier-Eastern chanting-goshawk-Dark chanting-goshawk-Lizard buzzard-Shikra-African goshawk-Great sparrowhawk-Bat hawk-African harrier-hawk-Augur buzzard-Mountain buzzard-Tawny eagle-Wahlberg's eagle-Ayre's hawk-eagle-Bateleur-Long-crested eagle-Martial eagle-African crowned eagle-Common kestrel-Grey kestrel-African hobby-Eurasian hobby-Lanner falcon-Peregrine falcon-Helmeted guineafowl-Crested guineafowl-[Scaly francolin]-Nahan's francolin-Handsome francolin-Coqui francolin-Heuglin's francolin-Crested francolin-Red-necked spurfowl-Harlequin quail-Blue quail-Common button-quail-White-spotted flufftail-African crake-Black crake-Purple swamphen-Common moorhen-African jacana-Grey crowned crane-Black-bellied bustard-Water thick-knee-Senegal thick-knee-Collared pratincole-Rock pratincole-Spur-winged lapwing-Long-toed lapwing-African wattled lapwing-Crowned lapwing-Black-headed lapwing-Senegal lapwing-Brown-chested lapwing-Kittlitz's plover-Three-banded plover-Common sandpiper-Wood sandpiper-Common greenshank-Grey-headed gull-African skimmer-White-winged tern-African green pigeon-Speckled pigeon-Afep pigeon-Olive pigeon-Feral pigeon-Emerald-spotted wood-dove-Blue-spotted wood-dove-Black-billed wood-dove-Tambourine dove-Namaqua dove-Ring-necked dove-Red-eyed dove-African mourning dove-Vinaceous dove-Laughing dove-Dusky turtle dove-Brown parrot-Grey parrot-Red-headed lovebird-Great blue turaco-Ross's turaco-Rwenzori turaco-White-crested turaco-Black-billed turaco-Bare-faced go-away-bird-Eastern grey plantain-eater-Black-and-white cuckoo-Madagascar lesser cuckoo-Red-chested cuckoo-Black cuckoo-Barred long-tailed cuckoo-Dusky long-tailed cuckoo-Diederik cuckoo-Klaas's cuckoo-African emerald cuckoo-Yellowbill-White-browed coucal-Blue-headed coucal-Senegal coucal-[Black-throated coucal]-African wood-owl-[Barn owl]-African scops-owl-Verreaux's eagle-owl-Spotted eagle-owl-Square-tailed nightjar-Long-tailed nightjar-Swamp nightjar-Rwenzori nightjar-Black-shouldered nightjar-Pennant-winged nightjar-Little swift-White-rumped swift-Horus swift-Mottled swift-Alpine swift-Eurasian swift-Scarce swift-African palm swift-Sabine's spinetail-Cassin's spinetail-Speckled mousebird-Blue-naped mousebird-Narina trogon-Bar-tailed trogon-Pied kingfisher-Striped kingfisher-Grey-headed kingfisher-Giant kingfisher-Woodland kingfisher-Blue-breasted kingfisher-Chocolate-backed kingfisher-Malachite kingfisher-African pygmy-kingfisher-African dwarf-kingfisher-Shining-blue kingfisher-Little bee-eater-Cinnamon-chested bee-eater-Blue-breasted bee-eater-White-throated bee-eater-Swallow-tailed bee-eater-Black bee-eater-Madagascar bee-eater-Red-throated bee-eater-Northern carmine bee-eater-Broad-billed roller-Blue-throated roller-Lilac-breasted roller-Green wood-hoopoe-Forest wood-hoopoe-Black scimitarbill-African grey hornbill-Crowned hornbill-African pied hornbill-Piping hornbill-Red-billed dwarf hornbill-White-crested hornbill-Black-and-white casqued hornbill-White-thighed hornbill-Black-casqued wattled hornbill-Abyssinian ground-hornbill-Yellow-rumped tinkerbird-Yellow-throated tinkerbird-Red-rumped tinkerbird-Western green tinkerbird-Speckled tinkerbird-Grey-throated barbet-Yellow-fronted tinkerbird-Spot-flanked barbet-Hairy-breasted barbet-Yellow-spotted barbet-White-headed barbet-Black-billed barbet-Red-faced barbet-Double-toothed barbet-Yellow-billed barbet-Greater honeyguide-Lesser honeyguide-Willcock's honeyguide-Least honeyguide-Tullberg's woodpecker-Buff-spotted woodpecker-Brown-eared woodpecker-Nubian woodpecker-Green-backed woodpecker-Cardinal woodpecker-Elliott's woodpecker-Speckle-breasted woodpecker-Yellow-crested woodpecker-Grey woodpecker-Olive woodpecker-African broadbill-Rufous-sided broadbill-[African green broadbill]-Rufous-naped lark-Flappet lark-Red-capped lark-Rock martin-Plain martin-Banded martin-Mosque swallow-Rufous-chested swallow-Lesser striped swallow-Barn swallow-Angola swallow-Wire-tailed swallow-Black saw-wing-White-headed saw-wing-African pied wagtail-Cape wagtail-Yellow-throated longclaw-Grassland pipit-Plain-backed pipit-Black cuckoo-shrike-Red-shouldered cuckoo-shrike-Purple-throated cuckoo-shrike-Petit's cuckoo-shrike-Grey cuckoo-shrike-Western nicator-[Yellow-throated nicator]-Common bulbul-Yellow-whiskered greenbul-Little greenbul-Mountain greenbul-Slender-billed greenbul-Shelley's greenbul-Yellow-streaked greenbul-Cabanis's greenbul-Ansorge's greenbul-Little grey greenbul-Toro olive greenbul-Cameroon sombre greenbul-Icterine greenbul-Xavier's greenbul-Joyful greenbul-Red-tailed bristlebill-[Green-tailed bristlebill]-Red-tailed greenbul-White-throated greenbul-Yellow-throated greenbul-Swamp palm bulbul-Honeyguide greenbul-Spotted greenbul-White-starred robin-Equatorial akalat-Forest robin-Brown-chested alethe-Red-throated alethe-Fire-crested alethe-Cape robin-chat-White-browed robin-chat-Blue-shouldered robin-chat-Snowy-headed robin-chat-Red-capped robin-chat-Archer's robin-White-bellied robin-chat-Olive thrush-African thrush-Kivu ground-thrush-White-tailed ant-thrush-Red-tailed ant-thrush-Rufous flycatcher-thrush-Sooty chat-African stonechat-White-browed scrub-robin-Brown-backed scrub-robin-Spotted mourning-thrush-Dark-capped yellow warbler-Mountain yellow warbler-Lesser reed warbler-[Greater swamp warbler]-African reed warbler-White-winged warbler-Cinnamon bracken warbler-Little rush warbler-Grauer's rush-warbler-Buff-bellied warbler-Uganda woodland warbler-Red-faced woodland warbler-Green hylia-Short-tailed warbler-White-browed crombec-Green crombec-Lemon-bellied crombec-Yellow longbill-Grey longbill-Northern crombec-Red-faced crombec-Rufous-crowned eromomela-Black-faced rufous warbler-African moustached warbler-Grauer's warbler-Zitting cisticola-Stout cisticola-Croaking cisticola-Rattling cisticola-Winding cisticola-Carruther's cisticola-Singing cisticola-Red-faced cisticola-Chubb's cisticola-Trilling cisticola-Whistling cisticola-Siffling cisticola-Foxy cisticola-Red-winged grey warbler-Tawny-flanked prinia-White-chinned prinia-Banded prinia-Grey-capped warbler-Grey-backed camaroptera-Olive-green camaroptera-Yellow-browed camaroptera-Yellow-breasted apalis-Grey apalis-Chestnut-throated apalis-Buff-throated apalis-Collared apalis-Black-throated apalis-Mountain masked apalis-Black-capped apalis-White-eyed slaty flycatcher-Northern black flycatcher-Yellow-eyed black-flycatcher-Pale flycatcher-Ashy flycatcher-African dusky flycatcher-Lead-coloured flycatcher-Grey-throated flycatcher-Swamp flycatcher-Cassin's grey flycatcher-Dusky-blue flycatcher-Sooty flycatcher-Forest flycatcher-Chin-spot batis-Black-headed batis-Rwenzori batis-African shrike-flycatcher-Black-and-white shrike-flycatcher-Brown-throated wattle-eye-Chestnut wattle-eye-Jameson's wattle-eye-Yellow-bellied wattle-eye-African paradise flycatcher-Red-bellied paradise-flycatcher-Silverbird-White-tailed crested-flycatcher-White-bellied crested-flycatcher-African blue-flycatcher-White-tailed blue-flycatcher-Chestnut-capped flycatcher-Scaly-breasted illadopsis-Mountain illadopsis-Brown illadopsis-Pale-breasted illadopsis-Puvel's illadopsis-African hill-babbler-Arrow-marked babbler-Brown babbler-Black-lored babbler-Dusky tit-White-shouldered tit-Stripe-breasted tit-Yellow-white-eye-Bronze sunbird-Green-headed sunbird-Blue-throated brown sunbird-Blue-headed sunbird-Northern double-collared sunbird-Olive-bellied sunbird-Rwenzori double-collared sunbird-Regal sunbird-Green-throated sunbird-Green sunbird-Olive sunbird-Little green sunbird-Grey-headed sunbird-Copper sunbird-Superb sunbird-Marico sunbird-Purple-banded sunbird-Scarlet-chested sunbird-Beautiful sunbird-Red-chested sunbird-Variable sunbird-Collared sunbird-Common fiscal-Grey-backed fiscal-Mackinnon's fiscal-Tropical boubou-Luedher's bush-shrike-Black-headed gonolek-Papyrus gonolek-Mountain black boubou-Sooty boubou-Northern puffback-Pink-footed puffback-Black-crowned tchagra-Brown-crowned tchagra-Marsh tchagra-Sulphur-breasted bush-shrike-Grey-headed bush-shrike-[Lagden's bush-shrike]-Doherty's bush-shrike-Bocages's bush-shrike-Fork-tailed drongo-Velvet-mantled drongo-Piapiac-Pied crow-White-naped raven-African black-headed oriole-Montane oriole-Western black-headed oriole-African golden oriole-Yellow-billed oxpecker-Stuhlmann's starling-Narrow-tailed starling-Waller's starling-Greater blue-eared starling-Lesser blue-eared starling-Ruppell's long-tailed starling-Purple-headed starling-Violet-backed starling-Sharpe's starling-Wattled starling-Rufous sparrow-Speckle-fronted weaver-Grey-headed sparrow-White-browed sparrow-weaver-Chestnut-crowned sparrow-weaver-Black-headed weaver-Lesser masked weaver-Vitelline weaver-Northern masked weaver-Spectacled weaver-Black-necked weaver-Baglafecht weaver-Grosbeak weaver-Little weaver-Slender-billed weaver-Yellow-backed weaver-Northern brown-throated weaver-Compact weaver-Holub's golden weaver-Weyn's weaver-Strange weaver-Brown-capped weaver-Yellow-mantled weaver-Black-billed weaver-Viellot's black weaver-Red-billed quelea-Cardinal quelea-Red-headed quelea-Red-headed weaver-Red-headed malimbe-Crested malimbe-Blue-billed malimbe-Red-collared widowbird-Fan-tailed widowbird-Black bishop-Yellow bishop-Yellow-mantled widowbird-Red bishop-Northern red bishop-Black-winged red bishop-Grey-headed negro-finch-White-breasted negrofinch-Green-winged pytilia-Red-winged pytilia-Grey-headed oliveback-Brown twinspot-Dusky crimsonwing-Red-headed bluebill-Black-bellied seedcracker-Red-cheeked cordonbleu-Red-billed firefinch-African firefinch-Bar-breasted firefinch-Yellow-bellied waxbill-Common waxbill-Black-rumped waxbill-Fawn-breasted waxbill-Black-crowned waxbill-Black-headed waxbill-Black-faced waxbill-Bronze mannikin-Black-and-white mannikin-Magpie mannikin-Pin-tailed whydah-Village indigobird-Brimstone canary-Yellow-fronted canary-Yellow-crowned canary-Thick-billed seedeater-African citril-White-rumped seedeater-Streaky seedeater-Oriole finch-Cinnamon-breasted rock bunting-African golden-breasted bunting-Brown-rumped bunting-Cabanis's bunting\n",
      "________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tables = \"./data/Dataset/Dataset/Round1_T2D/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    return len(re.findall(r'\\d+', str(s)))\n",
    "\n",
    "mapping = [\"ORG\", \"PER\", \"LOC\", \"OTHERS\"]\n",
    "\n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        column = df[col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_length = column.apply(len).median()\n",
    "        median_lengths.append(median_length)\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_count = column.apply(lambda x: len(x.split())).median()\n",
    "        median_token_counts.append(median_token_count)\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / len(df) if len(df) > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "\n",
    "        # Check for NE flag\n",
    "        NE_flag = column.isin(R1_cea).any()\n",
    "        if NE_flag:\n",
    "            joined_cells = column.str.cat(sep='-')\n",
    "            print(joined_cells)\n",
    "            print(\"________________\")\n",
    "            classifier_output = (classifier(joined_cells, mapping))\n",
    "            \n",
    "            # Get the highest score and its corresponding label\n",
    "            max_score_index = classifier_output['scores'].index(max(classifier_output['scores']))\n",
    "            highest_label = classifier_output['labels'][max_score_index]\n",
    "            \n",
    "            print(highest_label)\n",
    "            break\n",
    "            \n",
    "            doc = nlp(joined_cells)\n",
    "            entities = {key: [] for key in mapping.keys()}\n",
    "\n",
    "            # Extract entities and classify them\n",
    "            for ent in doc.ents:\n",
    "                for key, values in mapping.items():\n",
    "                    if ent.label_ in values:\n",
    "                        entities[key].append(ent.text)\n",
    "                        break\n",
    "            \n",
    "            # Find the key of the longest entities list\n",
    "            longest_key = max(entities, key=lambda k: len(entities[k]))\n",
    "            print(f\"{joined_cells} --> The key of the longest list is '{longest_key}'\")\n",
    "                    \n",
    "            target.append(\"NE\")\n",
    "        elif median_length - average_numeric_count < 2:\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns.extend(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc0c11-e811-4540-9a74-c29dd551b55f",
   "metadata": {},
   "source": [
    "## Round1_T2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dfe186-559d-4a4b-a568-eacafc41f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round1_T2D_f3_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R1_sorted_mentions = json.load(file)\n",
    "\n",
    "R1_cea = [item[0]for item in R1_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866bea9-b680-4c47-b179-93f270b6bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"Place\",\n",
    "    \"PopulatedPlace\",\n",
    "    \"City\",\n",
    "    \"Country\",\n",
    "    \"Region\",\n",
    "    \"Mountain\",\n",
    "    \"Island\",\n",
    "    \"Lake\",\n",
    "    \"River\",\n",
    "    \"Park\",\n",
    "    \"Building\",\n",
    "    \"HistoricPlace\",\n",
    "    \"Monument\",\n",
    "    \"Bridge\",\n",
    "    \"Road\",\n",
    "    \"Airport\",\n",
    "    \"Person\",\n",
    "    \"Artist\",\n",
    "    \"Athlete\",\n",
    "    \"Politician\",\n",
    "    \"Scientist\",\n",
    "    \"Writer\",\n",
    "    \"Actor\",\n",
    "    \"Musician\",\n",
    "    \"MilitaryPerson\",\n",
    "    \"Religious\",\n",
    "    \"Royalty\",\n",
    "    \"Criminal\",\n",
    "    \"Organisation\",\n",
    "    \"Company\",\n",
    "    \"EducationalInstitution\",\n",
    "    \"PoliticalParty\",\n",
    "    \"SportsTeam\",\n",
    "    \"Non-ProfitOrganisation\",\n",
    "    \"GovernmentAgency\",\n",
    "    \"ReligiousOrganisation\",\n",
    "    \"Band\",\n",
    "    \"Library\",\n",
    "    \"Museum\",\n",
    "    \"Hospital\",\n",
    "    \"University\",\n",
    "    \"TradeUnion\"\n",
    "]\n",
    "\n",
    "# Mapping of subtypes to macro classes\n",
    "mapping = {\n",
    "    \"Place\": [\"PopulatedPlace\", \"City\", \"Country\", \"Region\", \"Mountain\", \"Island\", \"Lake\", \"River\", \"Park\", \"Building\", \"HistoricPlace\", \"Monument\", \"Bridge\", \"Road\", \"Airport\"],\n",
    "    \"Person\": [\"Artist\", \"Athlete\", \"Politician\", \"Scientist\", \"Writer\", \"Actor\", \"Musician\", \"MilitaryPerson\", \"Religious\", \"Royalty\", \"Criminal\"],\n",
    "    \"Organisation\": [\"Company\", \"EducationalInstitution\", \"PoliticalParty\", \"SportsTeam\", \"Non-ProfitOrganisation\", \"GovernmentAgency\", \"ReligiousOrganisation\", \"Band\"],\n",
    "    \"Institution\": [\"Library\", \"Museum\", \"Hospital\", \"University\", \"TradeUnion\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab481172-9273-43e5-b4d2-d1011cec6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/Round1_T2D/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    return len(re.findall(r'\\d+', str(s)))\n",
    "\n",
    "median_lengths = []\n",
    "median_token_counts = []\n",
    "average_numeric_counts = []\n",
    "target = []\n",
    "columns = []\n",
    "\n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        column = df[col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_length = column.apply(len).median()\n",
    "        median_lengths.append(median_length)\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_count = column.apply(lambda x: len(x.split())).median()\n",
    "        median_token_counts.append(median_token_count)\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / len(df) if len(df) > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "\n",
    "        \n",
    "        # Check for NE flag\n",
    "        NE_flag = column.isin(R1_cea).any()\n",
    "        if NE_flag:\n",
    "            joined_cells = column.str.cat(sep='-')        \n",
    "            doc = nlp(joined_cells)\n",
    "            entities = {\"ORG\": [], \"PERS\": [], \"LOC\": [], \"OTHERS\": []}\n",
    "\n",
    "            # Extract entities and classify them\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"ORG\":\n",
    "                    entities[\"ORG\"].append(ent.text)\n",
    "                elif ent.label_ == \"PERSON\":\n",
    "                    entities[\"PERS\"].append(ent.text)\n",
    "                elif ent.label_ == \"GPE\" or ent.label_ == \"FAC\":  # GPE (Geopolitical Entity)\n",
    "                    entities[\"LOC\"].append(ent.text)\n",
    "                else:\n",
    "                    entities[\"OTHERS\"].append(ent.text)\n",
    "            \n",
    "            # Find the key of the longest entities list\n",
    "            longest_key = max(entities, key=lambda k: len(entities[k]))\n",
    "            print(f\"{joined_cells} --> The key of the longest list is '{longest_key}'\")\n",
    "                    \n",
    "            target.append(\"NE\")\n",
    "        elif median_length - average_numeric_count < 2:\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns.extend(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408542e-7a90-4b4b-b1a8-74fc2448eed5",
   "metadata": {},
   "source": [
    "## Round3_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da63443-b6a5-4060-b097-e6e4a2fb9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round3_2019_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R3_sorted_mentions = json.load(file)\n",
    "\n",
    "R3_cea = [item[0]for item in R3_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c261e-3ff1-41ca-8cde-34c090d858e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/Round3_2019/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    return len(re.findall(r'\\d+', str(s)))\n",
    "\n",
    "median_lengths = []\n",
    "median_token_counts = []\n",
    "average_numeric_counts = []\n",
    "target = []\n",
    "columns = []\n",
    "\n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        column = df[col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_length = column.apply(len).median()\n",
    "        median_lengths.append(median_length)\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_count = column.apply(lambda x: len(x.split())).median()\n",
    "        median_token_counts.append(median_token_count)\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / len(df) if len(df) > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "        \n",
    "        # Check for NE flag\n",
    "        NE_flag = column.isin(R3_cea).any()\n",
    "        if NE_flag:\n",
    "            target.append(\"NE\")\n",
    "        elif median_length - average_numeric_count < 2:\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns.extend(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673eea67-ad8c-4b23-99ef-c5f2dc86b1cc",
   "metadata": {},
   "source": [
    "## 2T_Round4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c0a1c-045b-4cc6-ac29-d60215b8fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/2T_Round4_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R4_sorted_mentions = json.load(file)\n",
    "\n",
    "R4_2T_cea = [item[0]for item in R4_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf378a-2f88-44c0-a551-843d7dc9bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/2T_Round4/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    return len(re.findall(r'\\d+', str(s)))\n",
    "\n",
    "median_lengths = []\n",
    "median_token_counts = []\n",
    "average_numeric_counts = []\n",
    "target = []\n",
    "columns = []\n",
    "\n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        column = df[col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_length = column.apply(len).median()\n",
    "        median_lengths.append(median_length)\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_count = column.apply(lambda x: len(x.split())).median()\n",
    "        median_token_counts.append(median_token_count)\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / len(df) if len(df) > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "        \n",
    "        # Check for NE flag\n",
    "        NE_flag = column.isin(R4_2T_cea).any()\n",
    "        if NE_flag:\n",
    "            target.append(\"NE\")\n",
    "        elif median_length - average_numeric_count < 2:\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns.extend(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a4ed1-7939-4dfc-9eb4-9c9c0f102ef4",
   "metadata": {},
   "source": [
    "## Round4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208edf55-99eb-4018-a0a7-031dbd192a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round4_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R4_sorted_mentions = json.load(file)\n",
    "\n",
    "R4_cea = [item[0]for item in R4_sorted_mentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b461089-7f54-4ed5-9aef-669855493e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/Round4_2020/tables/\"\n",
    "\n",
    "def count_numbers_in_string(s):\n",
    "    return len(re.findall(r'\\d+', str(s)))\n",
    "\n",
    "median_lengths = []\n",
    "median_token_counts = []\n",
    "average_numeric_counts = []\n",
    "target = []\n",
    "columns = []\n",
    "\n",
    "# Iterate through each table\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        column = df[col].astype(str)\n",
    "        \n",
    "        # Calculate median length for the current column\n",
    "        median_length = column.apply(len).median()\n",
    "        median_lengths.append(median_length)\n",
    "        \n",
    "        # Calculate median token count for the current column\n",
    "        median_token_count = column.apply(lambda x: len(x.split())).median()\n",
    "        median_token_counts.append(median_token_count)\n",
    "        \n",
    "        # Calculate average count of numeric values in the current column\n",
    "        total_numeric_count = column.apply(count_numbers_in_string).sum()\n",
    "        average_numeric_count = total_numeric_count / len(df) if len(df) > 0 else 0\n",
    "        average_numeric_counts.append(average_numeric_count)\n",
    "        \n",
    "        # Check for NE flag\n",
    "        NE_flag = column.isin(R4_cea).any()\n",
    "        if NE_flag:\n",
    "            target.append(\"NE\")\n",
    "        elif median_length - average_numeric_count < 2:\n",
    "            target.append(\"lit\")\n",
    "        else:\n",
    "            target.append(\"None\")\n",
    "    \n",
    "    columns.extend(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af83a2d-7e99-4577-85ec-b297fdf376ad",
   "metadata": {},
   "source": [
    "## DF creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c14bf0-1ea7-4856-90a9-e433c1c807a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "df_def = pd.DataFrame({\n",
    "    'column names': columns,\n",
    "    'median_lengths': median_lengths,\n",
    "    'median_token_counts': median_token_counts,\n",
    "    'average_numeric_counts': average_numeric_counts,\n",
    "    'target': target\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c179f-5eb2-4c54-9d77-4639ddb9f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def.to_csv('./data/NE_lit_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e1e43-0b44-4204-b52a-80be8cce57fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#   READ DIRECTLY THE DATASET HERE\n",
    "###################################\n",
    "\n",
    "df = pd.read_csv('./data/NE_lit_dataset.csv')\n",
    "filtered_df = df[df['target'].isin(['lit', 'NE'])]\n",
    "\n",
    "# Displaying the filtered DataFrame\n",
    "df[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b29d6-834d-47ce-bbf7-eac0d736e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = df['target'].value_counts()\n",
    "\n",
    "# Extract counts for specific values\n",
    "ne_count = target_counts.get(\"NE\", 0)\n",
    "lit_count = target_counts.get(\"lit\", 0)\n",
    "none_count = df.shape[0] - (ne_count+lit_count)\n",
    "\n",
    "print(f\"Count of 'NE': {ne_count}\")\n",
    "print(f\"Count of 'lit': {lit_count}\")\n",
    "print(f\"Count of 'NaN': {none_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b0060-e2de-4d00-a043-56bc1709897d",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2256078-4db3-4a4a-98c0-1e49c19b7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "filtered_df['target'] = label_encoder.fit_transform(filtered_df['target'])\n",
    "\n",
    "# One-hot encode the 'column names' column\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_columns = one_hot_encoder.fit_transform(filtered_df[['column names']])\n",
    "\n",
    "# Combine the encoded categorical data with the numeric data\n",
    "numeric_data = filtered_df[['median_lengths', 'median_token_counts', 'average_numeric_counts']].values\n",
    "X = np.hstack([encoded_columns, numeric_data])\n",
    "y = filtered_df['target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28204b07-3a07-4b09-8748-ec0d4f4eade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "mapped_predictions = [\"lit\" if pred == 1 else \"NE\" for pred in y_pred.ravel()]\n",
    "\n",
    "# Extract the part of X_test that corresponds to the one-hot encoded columns\n",
    "encoded_columns_test = X_test[:, :encoded_columns.shape[1]]\n",
    "\n",
    "# Inverse transform the one-hot encoded columns to get the original categorical labels\n",
    "original_labels = one_hot_encoder.inverse_transform(encoded_columns_test)\n",
    "\n",
    "# Print a few examples to check\n",
    "for i in range(100):\n",
    "    print(f'Original label: {original_labels[i]}, Predicted: {mapped_predictions[i]}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06397d40-ffd2-4fc2-a622-3a3338c45d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
