{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62066ba3-f7de-456f-9526-3e0604538592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95919468-1f01-420a-8aff-2b9500aa2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnAnalysis:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.entity_type_dict = {\n",
    "            \"PERSON\": \"NE\",\n",
    "            \"NORP\": \"NE\",\n",
    "            \"FAC\": \"NE\",\n",
    "            \"ORG\": \"NE\",\n",
    "            \"GPE\": \"NE\",\n",
    "            \"LOC\": \"NE\",\n",
    "            \"PRODUCT\": \"NE\",\n",
    "            \"EVENT\": \"NE\",\n",
    "            \"WORK_OF_ART\": \"NE\",\n",
    "            \"LAW\": \"NE\",\n",
    "            \"LANGUAGE\": \"NE\",\n",
    "            \"DATE\": \"LIT\",\n",
    "            \"TIME\": \"LIT\",\n",
    "            \"PERCENT\": \"LIT\",\n",
    "            \"MONEY\": \"LIT\",\n",
    "            \"QUANTITY\": \"LIT\",\n",
    "            \"ORDINAL\": \"LIT\",\n",
    "            \"CARDINAL\": \"LIT\",\n",
    "            \"URL\": \"LIT\",\n",
    "            \"DESC\": \"LIT\",\n",
    "            \"TOKEN\": \"NE\",\n",
    "            \"INTEGER\": \"LIT\",\n",
    "            \"FLOAT\": \"LIT\",\n",
    "            \"DATETIME\": \"LIT\",\n",
    "            \"ADDRESS\": \"LIT\",\n",
    "            \"EMAIL\": \"LIT\"\n",
    "        }\n",
    "\n",
    "        self.LIT_DATATYPE = {\n",
    "            \"DATE\": \"DATETIME\", \n",
    "            \"TIME\": \"STRING\", \n",
    "            \"PERCENT\": \"STRING\", \n",
    "            \"MONEY\": \"STRING\", \n",
    "            \"QUANTITY\": \"STRING\", \n",
    "            \"ORDINAL\": \"NUMBER\", \n",
    "            \"CARDINAL\": \"NUMBER\", \n",
    "            \"URL\": \"STRING\",\n",
    "            \"DESC\": \"STRING\",\n",
    "            \"TOKEN\": \"STRING\",\n",
    "            \"INTEGER\": \"NUMBER\",\n",
    "            \"FLOAT\": \"NUMBER\",\n",
    "            \"DATETIME\": \"DATETIME\",\n",
    "            \"ADDRESS\": \"STRING\",\n",
    "            \"EMAIL\": \"STRING\",\n",
    "            \"STRING\": \"STRING\"\n",
    "        }\n",
    "\n",
    "        self.NE_DATATYPE = [\"PERSON\", \"NORP\", \"FAC\", \"ORG\", \"GPE\", \"LOC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\", \"LANGUAGE\"]\n",
    "\n",
    "\n",
    "    \n",
    "    def most_frequent_element(self, input_list):\n",
    "        counter = Counter(input_list)\n",
    "        most_common = counter.most_common(1)\n",
    "        return most_common[0][0] if most_common else None\n",
    "\n",
    "    def extract_number_features(self, column):\n",
    "        try:\n",
    "            col = pd.to_numeric(column, errors='coerce')\n",
    "            return {\n",
    "                'min_value': np.min(col),\n",
    "                'max_value': np.max(col),\n",
    "                'mean_value': np.mean(col),\n",
    "                'std_dev': np.std(col),\n",
    "                'unique_count': len(set(col))\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting number features: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def extract_named_entity_features(self, column):\n",
    "        lengths = [len(str(entry)) for entry in column]\n",
    "        features = {\n",
    "            'average_length': np.mean(lengths) if lengths else 0,\n",
    "            'min_length': np.min(lengths) if lengths else 0,\n",
    "            'max_length': np.max(lengths) if lengths else 0,\n",
    "            'all_caps': sum(1 for entry in column if str(entry).isupper()),\n",
    "            'capitalized': sum(1 for entry in column if str(entry).istitle()),\n",
    "            'hyphens': sum(str(entry).count('-') for entry in column),\n",
    "            'periods': sum(str(entry).count('.') for entry in column),\n",
    "            'commas': sum(str(entry).count(',') for entry in column)\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    def extract_string_features(self, column):\n",
    "        lengths = [len(str(entry)) for entry in column]\n",
    "        features = {\n",
    "            'average_length': np.mean(lengths) if lengths else 0,\n",
    "            'min_length': np.min(lengths) if lengths else 0,\n",
    "            'max_length': np.max(lengths) if lengths else 0,\n",
    "            'all_caps': sum(1 for entry in column if str(entry).isupper()),\n",
    "            'capitalized': sum(1 for entry in column if str(entry).istitle()),\n",
    "            'alphabetic_chars': sum(char.isalpha() for entry in column for char in str(entry)),\n",
    "            'digit_chars': sum(char.isdigit() for entry in column for char in str(entry)),\n",
    "            'special_chars': sum(not char.isalnum() for entry in column for char in str(entry))\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    def extract_datetime_features(self, column):\n",
    "        dates = pd.to_datetime(column, errors='coerce')\n",
    "        features = {\n",
    "            'min_date': dates.min(),\n",
    "            'max_date': dates.max(),\n",
    "            'date_range': (dates.max() - dates.min()).days,\n",
    "            'year_counts': dates.dt.year.value_counts().to_dict(),\n",
    "            'month_counts': dates.dt.month.value_counts().to_dict()\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    def classify_columns(self, df):\n",
    "\n",
    "        def combine_scores(j_score, ed_score, w1=0.5, w2=0.5):\n",
    "            return w1 * j_score + w2 * ed_score\n",
    "        \n",
    "        url_pattern = re.compile(r'^(https?|ftp)://[^\\s/$.?#].[^\\s]*$', re.IGNORECASE)\n",
    "        email_pattern = re.compile(r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$', re.IGNORECASE)\n",
    "        address_pattern = re.compile(r'\\d+\\s+\\w+\\s+(?:street|st|avenue|ave|road|rd|boulevard|blvd|lane|ln|drive|dr|court|ct|circle|cir|place|pl)\\.?\\s*\\w*', re.IGNORECASE)\n",
    "        datetime_pattern = re.compile(\n",
    "            r'(?:\\d{4}-\\d{2}-\\d{2})'  # YYYY-MM-DD format\n",
    "            r'|(?:31(?:\\/|-|\\.)0?[13578]|1[02](?:\\/|-|\\.)\\d{4})'  # 31 days months\n",
    "            r'|(?:29|30(?:\\/|-|\\.)0?[1,3-9]|1[0-2](?:\\/|-|\\.)\\d{4})'  # 29/30 days months\n",
    "            r'|(?:0?[1-9]|[12]\\d|3[01])(?:\\/|-|\\.)'  # Day\n",
    "            r'(?:0?[1-9]|1[0-2])(?:\\/|-|\\.)\\d{4}'  # Month\n",
    "            r'|(?:0?[1-9]|1[0-2])/(?:0?[1-9]|[12]\\d|3[01])/(?:\\d{2})'  # MM/DD/YY format\n",
    "            r'|(?:0?[1-9]|1[0-2])/(?:0?[1-9]|[12]\\d|3[01])/\\d{2}'  # MM/DD/YY format\n",
    "            r'\\b\\d{2}/(?:0?[1-9]|[12]\\d|3[01])/(?:0?[1-9]|1[0-2])\\b'  # YY/DD/MM format\n",
    "            r'|(?:[01]?\\d|2[0-3]):[0-5]\\d\\.[0-5]\\d'  # HH:MM.SS format\n",
    "            r'|(?:[01]?\\d|2[0-3]):[0-5]\\d'  # HH:MM format\n",
    "            r'|(?:[0-5]?\\d):[0-5]\\d(?:\\.\\d{1,2})?'  # H:MM or H:MM.S format\n",
    "            r'|(?:2[0-3]|[01]?\\d)h[0-5]?\\d(?:m[0-5]?\\d(?:\\.\\d{1,2})?s)?',  # HhMMmSSs format\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "\n",
    "        col_type = []\n",
    "        feature_list = []\n",
    "        \n",
    "        for col_name, col_data in df.items():\n",
    "            type = []\n",
    "            count_cell = 0\n",
    "            \n",
    "            \n",
    "            for cell in col_data:\n",
    "                label = None\n",
    "                is_number = False\n",
    "\n",
    "                try:\n",
    "                    if math.isnan(cell):\n",
    "                        label = \"None\"\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                if isinstance(cell, str):\n",
    "                    if cell == \"NaN\" or cell == \"nan\":\n",
    "                        label = \"None\"\n",
    "                    elif re.match(url_pattern, cell):\n",
    "                        label = \"URL\"\n",
    "                    elif re.match(email_pattern, cell):\n",
    "                        label = \"EMAIL\"\n",
    "                    elif re.match(address_pattern, cell):\n",
    "                        label = \"ADDRESS\"\n",
    "                    elif re.match(datetime_pattern, cell):\n",
    "                        label = \"DATETIME\"\n",
    "                \n",
    "                if label is None:\n",
    "                    print(\"math.isnan(cell):\")\n",
    "                    try:\n",
    "                        cell_str = str(cell)\n",
    "                        if ',' in cell_str or '.' in cell_str or '%' in cell_str or '$' in cell_str:\n",
    "                            cell_str = cell_str.replace('.', '').replace(',', '').replace('%', '').replace('$', '')\n",
    "                        if len(cell_str) - len(re.findall(r'\\d', cell_str)) < 5 and len(re.findall(r'\\d', cell_str)) != 0:\n",
    "                            is_number = True\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                if is_number:\n",
    "                    label = \"NUMBER\"\n",
    "                elif label != \"None\" and len(cell.split(\" \")) >= 15:\n",
    "                    label = \"NOA\"\n",
    "                elif label != \"None\" and len(cell.split(\" \")) >= 1 and len(cell) <= 4:\n",
    "                    label = \"STRING\"\n",
    "                \n",
    "                if label is not None:\n",
    "                    type.append(label)\n",
    "                    break\n",
    "                else:\n",
    "                    if count_cell > 5:\n",
    "                        type.append(None)\n",
    "                        break\n",
    "                    else:\n",
    "                        count_cell += 1\n",
    "                        # do the lookup\n",
    "                        url = 'https://lamapi.hel.sintef.cloud/lookup/entity-retrieval'\n",
    "                        params = {\n",
    "                            'name': cell,\n",
    "                            'token': 'lamapi_demo_2023',\n",
    "                            'kg': 'wikidata',\n",
    "                            'limit': 10,\n",
    "                            'query': f'{{\"query\": {{\"bool\": {{\"must\": [{{\"match\": {{\"name\": {{\"query\": \"{cell}\", \"boost\": 2.0}}}}}}]}}}}}}',\n",
    "                            'sort': [\n",
    "                                f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "                            ]\n",
    "                        }\n",
    "    \n",
    "                        response = requests.get(url, params=params)\n",
    "                        if response.status_code == 200:\n",
    "                            data = response.json()\n",
    "                            if len(data) > 0 and data[0]['NERtype'] != None:\n",
    "                                # assign the NERtype only if the weighted mean (on 50%) of the two scores is higher than 0.7\n",
    "                                \n",
    "                                if combine_scores(data[0]['jaccard_score'], data[0]['ed_score']) >= 0.7:\n",
    "                                    #print(f\"{cell} --> NE_{data[0]['NERtype']}, jaccard_score: {data[0]['jaccard_score']}, ed_score: {data[0]['ed_score']}\")\n",
    "                                    type.append(f\"NE_{data[0]['NERtype']}\")\n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                #print(f\"{cell} --> NE_{data[0]['NERtype']}\")\n",
    "                                #type.append(f\"NE_{data[0]['NERtype']}\")\n",
    "                                \n",
    "                            else:\n",
    "                                type.append(\"STRING\")\n",
    "\n",
    "          \n",
    "            most_common_type = self.most_frequent_element(type)\n",
    "            col_type.append(most_common_type)\n",
    "            \n",
    "            if most_common_type == \"NUMBER\":\n",
    "                features = self.extract_number_features(col_data)\n",
    "            elif most_common_type in ['NE_PERS', 'NE_LOC', 'NE_ORG', 'NE_OTHERS']:\n",
    "                features = self.extract_named_entity_features(col_data)\n",
    "            elif most_common_type == \"STRING\":\n",
    "                features = self.extract_string_features(col_data)\n",
    "            elif most_common_type == \"DATETIME\":\n",
    "                features = self.extract_datetime_features(col_data)\n",
    "            else:\n",
    "                features = {}\n",
    "\n",
    "            features['column_name'] = col_name\n",
    "            features['column_type'] = most_common_type\n",
    "            feature_list.append(features)\n",
    "\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
