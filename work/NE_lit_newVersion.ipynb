{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62066ba3-f7de-456f-9526-3e0604538592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import requests\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82770b3a-6e3d-40f0-9680-bf905ab6d143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdslim/bert-base-NER\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForTokenClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdslim/bert-base-NER\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95919468-1f01-420a-8aff-2b9500aa2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnAnalysis:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.entity_type_dict = {\n",
    "            \"PERSON\": \"NE\",\n",
    "            \"NORP\": \"NE\",\n",
    "            \"FAC\": \"NE\",\n",
    "            \"ORG\": \"NE\",\n",
    "            \"GPE\": \"NE\",\n",
    "            \"LOC\": \"NE\",\n",
    "            \"PRODUCT\": \"NE\",\n",
    "            \"EVENT\": \"NE\",\n",
    "            \"WORK_OF_ART\": \"NE\",\n",
    "            \"LAW\": \"NE\",\n",
    "            \"LANGUAGE\": \"NE\",\n",
    "            \"DATE\": \"LIT\",\n",
    "            \"TIME\": \"LIT\",\n",
    "            \"PERCENT\": \"LIT\",\n",
    "            \"MONEY\": \"LIT\",\n",
    "            \"QUANTITY\": \"LIT\",\n",
    "            \"ORDINAL\": \"LIT\",\n",
    "            \"CARDINAL\": \"LIT\",\n",
    "            \"URL\": \"LIT\",\n",
    "            \"DESC\": \"LIT\",\n",
    "            \"TOKEN\": \"NE\",\n",
    "            \"INTEGER\": \"LIT\",\n",
    "            \"FLOAT\": \"LIT\",\n",
    "            \"DATETIME\": \"LIT\",\n",
    "            \"ADDRESS\": \"LIT\",\n",
    "            \"EMAIL\": \"LIT\"\n",
    "        }\n",
    "\n",
    "        self.LIT_DATATYPE = {\n",
    "            \"DATE\": \"DATETIME\", \n",
    "            \"TIME\": \"STRING\", \n",
    "            \"PERCENT\": \"STRING\", \n",
    "            \"MONEY\": \"STRING\", \n",
    "            \"QUANTITY\": \"STRING\", \n",
    "            \"ORDINAL\": \"NUMBER\", \n",
    "            \"CARDINAL\": \"NUMBER\", \n",
    "            \"URL\": \"STRING\",\n",
    "            \"DESC\": \"STRING\",\n",
    "            \"TOKEN\": \"STRING\",\n",
    "            \"INTEGER\": \"NUMBER\",\n",
    "            \"FLOAT\": \"NUMBER\",\n",
    "            \"DATETIME\": \"DATETIME\",\n",
    "            \"ADDRESS\": \"STRING\",\n",
    "            \"EMAIL\": \"STRING\",\n",
    "            \"STRING\": \"STRING\"\n",
    "        }\n",
    "\n",
    "        self.NE_DATATYPE = [\"PERSON\", \"NORP\", \"FAC\", \"ORG\", \"GPE\", \"LOC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\", \"LANGUAGE\"]\n",
    "\n",
    "    def most_frequent_element(self, input_list):\n",
    "        counter = Counter(input_list)\n",
    "        most_common = counter.most_common(1)\n",
    "        return most_common[0][0] if most_common else None\n",
    "\n",
    "    \n",
    "    def classify_columns(self, df):\n",
    "\n",
    "        def combine_scores(j_score, ed_score, w1=0.5, w2=0.5):\n",
    "            return w1 * j_score + w2 * ed_score\n",
    "        \n",
    "        url_pattern = re.compile(r'^(https?|ftp)://[^\\s/$.?#].[^\\s]*$', re.IGNORECASE)\n",
    "        email_pattern = re.compile(r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$', re.IGNORECASE)\n",
    "        address_pattern = re.compile(r'\\d+\\s+\\w+\\s+(?:street|st|avenue|ave|road|rd|boulevard|blvd|lane|ln|drive|dr|court|ct|circle|cir|place|pl)\\.?\\s*\\w*', re.IGNORECASE)\n",
    "        datetime_pattern = re.compile(\n",
    "            r'(?:\\d{4}-\\d{2}-\\d{2})'  # YYYY-MM-DD format\n",
    "            r'|(?:31(?:\\/|-|\\.)0?[13578]|1[02](?:\\/|-|\\.)\\d{4})'  # 31 days months\n",
    "            r'|(?:29|30(?:\\/|-|\\.)0?[1,3-9]|1[0-2](?:\\/|-|\\.)\\d{4})'  # 29/30 days months\n",
    "            r'|(?:0?[1-9]|[12]\\d|3[01])(?:\\/|-|\\.)'  # Day\n",
    "            r'(?:0?[1-9]|1[0-2])(?:\\/|-|\\.)\\d{4}'  # Month\n",
    "            r'|(?:0?[1-9]|1[0-2])/(?:0?[1-9]|[12]\\d|3[01])/(?:\\d{2})'  # MM/DD/YY format\n",
    "            r'|(?:0?[1-9]|1[0-2])/(?:0?[1-9]|[12]\\d|3[01])/\\d{2}'  # MM/DD/YY format\n",
    "            r'\\b\\d{2}/(?:0?[1-9]|[12]\\d|3[01])/(?:0?[1-9]|1[0-2])\\b'  # YY/DD/MM format\n",
    "            r'|(?:[01]?\\d|2[0-3]):[0-5]\\d\\.[0-5]\\d'  # HH:MM.SS format\n",
    "            r'|(?:[01]?\\d|2[0-3]):[0-5]\\d'  # HH:MM format\n",
    "            r'|(?:[0-5]?\\d):[0-5]\\d(?:\\.\\d{1,2})?'  # H:MM or H:MM.S format\n",
    "            r'|(?:2[0-3]|[01]?\\d)h[0-5]?\\d(?:m[0-5]?\\d(?:\\.\\d{1,2})?s)?',  # HhMMmSSs format\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "\n",
    "        col_type = []\n",
    "        feature_list = []\n",
    "        \n",
    "        for col_name, col_data in df.items():\n",
    "            type = []\n",
    "            count_cell = 0\n",
    "            \n",
    "            \n",
    "            for cell in col_data:\n",
    "                label = None\n",
    "                is_number = False\n",
    "\n",
    "                try:\n",
    "                    if math.isnan(cell):\n",
    "                        label = \"None\"\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                if isinstance(cell, str):\n",
    "                    if cell == \"NaN\" or cell == \"nan\":\n",
    "                        label = \"None\"\n",
    "                    elif re.match(url_pattern, cell):\n",
    "                        label = \"URL\"\n",
    "                    elif re.match(email_pattern, cell):\n",
    "                        label = \"EMAIL\"\n",
    "                    elif re.match(address_pattern, cell):\n",
    "                        label = \"ADDRESS\"\n",
    "                    elif re.match(datetime_pattern, cell):\n",
    "                        label = \"DATETIME\"\n",
    "                \n",
    "                if label is None:\n",
    "                    try:\n",
    "                        cell_str = str(cell)\n",
    "                        if ',' in cell_str or '.' in cell_str or '%' in cell_str or '$' in cell_str:\n",
    "                            cell_str = cell_str.replace('.', '').replace(',', '').replace('%', '').replace('$', '')\n",
    "                        if len(cell_str) - len(re.findall(r'\\d', cell_str)) < 5 and len(re.findall(r'\\d', cell_str)) != 0:\n",
    "                            is_number = True\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                if is_number:\n",
    "                    label = \"NUMBER\"\n",
    "                elif label != \"None\" and len(cell.split(\" \")) >= 15:\n",
    "                    label = \"NOA\"\n",
    "                elif label != \"None\" and len(cell.split(\" \")) >= 1 and len(cell) <= 4:\n",
    "                    label = \"STRING\"\n",
    "                \n",
    "                if label is not None:\n",
    "                    type.append(label)\n",
    "                    break\n",
    "                else:\n",
    "                    if count_cell > 5:\n",
    "                        type.append(None)\n",
    "                        break\n",
    "                    else:\n",
    "                        count_cell += 1\n",
    "\n",
    "                        print(f\"{cell} --> {nlp(cell)}\")\n",
    "                        \n",
    "                        \n",
    "\n",
    "          \n",
    "            most_common_type = self.most_frequent_element(type)\n",
    "            col_type.append(most_common_type)\n",
    "            \n",
    "\n",
    "\n",
    "        return col_type\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58ab00-03ba-4342-85a9-4d3a2d270e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_table(column_analysis, table_path, train_df, columns):\n",
    "    df = pd.read_csv(table_path)\n",
    "    result = await column_analysis.classify_columns(df.iloc[1:10])\n",
    "\n",
    "    for entry in result:\n",
    "        row = {col: [entry.get(col, None)] for col in columns}\n",
    "        train_df = pd.concat([train_df, pd.DataFrame(row)], ignore_index=True)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "async def main(tables_path):\n",
    "    column_analysis = ColumnAnalysis()\n",
    "\n",
    "    columns = [\n",
    "        'column_name', 'column_type', 'min_value', 'max_value', 'mean_value', 'std_dev', 'unique_count', 'special_values',\n",
    "        'average_length', 'min_length', 'max_length', 'all_caps', 'capitalized', 'hyphens', 'periods', 'commas', 'common_prefixes', 'common_suffixes',\n",
    "        'alphabetic_chars', 'digit_chars', 'special_chars', 'min_date', 'max_date', 'date_range', 'year_counts', 'month_counts',\n",
    "        'valid_urls', 'address_count', 'valid_emails'\n",
    "    ]\n",
    "    \n",
    "    train_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    pattern = r'^\\.'\n",
    "\n",
    "    # Create a list of file paths, excluding files that start with a dot\n",
    "    table_files = [os.path.join(tables_path, table) for table in os.listdir(tables_path) if not re.match(pattern, table)]\n",
    "\n",
    "    for table_file in tqdm(table_files):\n",
    "        train_df = await process_table(column_analysis, table_file, train_df, columns)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tables_path = \"./data/Dataset/Dataset/Round1_T2D/tables/\"\n",
    "    #tables_path = \"./data/Dataset/Dataset/HardTablesR2/tables/\"    \n",
    "    #tables_path = \"./data/Dataset/Dataset/Round3_2019/tables/\"\n",
    "    train_df = await (main(tables_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
