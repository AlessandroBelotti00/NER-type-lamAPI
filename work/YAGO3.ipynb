{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0e592d-d6ee-4f23-9ad8-f9de351a6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in /opt/conda/lib/python3.11/site-packages (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from rdflib) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from rdflib) (3.1.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n",
      "Collecting multiprocessing\n",
      "  Downloading multiprocessing-2.6.2.1.tar.gz (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[7 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-z7v2gh21/multiprocessing_6d159aaf0c9b494484c84cd720c4723f/setup.py\", line 94\n",
      "  \u001b[31m   \u001b[0m     print 'Macros:'\n",
      "  \u001b[31m   \u001b[0m     ^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m SyntaxError: Missing parentheses in call to 'print'. Did you mean print(...)?\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install rdflib\n",
    "! pip install multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "506e2b01-54de-454d-a13e-b7c71d4f43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip  # For reading compressed files\n",
    "from rdflib import Graph  # For working with RDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932a2a3b-634d-4f1b-ae58-0121d176f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12502500 lines\n",
      "Processed 25005000 lines\n",
      "Processed 37507500 lines\n",
      "Processed 50010000 lines\n",
      "Processed 62512500 lines\n",
      "Processed 75015000 lines\n",
      "Processed 87517500 lines\n",
      "Processed 100020000 lines\n",
      "Processed 112522500 lines\n",
      "Processed 125025000 lines\n",
      "Processed 137527500 lines\n",
      "Processed 150030000 lines\n",
      "Processed 162532500 lines\n",
      "Processed 175035000 lines\n",
      "Processed 187537500 lines\n",
      "Processed 200040000 lines\n",
      "Processed 212542500 lines\n",
      "Processed 225045000 lines\n",
      "Processed 237547500 lines\n",
      "Processed 250050000 lines\n",
      "Processed 262552500 lines\n",
      "Processed 275055000 lines\n",
      "Processed 287557500 lines\n",
      "Processed 300060000 lines\n",
      "Processed 312562500 lines\n",
      "Processed 325065000 lines\n",
      "Processed 337567500 lines\n",
      "Processed 350070000 lines\n",
      "Processed 362572500 lines\n",
      "Processed 375075000 lines\n",
      "Processed 387577500 lines\n",
      "Processed 400080000 lines\n",
      "Processed 412582500 lines\n",
      "Processed 425085000 lines\n",
      "Processed 437587500 lines\n",
      "Processed 450090000 lines\n",
      "Processed 462592500 lines\n",
      "Processed 475095000 lines\n",
      "Processed 487597500 lines\n",
      "Processed 500100000 lines\n",
      "Processed 512602500 lines\n",
      "Processed 525105000 lines\n",
      "Processed 537607500 lines\n",
      "Processed 550110000 lines\n",
      "Processed 562612500 lines\n",
      "Processed 575115000 lines\n",
      "Processed 587617500 lines\n",
      "Processed 600120000 lines\n",
      "Processed 612622500 lines\n",
      "Processed 625125000 lines\n",
      "Processed 637627500 lines\n",
      "Processed 650130000 lines\n",
      "Processed 662632500 lines\n",
      "Processed 675135000 lines\n",
      "Processed 687637500 lines\n",
      "Processed 700140000 lines\n",
      "Processed 712642500 lines\n",
      "Processed 725145000 lines\n",
      "Processed 737647500 lines\n",
      "Processed 750150000 lines\n",
      "Processed 762652500 lines\n",
      "Processed 775155000 lines\n",
      "Processed 787657500 lines\n",
      "Processed 800160000 lines\n",
      "Processed 812662500 lines\n",
      "Processed 825165000 lines\n",
      "Processed 837667500 lines\n",
      "Processed 850170000 lines\n",
      "Processed 862672500 lines\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;66;03m# Process the remaining lines in the last chunk\u001b[39;00m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m chunk:\n\u001b[0;32m---> 24\u001b[0m                 \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m                 line_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/rdflib/graph.py:1492\u001b[0m, in \u001b[0;36mGraph.parse\u001b[0;34m(self, source, publicID, format, location, file, data, **args)\u001b[0m\n\u001b[1;32m   1489\u001b[0m parser \u001b[38;5;241m=\u001b[39m plugin\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mformat\u001b[39m, Parser)()\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;66;03m# TODO FIXME: Parser.parse should have **kwargs argument.\u001b[39;00m\n\u001b[0;32m-> 1492\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m se:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m could_not_guess_format:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/rdflib/plugins/parsers/ntriples.py:377\u001b[0m, in \u001b[0;36mNTParser.parse\u001b[0;34m(cls, source, sink, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         f \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetreader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)(b)\n\u001b[1;32m    376\u001b[0m parser \u001b[38;5;241m=\u001b[39m W3CNTriplesParser(NTGraphSink(sink))\n\u001b[0;32m--> 377\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/rdflib/plugins/parsers/ntriples.py:196\u001b[0m, in \u001b[0;36mW3CNTriplesParser.parse\u001b[0;34m(self, f, bnode_context)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbnode_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnode_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParseError:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParseError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid line: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/rdflib/plugins/parsers/ntriples.py:249\u001b[0m, in \u001b[0;36mW3CNTriplesParser.parseline\u001b[0;34m(self, bnode_context)\u001b[0m\n\u001b[1;32m    246\u001b[0m predicate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicate()\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meat(r_wspaces)\n\u001b[0;32m--> 249\u001b[0m object_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbnode_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meat(r_tail)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/rdflib/plugins/parsers/ntriples.py:284\u001b[0m, in \u001b[0;36mW3CNTriplesParser.object\u001b[0;34m(self, bnode_context)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobject\u001b[39m(\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m, bnode_context: Optional[_BNodeContextType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    283\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[URI, bNode, Literal]:\n\u001b[0;32m--> 284\u001b[0m     objt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muriref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodeid(bnode_context) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mliteral()\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m objt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParseError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognised object type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/rdflib/plugins/parsers/ntriples.py:294\u001b[0m, in \u001b[0;36mW3CNTriplesParser.uriref\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m     uri \u001b[38;5;241m=\u001b[39m unquote(uri)\n\u001b[1;32m    293\u001b[0m     uri \u001b[38;5;241m=\u001b[39m uriquote(uri)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mURI\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/rdflib/term.py:286\u001b[0m, in \u001b[0;36mURIRef.__new__\u001b[0;34m(cls, value, base)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    284\u001b[0m             value \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_is_valid_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    287\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not look like a valid URI, trying to serialize this will break.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m    290\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/rdflib/term.py:101\u001b[0m, in \u001b[0;36m_is_valid_uri\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_valid_uri\u001b[39m(uri: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m _invalid_uri_chars:\n\u001b[0;32m--> 101\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m uri:\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# IMPLEMENT tqdm BAR !!!!!!!!!!!!\n",
    "##############################################\n",
    "\n",
    "file_path = \"./my-data/yago-wd-full-types.nt.gz\"\n",
    "\n",
    "# Create an RDFlib Graph object to store the parsed RDF data\n",
    "graph = Graph()\n",
    "\n",
    "# Open the compressed NT file and process it in chunks\n",
    "try:\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        line_count = 0\n",
    "        chunk_size = 5000 \n",
    "        chunk = []\n",
    "        for line in f:\n",
    "            line_str = line.decode('utf-8').strip()\n",
    "            chunk.append(line_str)\n",
    "            \n",
    "            if len(chunk) >= chunk_size:\n",
    "                    graph.parse(data='\\n'.join(chunk), format='nt')\n",
    "                    line_count += len(chunk)\n",
    "                    chunk = []  # Reset chunk after processing\n",
    "                    print(f\"Processed {line_count} lines\")\n",
    "            \n",
    "            # Process the remaining lines in the last chunk\n",
    "            if chunk:\n",
    "                graph.parse(data='\\n'.join(chunk), format='nt')\n",
    "                line_count += len(chunk)\n",
    "            \n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_path}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing RDF data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59aa289-9b79-4185-8ece-cf8bdc0c7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_list = [\n",
    "    'Airline', 'Consortium', 'Corporation', 'EducationalOrganization', 'CollegeOrUniversity', 'ElementarySchool', 'HighSchool', \n",
    "    'MiddleSchool', 'Preschool', 'School', 'FundingScheme', 'GovernmentOrganization', 'LibrarySystem',\n",
    "    'AnimalShelter', 'ArchiveOrganization', 'AutoBodyShop', 'AutoDealer', 'AutoPartsStore', 'AutoRental', \n",
    "    'AutoRepair', 'AutoWash', 'GasStation', 'MotorcycleDealer', 'MotorcycleRepair', 'ChildCare', ' MedicalOrganization', 'Dentist', ' LocalBusiness', \n",
    "    'DryCleaningOrLaundry', 'FireStation', 'Hospital', 'PoliceStation', 'EmploymentAgency', 'AdultEntertainment', \n",
    "    'AmusementPark', 'ArtGallery', 'Casino', 'ComedyClub', 'MovieTheater', 'NightClub', 'AccountingService', \n",
    "    'AutomatedTeller', 'BankOrCreditUnion', 'InsuranceAgency', 'Bakery', 'BarOrPub', 'Brewery', 'CafeOrCoffeeShop', \n",
    "    'Distillery', 'FastFoodRestaurant', 'IceCreamShop', 'Restaurant', 'Winery', 'PostOffice', 'BeautySalon', \n",
    "    'DaySpa', 'HairSalon', 'HealthClub', 'NailSalon', 'TattooParlor', 'Electrician', 'GeneralContractor', \n",
    "    'HVACBusiness', 'HousePainter', 'Locksmith', 'MovingCompany', 'Plumber', 'RoofingContractor', 'InternetCafe', \n",
    "    'Attorney', 'Notary', 'Library', 'BedAndBreakfast', 'Campground', 'Hostel', 'Hotel', 'Motel', 'Resort', 'SkiResort',\n",
    "    'VacationRental', 'DiagnosticLab', 'NGO', 'NewsMediaOrganization', 'OnlineStore', 'DanceGroup', 'MusicGroup', \n",
    "    'TheaterGroup', 'PoliticalParty', 'FundingAgency', 'ResearchProject', 'ResearchOrganization', \n",
    "    'SearchRescueOrganization', 'SportsTeam', 'WorkersUnion', 'OnlineBusiness', 'PerformingGroup', 'Project', 'SportsOrganization', \n",
    "    'MedicalBusiness', 'CommunityHealth', 'Dermatology', 'DietNutrition', 'Emergency', 'Geriatric', 'Gynecologic',\n",
    "    'MedicalClinic', 'CovidTestingFacility', 'Midwifery', 'Nursing', 'Obstetric', 'Oncologic', 'Optician', 'Optometric',\n",
    "    'Otolaryngologic', 'Pediatric', 'Pharmacy', 'Physician', 'IndividualPhysician', 'PhysiciansOffice', 'Physiotherapy',\n",
    "    'PlasticSurgery', 'Podiatric', 'PrimaryCare', 'Psychiatric', 'PublicHealth', 'ProfessionalService', 'RadioStation',\n",
    "    'RealEstateAgent', 'RecyclingCenter', 'SelfStorage', 'ShoppingCenter', 'SportsActivityLocation', 'BowlingAlley',\n",
    "    'ExerciseGym', 'GolfCourse', 'PublicSwimmingPool', 'SportsClub', 'StadiumOrArena', 'TennisComplex',\n",
    "    'Store', 'BikeStore', 'BookStore', 'ClothingStore', 'ComputerStore', 'ConvenienceStore', 'DepartmentStore',\n",
    "    'ElectronicsStore', 'Florist', 'FurnitureStore', 'GardenStore', 'GroceryStore', 'HardwareStore', 'HobbyShop',\n",
    "    'HomeGoodsStore', 'JewelryStore', 'LiquorStore', 'MensClothingStore', 'MobilePhoneStore', 'MovieRentalStore',\n",
    "    'MusicStore', 'OfficeEquipmentStore', 'OutletStore', 'PawnShop', 'PetStore', 'ShoeStore', 'SportingGoodsStore',\n",
    "    'TireShop', 'ToyStore', 'WholesaleStore', 'TelevisionStation', 'TouristInformationCenter', 'TravelAgency',\n",
    "    'VeterinaryCare'\n",
    "]\n",
    "\n",
    "\n",
    "person_list = [\n",
    "    'Patient', 'Human'\n",
    "]\n",
    "\n",
    "place_list = [\n",
    "    'Apartment', 'CampingPitch', 'SingleFamilyResidence', 'HotelRoom', 'MeetingRoom', 'Suite', 'City', \n",
    "    'Country', 'SchoolDistrict', 'State', 'Airport', 'Aquarium', 'Beach', 'BoatTerminal', 'Bridge', 'BusStation', \n",
    "    'BusStop', 'Campground', 'Cemetery', 'Crematorium', 'EducationalOrganization', 'EventVenue', 'FireStation', 'CityHall', \n",
    "    'Courthouse', 'DefenceEstablishment', 'Embassy', 'LegislativeBuilding', 'Hospital', 'MovieTheater', 'Museum', 'MusicVenue', 'Park', \n",
    "    'ParkingFacility', 'PerformingArtsTheater', 'PlaceOfWorship', 'BuddhistTemple', 'CatholicChurch', 'HinduTemple', 'Mosque', 'Synagogue', 'Playground', \n",
    "    'PoliceStation', 'PublicToilet', 'RVPark', 'StadiumOrArena', 'SubwayStation', 'TaxiStand', 'TrainStation', 'Zoo', \n",
    "    'Canal', 'LakeBodyOfWater', 'OceanBodyOfWater', 'Pond', 'Reservoir', 'RiverBodyOfWater', 'SeaBodyOfWater', \n",
    "    'Waterfall', 'Continent', 'Mountain', 'Volcano', 'ApartmentComplex', 'GatedResidenceCommunity', 'TouristAttraction', \n",
    "    'TouristDestination', 'Accommodation', 'AdministrativeArea', 'CivicStructure', 'Landform', \n",
    "    'LandmarksOrHistoricalBuildings', 'LocalBusiness', 'Residence'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51144c4a-a093-4648-916e-9ab1ffe27d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG = []\n",
    "LOC = []\n",
    "PERS = []\n",
    "OTHERS = []\n",
    "serialized_data = graph.serialize(format='turtle')\n",
    "serialized_lines = serialized_data.splitlines()\n",
    "\n",
    "for line in serialized_lines[3:]:\n",
    "    #print(line)\n",
    "    parts = line.split(' ')\n",
    "    if len(parts) >= 3:\n",
    "        input_string = parts[2].rsplit('/', 1)[-1]\n",
    "        cleaned_string = input_string.rstrip('> .')\n",
    "        \n",
    "        #print(cleaned_string)\n",
    "        \n",
    "        if cleaned_string in organization_list:\n",
    "            ORG.append(line)\n",
    "            #print(f\"ORG: {line}\")\n",
    "        elif cleaned_string in place_list:\n",
    "            LOC.append(line)\n",
    "            #print(f\"LOC: {line}\")\n",
    "        elif cleaned_string in person_list:\n",
    "            PERS.append(line)\n",
    "            #print(f\"PERS: {line}\")\n",
    "        elif cleaned_string != \"\": \n",
    "            OTHERS.append(line)\n",
    "            #print(f\"OTHERS: {line}\")\n",
    "    #print(parts[1].split(' ')[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6863016f-a6a1-48b2-83e1-1b0d7473ca1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<http://yago-knowledge.org/resource/!_(Trippie_Redd_album)> a <http://yago-knowledge.org/resource/Studio_album> .',\n",
       " '<http://yago-knowledge.org/resource/$100_Room> a <http://schema.org/MusicAlbum> .',\n",
       " '<http://yago-knowledge.org/resource/%22Master_Harold%22...and_the_Boys> a <http://schema.org/Play> .',\n",
       " '<http://yago-knowledge.org/resource/%5Etxt2regex$> a <http://yago-knowledge.org/resource/Free_software> .',\n",
       " '<http://yago-knowledge.org/resource/%60Ambar_Samuch> a <http://yago-knowledge.org/resource/Human_settlement> .',\n",
       " '<http://yago-knowledge.org/resource/%60Amudiyah> a <http://yago-knowledge.org/resource/Human_settlement> .',\n",
       " '<http://yago-knowledge.org/resource/%60Amum> a <http://yago-knowledge.org/resource/Human_settlement> .',\n",
       " \"<http://yago-knowledge.org/resource/'Ajam_of_Kuwait> a <http://yago-knowledge.org/resource/Ethnic_group> .\",\n",
       " \"<http://yago-knowledge.org/resource/'Aliabad> a <http://yago-knowledge.org/resource/Human_settlement> .\",\n",
       " \"<http://yago-knowledge.org/resource/'N'_Dey_Say> a <http://yago-knowledge.org/resource/Single_(music)> .\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OTHERS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe29c153-c22b-4ed4-a9f0-de2bf0aed2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG = 1543\n",
      "LOC = 5588\n",
      "PERS = 31302\n",
      "OTHERS = 52771\n"
     ]
    }
   ],
   "source": [
    "print(f\"ORG = {len(ORG)}\")\n",
    "print(f\"LOC = {len(LOC)}\")\n",
    "print(f\"PERS = {len(PERS)}\")\n",
    "print(f\"OTHERS = {len(OTHERS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302d78f-c9db-4033-b00b-ac121e4615a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming ORG, LOC, PERS, OTHERS are populated lists based on entity classification\n",
    "data = {\n",
    "    \"ORG\": ORG,\n",
    "    \"LOC\": LOC,\n",
    "    \"PERS\": PERS,\n",
    "    \"OTHERS\": OTHERS\n",
    "}\n",
    "\n",
    "# Specify the file path where you want to save the JSON file\n",
    "json_file_path = \"entity_classification.json\"\n",
    "\n",
    "# Write the categorized data to a JSON file\n",
    "try:\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    print(f\"Data saved successfully to {json_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving data to JSON file: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
