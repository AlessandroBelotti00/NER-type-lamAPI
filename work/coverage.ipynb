{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeea9db-4845-49a4-9c53-eb5f82205e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca6421-7158-468a-8db8-7f23670fd1fc",
   "metadata": {},
   "source": [
    "# Round1_T2D_f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ef6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_file = './data/dataset_GT/Round1_T2D_f3.csv'\n",
    "\n",
    "chunk_size = 1000  # Adjust this based on your memory constraints\n",
    "ids = {}\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "total_rows = sum(1 for line in open(GT_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    for chunk_GT in pd.read_csv(GT_file, chunksize=chunk_size):\n",
    "        items = chunk_GT[chunk_GT['target'] == 1]\n",
    "        for _, row in items.iterrows():\n",
    "            if row['target'] == 1:\n",
    "                ids[row[\"key\"]] = {\n",
    "                    \"id\": 'https://www.wikidata.org/entity/' + row['id'],\n",
    "                    \"name\": row['name'],\n",
    "                    \"ed_score\": row['ed_score'],\n",
    "                    \"jaccard_score\": row['jaccard_score']\n",
    "                }\n",
    "        pbar.update(1)  # Update progress bar for each chunk iteration\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc24f3-289d-4e50-a8e0-d2f7385a10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mention in the table\n",
    "tables = \"./data/Dataset/Dataset/Round1_T2D/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/Round1_T2D/gt/CEA_Round1_gt_WD.csv'\n",
    "os.listdir(tables)\n",
    "df = pd.read_csv(cea_file, header=None)\n",
    "df[\"key\"] = df[0] + \" \" + df[1].astype('str') + \" \" + df[2].astype('str')\n",
    "cea_keys = set(df[\"key\"].values)\n",
    "key_to_cell = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {row+1} {col}\"\n",
    "            if key in cea_keys:\n",
    "                cell_value = df.iloc[row, col]\n",
    "                key_to_cell[key] = cell_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019789e6-0ac5-4f77-9b9e-a68d9ccb44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cea_file = './data/Dataset/Dataset/Round1_T2D/gt/CEA_Round1_gt_WD.csv'\n",
    "mentions = {}\n",
    "chunk_size = 1000\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "\n",
    "total_rows = sum(1 for line in open(cea_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "for chunk_cea in tqdm(pd.read_csv(cea_file, chunksize=chunk_size), total=total_iterations):\n",
    "    chunk_cea.columns = column_names\n",
    "    for _, row in chunk_cea.iterrows():\n",
    "        parts = row['url'].split('/')\n",
    "        wikidata_id = parts[-1]\n",
    "        num_rows, num_columns = df.shape\n",
    "        key = f\"{row['table_name']} {row['row']} {row['col']}\"\n",
    "        if key in ids:\n",
    "            cell_value = key_to_cell[key]\n",
    "            data = ids[key]\n",
    "            mentions[cell_value] = data\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821fcd61-91d8-4428-bf63-b4865ed7464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mentions = sorted(mentions.items(), key=lambda x: x[1][\"ed_score\"])\n",
    "\n",
    "json_file_path = \"./data/Round1_T2D_f3_sorted_mentions.json\"\n",
    "\n",
    "# Save the sorted_mentions dictionary to a JSON file\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(sorted_mentions, json_file, indent=4)\n",
    "\n",
    "print(f\"Sorted mentions saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e9063-4b83-49e1-97a6-e82d9ebfae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round1_T2D_f3_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R1_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62327f8-cdfb-4c72-91d8-9a24c82ea65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ed_score and jaccard_score values\n",
    "ed_scores = [item[1]['ed_score'] for item in R1_sorted_mentions]\n",
    "jaccard_scores = [item[1]['jaccard_score'] for item in R1_sorted_mentions]\n",
    "\n",
    "# Convert to a pandas DataFrame for easier analysis\n",
    "df = pd.DataFrame({'ED Score': ed_scores, 'Jaccard Score': jaccard_scores})\n",
    "\n",
    "# Density Plot for ED Score and Jaccard Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for ED Score\n",
    "sns.kdeplot(df['ED Score'], fill=True, label='ED Score')\n",
    "\n",
    "# Plot for Jaccard Score\n",
    "sns.kdeplot(df['Jaccard Score'], fill=True, label='Jaccard Score')\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of ED and Jaccard Scores')\n",
    "plt.legend(loc='upper left')  # Show legend with labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac2be8-a8ef-48ef-846c-68c4df2ebdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bcf5c8-742b-41d8-bc6b-6899751e3c71",
   "metadata": {},
   "source": [
    "## Sample extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eea9d7-8d1b-4f56-9450-a8564fe1edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(R1_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = R1_sorted_mentions[:q1_idx]\n",
    "q2 = R1_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = R1_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = R1_sorted_mentions[q3_idx:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61221ee6-d837-453e-9e51-5240717cf1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = int(len(R1_sorted_mentions)/40)  \n",
    "R1_sample_keys = []\n",
    "R1_sample_keys = R1_sample_keys + random.sample(q1, sample_size)\n",
    "R1_sample_keys = R1_sample_keys + random.sample(q2, sample_size)\n",
    "R1_sample_keys = R1_sample_keys + random.sample(q3, sample_size)\n",
    "R1_sample_keys = R1_sample_keys + random.sample(q4, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb108a-226f-4247-9610-011db4e5184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting ED scores and Jaccard scores\n",
    "ed_scores = [score[1]['ed_score'] for score in R1_sample_keys]\n",
    "jaccard_scores = [score[1]['jaccard_score'] for score in R1_sample_keys]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.kdeplot(ed_scores, color='skyblue', label='Edit Distance Score', fill=True)\n",
    "sns.kdeplot(jaccard_scores, color='salmon', label='Jaccard Score', fill=True)\n",
    "\n",
    "plt.title('Edit Distance and Jaccard Score Density')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e65fe14-c716-462e-b419-55d9475e5555",
   "metadata": {},
   "source": [
    "# Round3_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53dcd1b-493f-4de4-97b1-b57963feecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_file = './data/dataset_GT/Round3_f3.csv'\n",
    "chunk_size = 1000  # Adjust this based on your memory constraints\n",
    "\n",
    "ids = {}\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "total_rows = sum(1 for line in open(GT_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    for chunk_GT in pd.read_csv(GT_file, chunksize=chunk_size):\n",
    "        items = chunk_GT[chunk_GT['target'] == 1]\n",
    "        for _, row in items.iterrows():\n",
    "            if row['target'] == 1:\n",
    "                ids[row[\"key\"]] = {\n",
    "                    \"id\": 'https://www.wikidata.org/entity/' + row['id'],\n",
    "                    \"name\": row['name'],\n",
    "                    \"ed_score\": row['ed_score'],\n",
    "                    \"jaccard_score\": row['jaccard_score']\n",
    "                }\n",
    "        pbar.update(1)  # Update progress bar for each chunk iteration\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e42600-5529-4f4c-82df-aef189b889d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mention in the table\n",
    "tables = \"./data/Dataset/Dataset/Round3_2019/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/Round3_2019/gt/CEA_Round3_gt_WD.csv'\n",
    "os.listdir(tables)\n",
    "df = pd.read_csv(cea_file, header=None)\n",
    "df[\"key\"] = df[0] + \" \" + df[1].astype('str') + \" \" + df[2].astype('str')\n",
    "cea_keys = set(df[\"key\"].values)\n",
    "key_to_cell = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {row+1} {col}\"\n",
    "            if key in cea_keys:\n",
    "                cell_value = df.iloc[row, col]\n",
    "                key_to_cell[key] = cell_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e904f-c7c7-40a7-8660-3c95569810eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cea_file = './data/Dataset/Dataset/Round3_2019/gt/CEA_Round3_gt_WD.csv'\n",
    "mentions = {}\n",
    "chunk_size = 1000\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "\n",
    "total_rows = sum(1 for line in open(cea_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "for chunk_cea in tqdm(pd.read_csv(cea_file, chunksize=chunk_size), total=total_iterations):\n",
    "    chunk_cea.columns = column_names\n",
    "    for _, row in chunk_cea.iterrows():\n",
    "        parts = row['url'].split('/')\n",
    "        wikidata_id = parts[-1]\n",
    "        num_rows, num_columns = df.shape\n",
    "        key = f\"{row['table_name']} {row['row']} {row['col']}\"\n",
    "        if key in ids:\n",
    "            cell_value = key_to_cell[key]\n",
    "            data = ids[key]\n",
    "            mentions[cell_value] = data\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f2b55-1d9e-4594-ad61-12e2320d76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mentions = sorted(mentions.items(), key=lambda x: x[1][\"ed_score\"])\n",
    "\n",
    "json_file_path = \"./data/Round3_2019_sorted_mentions.json\"\n",
    "\n",
    "# Save the sorted_mentions dictionary to a JSON file\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(sorted_mentions, json_file, indent=4)\n",
    "\n",
    "print(f\"Sorted mentions saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a6cc8-4d3b-4fc7-bf7a-7785600e3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round3_2019_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R3_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc843c-3a51-4bc3-a761-bf6cf0406678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ed_score and jaccard_score values\n",
    "ed_scores = [item[1]['ed_score'] for item in R3_sorted_mentions]\n",
    "jaccard_scores = [item[1]['jaccard_score'] for item in R3_sorted_mentions]\n",
    "\n",
    "# Convert to a pandas DataFrame for easier analysis\n",
    "df = pd.DataFrame({'ED Score': ed_scores, 'Jaccard Score': jaccard_scores})\n",
    "\n",
    "# Density Plot for ED Score and Jaccard Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for ED Score\n",
    "sns.kdeplot(df['ED Score'], fill=True, label='ED Score')\n",
    "\n",
    "# Plot for Jaccard Score\n",
    "sns.kdeplot(df['Jaccard Score'], fill=True, label='Jaccard Score')\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of ED and Jaccard Scores')\n",
    "plt.legend(loc='upper left')  # Show legend with labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d50e2-a75d-4464-8d65-07058466d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18abe44c-da17-47b6-8608-0eda5cf4bce3",
   "metadata": {},
   "source": [
    "## Sample extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188f0a1-d65d-407c-995f-9bb659c15cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(R3_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = R3_sorted_mentions[:q1_idx]\n",
    "q2 = R3_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = R3_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = R3_sorted_mentions[q3_idx:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19eb848-5633-4314-831c-0b1687a9bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = int(len(R3_sorted_mentions)/40) \n",
    "R3_sample_keys = []\n",
    "R3_sample_keys = R3_sample_keys + random.sample(q1, sample_size)\n",
    "R3_sample_keys = R3_sample_keys + random.sample(q2, sample_size)\n",
    "R3_sample_keys = R3_sample_keys + random.sample(q3, sample_size)\n",
    "R3_sample_keys = R3_sample_keys + random.sample(q4, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4687287f-cc9f-4e97-99c9-e26f2bbc9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting ED scores and Jaccard scores\n",
    "ed_scores = [score[1]['ed_score'] for score in R3_sample_keys]\n",
    "jaccard_scores = [score[1]['jaccard_score'] for score in R3_sample_keys]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.kdeplot(ed_scores, color='skyblue', label='Edit Distance Score', fill=True)\n",
    "sns.kdeplot(jaccard_scores, color='salmon', label='Jaccard Score', fill=True)\n",
    "\n",
    "plt.title('Edit Distance and Jaccard Score Density')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a53e3-e5fe-46d9-bc52-244e7802b197",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2T_Round4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21682bc5-8812-4cef-b596-0160c59421c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_file = './data/dataset_GT/2T-2020_f3.csv'\n",
    "chunk_size = 1000  # Adjust this based on your memory constraints\n",
    "\n",
    "ids = {}\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "total_rows = sum(1 for line in open(GT_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    for chunk_GT in pd.read_csv(GT_file, chunksize=chunk_size):\n",
    "        items = chunk_GT[chunk_GT['target'] == 1]\n",
    "        for _, row in items.iterrows():\n",
    "            ids[row[\"key\"]] = {\n",
    "                \"id\": 'https://www.wikidata.org/entity/' + row['id'],\n",
    "                \"name\": row['name'],\n",
    "                \"ed_score\": row['ed_score'],\n",
    "                \"jaccard_score\": row['jaccard_score']\n",
    "            }\n",
    "        pbar.update(1)  # Update progress bar for each chunk iteration\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b44b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mention in the table\n",
    "tables = \"./data/Dataset/Dataset/2T_2020/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/2T_2020/gt/cea.csv'\n",
    "os.listdir(tables)\n",
    "df = pd.read_csv(cea_file, header=None)\n",
    "df[\"key\"] = df[0] + \" \" + df[1].astype('str') + \" \" + df[2].astype('str')\n",
    "cea_keys = set(df[\"key\"].values)\n",
    "key_to_cell = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {row+1} {col}\"\n",
    "            if key in cea_keys:\n",
    "                cell_value = df.iloc[row, col]\n",
    "                key_to_cell[key] = cell_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3b254-fd9b-4b32-a799-5c243c8daedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cea_file = './data/Dataset/Dataset/2T_2020/gt/cea.csv'\n",
    "mentions = {}\n",
    "chunk_size = 1000\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "\n",
    "total_rows = sum(1 for line in open(cea_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "for chunk_cea in tqdm(pd.read_csv(cea_file, chunksize=chunk_size), total=total_iterations):\n",
    "    chunk_cea.columns = column_names\n",
    "    for _, row in chunk_cea.iterrows():\n",
    "        parts = row['url'].split('/')\n",
    "        wikidata_id = parts[-1]\n",
    "        num_rows, num_columns = df.shape\n",
    "        key = f\"{row['table_name']} {row['row']} {row['col']}\"\n",
    "        if key in ids:\n",
    "            cell_value = key_to_cell[key]\n",
    "            data = ids[key]\n",
    "            mentions[cell_value] = data\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee2419-0618-4f43-88b4-087bfa1b8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mentions = sorted(mentions.items(), key=lambda x: x[1][\"ed_score\"])\n",
    "\n",
    "json_file_path = \"./data/2T_Round4_sorted_mentions.json\"\n",
    "\n",
    "# Save the sorted_mentions dictionary to a JSON file\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(sorted_mentions, json_file, indent=4)\n",
    "\n",
    "print(f\"Sorted mentions saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bb8b0-9ae2-4774-87f5-4b0b2a3170a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/2T_Round4_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R4_2T_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05332528-eedf-4027-bfda-d5d9e784c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ed_score and jaccard_score values\n",
    "ed_scores = [item[1]['ed_score'] for item in R4_2T_sorted_mentions]\n",
    "jaccard_scores = [item[1]['jaccard_score'] for item in R4_2T_sorted_mentions]\n",
    "\n",
    "# Convert to a pandas DataFrame for easier analysis\n",
    "df = pd.DataFrame({'ED Score': ed_scores, 'Jaccard Score': jaccard_scores})\n",
    "\n",
    "# Density Plot for ED Score and Jaccard Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for ED Score\n",
    "sns.kdeplot(df['ED Score'], fill=True, label='ED Score')\n",
    "\n",
    "# Plot for Jaccard Score\n",
    "sns.kdeplot(df['Jaccard Score'], fill=True, label='Jaccard Score')\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of ED and Jaccard Scores')\n",
    "plt.legend(loc='upper left')  # Show legend with labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb8cf3-f85a-4dc1-a5ce-19455a021584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b681548a-3abe-4812-97d9-3bcee7163222",
   "metadata": {},
   "source": [
    "## Sample extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db422eb9-a3ab-431c-b932-78e92497ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample extraction\n",
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(R4_2T_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = R4_2T_sorted_mentions[:q1_idx]\n",
    "q2 = R4_2T_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = R4_2T_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = R4_2T_sorted_mentions[q3_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119033ab-6741-4ada-8d44-c2925cf6cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = int(len(R4_2T_sorted_mentions)/40) \n",
    "R4_2T_sample_keys = []\n",
    "R4_2T_sample_keys = R4_2T_sample_keys + random.sample(q1, sample_size)\n",
    "R4_2T_sample_keys = R4_2T_sample_keys + random.sample(q2, sample_size)\n",
    "R4_2T_sample_keys = R4_2T_sample_keys + random.sample(q3, sample_size)\n",
    "R4_2T_sample_keys = R4_2T_sample_keys + random.sample(q4, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3cf738-ad6c-43bd-b6e9-967615fa8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting ED scores and Jaccard scores\n",
    "ed_scores = [score[1]['ed_score'] for score in R4_2T_sample_keys]\n",
    "jaccard_scores = [score[1]['jaccard_score'] for score in R4_2T_sample_keys]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.kdeplot(ed_scores, color='skyblue', label='Edit Distance Score', fill=True)\n",
    "sns.kdeplot(jaccard_scores, color='salmon', label='Jaccard Score', fill=True)\n",
    "\n",
    "plt.title('Edit Distance and Jaccard Score Density')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60955944",
   "metadata": {},
   "source": [
    "# Round4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3793c96-1cdd-48fb-aaca-1c84d7ed1b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5302/18384 [01:06<02:43, 79.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tableName                                                    95RMZLI4\n",
      "key                                                      95RMZLI4 9 0\n",
      "id                                                          Q83641013\n",
      "name                                                      imo 9528017\n",
      "types                      [{'id': 'Q15276', 'name': 'bulk carrier'}]\n",
      "ambiguity_mention                                                 0.0\n",
      "corrects_tokens                                                   1.0\n",
      "ntoken_mention                                                      2\n",
      "ntoken_entity                                                       2\n",
      "length_mention                                                     14\n",
      "length_entity                                                      11\n",
      "popularity                                                        0.0\n",
      "pos_score                                                       0.002\n",
      "es_score                                                          1.0\n",
      "ed_score                                                          0.0\n",
      "jaccard_score                                                     0.0\n",
      "jaccardNgram_score                                                0.0\n",
      "cosine_similarity                                                0.25\n",
      "p_subj_ne                                                         0.0\n",
      "p_subj_lit_datatype                                               1.0\n",
      "p_subj_lit_all_datatype                                           1.0\n",
      "p_subj_lit_row                                                    0.4\n",
      "p_obj_ne                                                          0.0\n",
      "desc                                                              0.0\n",
      "descNgram                                                       0.091\n",
      "cta_t1                                                           0.95\n",
      "cta_t2                                                            0.0\n",
      "cta_t3                                                            0.0\n",
      "cta_t4                                                            0.0\n",
      "cta_t5                                                            0.0\n",
      "cpa_t1                                                            1.0\n",
      "cpa_t2                                                          0.592\n",
      "cpa_t3                                                            0.0\n",
      "cpa_t4                                                            0.0\n",
      "cpa_t5                                                            0.0\n",
      "target                                                              1\n",
      "group                                                          284042\n",
      "Name: 5286321, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 16258/18384 [03:27<00:26, 80.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tableName                                                    RDL6Z4OQ\n",
      "key                                                      RDL6Z4OQ 7 0\n",
      "id                                                          Q83641013\n",
      "name                                                      imo 9528017\n",
      "types                      [{'id': 'Q15276', 'name': 'bulk carrier'}]\n",
      "ambiguity_mention                                                 0.0\n",
      "corrects_tokens                                                   1.0\n",
      "ntoken_mention                                                      2\n",
      "ntoken_entity                                                       2\n",
      "length_mention                                                     14\n",
      "length_entity                                                      11\n",
      "popularity                                                        0.0\n",
      "pos_score                                                       0.002\n",
      "es_score                                                          1.0\n",
      "ed_score                                                          0.0\n",
      "jaccard_score                                                     0.0\n",
      "jaccardNgram_score                                                0.0\n",
      "cosine_similarity                                                0.25\n",
      "p_subj_ne                                                         0.0\n",
      "p_subj_lit_datatype                                               1.0\n",
      "p_subj_lit_all_datatype                                           0.0\n",
      "p_subj_lit_row                                                    0.0\n",
      "p_obj_ne                                                          0.0\n",
      "desc                                                              0.0\n",
      "descNgram                                                       0.105\n",
      "cta_t1                                                           0.95\n",
      "cta_t2                                                            0.0\n",
      "cta_t3                                                            0.0\n",
      "cta_t4                                                            0.0\n",
      "cta_t5                                                            0.0\n",
      "cpa_t1                                                            1.0\n",
      "cpa_t2                                                          0.957\n",
      "cpa_t3                                                          0.019\n",
      "cpa_t4                                                          0.003\n",
      "cpa_t5                                                            0.0\n",
      "target                                                              1\n",
      "group                                                          876039\n",
      "Name: 16244903, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18384/18384 [03:55<00:00, 77.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GT_file = './data/dataset_GT/Round4_f3.csv'\n",
    "chunk_size = 1000  # Adjust this based on your memory constraints\n",
    "\n",
    "ids = {}\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "total_rows = sum(1 for line in open(GT_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    for chunk_GT in pd.read_csv(GT_file, chunksize=chunk_size):\n",
    "        items = chunk_GT[chunk_GT['target'] == 1]\n",
    "        for _, row in items.iterrows():\n",
    "            \n",
    "            if row['name'] == \"imo 9528017\":\n",
    "                print(row)\n",
    "                break\n",
    "\n",
    "            \n",
    "            ids[row[\"key\"]] = {\n",
    "                \"id\": 'https://www.wikidata.org/entity/' + row['id'],\n",
    "                \"name\": row['name'],\n",
    "                \"ed_score\": row['ed_score'],\n",
    "                \"jaccard_score\": row['jaccard_score']\n",
    "            }\n",
    "        pbar.update(1)  # Update progress bar for each chunk iteration\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a3d73-a6d9-4537-bf8d-02d55391fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mention in the table\n",
    "tables = \"./data/Dataset/Dataset/Round4_2020/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/Round4_2020/gt/cea.csv'\n",
    "os.listdir(tables)\n",
    "df = pd.read_csv(cea_file, header=None)\n",
    "df[\"key\"] = df[0] + \" \" + df[1].astype('str') + \" \" + df[2].astype('str')\n",
    "cea_keys = set(df[\"key\"].values)\n",
    "key_to_cell = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {row+1} {col}\"\n",
    "            if key in cea_keys:\n",
    "                cell_value = df.iloc[row, col]\n",
    "                key_to_cell[key] = cell_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cd3ec-c29e-48c4-8db9-3090849293f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cea_file = './data/Dataset/Dataset/Round4_2020/gt/cea.csv'\n",
    "mentions = {}\n",
    "chunk_size = 1000\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "\n",
    "total_rows = sum(1 for line in open(cea_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "for chunk_cea in tqdm(pd.read_csv(cea_file, chunksize=chunk_size), total=total_iterations):\n",
    "    chunk_cea.columns = column_names\n",
    "    for _, row in chunk_cea.iterrows():\n",
    "        parts = row['url'].split('/')\n",
    "        wikidata_id = parts[-1]\n",
    "        num_rows, num_columns = df.shape\n",
    "        key = f\"{row['table_name']} {row['row']} {row['col']}\"\n",
    "        if key in ids:\n",
    "            cell_value = key_to_cell[key]\n",
    "            data = ids[key]\n",
    "            mentions[cell_value] = data\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38394dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mentions = sorted(mentions.items(), key=lambda x: x[1][\"ed_score\"])\n",
    "\n",
    "json_file_path = \"./data/Round4_sorted_mentions.json\"\n",
    "\n",
    "# Save the sorted_mentions dictionary to a JSON file\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(sorted_mentions, json_file, indent=4)\n",
    "\n",
    "print(f\"Sorted mentions saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b9e56-0bcc-4cdb-9bb3-a23e505faf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round4_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R4_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998da0eb-bd65-4ce4-bd49-88610ce63963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ed_score and jaccard_score values\n",
    "ed_scores = [item[1]['ed_score'] for item in R4_sorted_mentions]\n",
    "jaccard_scores = [item[1]['jaccard_score'] for item in R4_sorted_mentions]\n",
    "\n",
    "# Convert to a pandas DataFrame for easier analysis\n",
    "df = pd.DataFrame({'ED Score': ed_scores, 'Jaccard Score': jaccard_scores})\n",
    "\n",
    "# Density Plot for ED Score and Jaccard Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for ED Score\n",
    "sns.kdeplot(df['ED Score'], fill=True, label='ED Score')\n",
    "\n",
    "# Plot for Jaccard Score\n",
    "sns.kdeplot(df['Jaccard Score'], fill=True, label='Jaccard Score')\n",
    "\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of ED and Jaccard Scores')\n",
    "plt.legend(loc='upper left')  # Show legend with labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673328d-fba3-48b5-8f8a-b74f67b7f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a6451-1289-489b-937f-a42891bd741a",
   "metadata": {},
   "source": [
    "## Sample extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420df23-d18e-460b-9471-0915d141b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample extraction\n",
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(R4_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = R4_sorted_mentions[:q1_idx]\n",
    "q2 = R4_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = R4_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = R4_sorted_mentions[q3_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab86609-191e-4574-96e5-209b44bf850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = int(len(R4_sorted_mentions)/40) \n",
    "R4_sample_keys = []\n",
    "R4_sample_keys = R4_sample_keys + random.sample(q1, sample_size)\n",
    "R4_sample_keys = R4_sample_keys + random.sample(q2, sample_size)\n",
    "R4_sample_keys = R4_sample_keys + random.sample(q3, sample_size)\n",
    "R4_sample_keys = R4_sample_keys + random.sample(q4, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c115e-6e5b-4300-9b6a-6c7764c5a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting ED scores and Jaccard scores\n",
    "ed_scores = [score[1]['ed_score'] for score in R4_sample_keys]\n",
    "jaccard_scores = [score[1]['jaccard_score'] for score in R4_sample_keys]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.kdeplot(ed_scores, color='skyblue', label='Edit Distance Score', fill=True)\n",
    "sns.kdeplot(jaccard_scores, color='salmon', label='Jaccard Score', fill=True)\n",
    "\n",
    "plt.title('Edit Distance and Jaccard Score Density')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8d5dc-9d79-4445-9fbf-68f30328c8a1",
   "metadata": {},
   "source": [
    "## Datasets Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2ea98-7025-484e-9cb3-d0cd69c20867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scores(data):\n",
    "    return [item[1]['ed_score'] for item in data]\n",
    "\n",
    "ed_scores_R1 = extract_scores(R1_sample_keys)\n",
    "ed_scores_R3 = extract_scores(R3_sample_keys)\n",
    "ed_scores_R4 = extract_scores(R4_sample_keys)\n",
    "ed_scores_R4_2T = extract_scores(R4_2T_sample_keys)\n",
    "\n",
    "# Plot the KDE plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.kdeplot(ed_scores_R1, color='skyblue', label='R1 Edit Distance Score', fill=True)\n",
    "sns.kdeplot(ed_scores_R3, color='green', label='R3 Edit Distance Score', fill=True)\n",
    "sns.kdeplot(ed_scores_R4, color='red', label='R4 Edit Distance Score', fill=True)\n",
    "sns.kdeplot(ed_scores_R4_2T, color='purple', label='R4_2T Edit Distance Score', fill=True)\n",
    "\n",
    "plt.xlabel('Edit Distance Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of Edit Distance Scores for Different Rounds')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
