{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: backoff in /opt/conda/lib/python3.11/site-packages (2.2.1)\n",
      "Collecting SPARQLWrapper\n",
      "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting rdflib>=6.1.1 (from SPARQLWrapper)\n",
      "  Downloading rdflib-7.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=6.1.1->SPARQLWrapper)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.1.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
      "Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: isodate, rdflib, SPARQLWrapper\n",
      "Successfully installed SPARQLWrapper-2.0.0 isodate-0.6.1 rdflib-7.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install backoff\n",
    "! pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import backoff\n",
    "import nest_asyncio\n",
    "import time\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from requests import get\n",
    "import numpy as np\n",
    "import requests\n",
    "from aiohttp import ClientResponseError\n",
    "import logging\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Round1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round1_T2D_f3_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R1_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(R1_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = R1_sorted_mentions[:q1_idx]\n",
    "q2 = R1_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = R1_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = R1_sorted_mentions[q3_idx:]\n",
    "\n",
    "sample_size = 1000\n",
    "R1_sample_keys = []\n",
    "R1_sample_keys = R1_sample_keys + random.sample(q1, sample_size)\n",
    "R1_sample_keys = R1_sample_keys + random.sample(q2, sample_size)\n",
    "R1_sample_keys = R1_sample_keys + random.sample(q3, sample_size)\n",
    "R1_sample_keys = R1_sample_keys + random.sample(q4, sample_size)\n",
    "\n",
    "q_ids = {item[1]['name']: item[1]['id'] for item in R1_sample_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 52.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# find the mention in the table\n",
    "tables = \"./data/Dataset/Dataset/Round1_T2D/tables/\"\n",
    "cta_file = './data/Dataset/Dataset/Round1_T2D/gt/CTA_Round1_gt.csv'\n",
    "os.listdir(tables)\n",
    "\n",
    "mapping = {\n",
    "    \"LOC\": [\n",
    "        \"Place\", \"PopulatedPlace\", \"City\", \"Country\", \"Region\", \"Mountain\", \"Island\", \"Lake\", \"River\",\n",
    "        \"Park\", \"Building\", \"HistoricPlace\", \"Monument\", \"Bridge\", \"Road\", \"Airport\"\n",
    "    ],\n",
    "    \"PERS\": [\n",
    "        \"Person\", \"Artist\", \"Athlete\", \"Politician\", \"Scientist\", \"Writer\", \"Actor\", \"Musician\", \"MilitaryPerson\",\n",
    "        \"Religious\", \"Royalty\", \"Criminal\"\n",
    "    ],\n",
    "    \"ORG\": [\n",
    "        \"Organisation\", \"Company\", \"EducationalInstitution\", \"PoliticalParty\", \"SportsTeam\", \"Non-ProfitOrganisation\",\n",
    "        \"GovernmentAgency\", \"ReligiousOrganisation\", \"Band\", \"Library\", \"Museum\", \"Hospital\", \"University\", \"TradeUnion\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create reverse mapping\n",
    "reverse_mapping = {v: k for k, values in mapping.items() for v in values}\n",
    "\n",
    "# Define function to map df[2] values to their categories\n",
    "def map_class_to_category(class_name):\n",
    "    return reverse_mapping.get(class_name, \"OTHERS\")\n",
    "\n",
    "# Apply the function and create the 'key' column\n",
    "cta_keys = {}\n",
    "df = pd.read_csv(cta_file, header=None)\n",
    "type = df[2].astype(str).str.split('/').str[-1]\n",
    "df[\"category\"] = type.apply(map_class_to_category)\n",
    "cta_keys[\"key\"] = (df[0] + \" \" + df[1].astype('str'), df[\"category\"])\n",
    "\n",
    "key_to_cell = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {col}\"\n",
    "            if key in set(cta_keys[\"key\"][0].values):\n",
    "                tmp_index = cta_keys[\"key\"][0].values.tolist().index(key)\n",
    "                tmp_value = cta_keys[\"key\"][1].iloc[tmp_index]\n",
    "                key_to_cell[key] = tmp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'q_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m chunk_cea\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     17\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_to_cell\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;129;01mand\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[43mq_ids\u001b[49m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     19\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m         data \u001b[38;5;241m=\u001b[39m key_to_cell[key]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q_ids' is not defined"
     ]
    }
   ],
   "source": [
    "cea_file = './data/Dataset/Dataset/Round1_T2D/gt/CEA_Round1_gt_WD.csv'\n",
    "mentions = {}\n",
    "chunk_size = 1000\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "\n",
    "total_rows = sum(1 for line in open(cea_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "count = 0\n",
    "for chunk_cea in tqdm(pd.read_csv(cea_file, chunksize=chunk_size), total=total_iterations):\n",
    "    chunk_cea.columns = column_names\n",
    "    for _, row in chunk_cea.iterrows():\n",
    "        key = f\"{row['table_name']} {row['col']}\"\n",
    "        if key in key_to_cell.keys() and row[\"url\"] in q_ids.values():\n",
    "            count += 1\n",
    "            data = key_to_cell[key]\n",
    "            mentions[get_keys_from_value(q_ids, row[\"url\"])] = (row[\"url\"], data)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3857 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/3857 [00:16<17:25:34, 16.27s/it]\u001b[A\n",
      "  0%|          | 2/3857 [00:16<7:32:31,  7.04s/it] \u001b[A\n",
      "  0%|          | 4/3857 [00:16<2:51:21,  2.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex luger: Q115347 NOT FOUND in OTHERS\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 5/3857 [00:17<2:01:59,  1.90s/it]\u001b[A\n",
      "  0%|          | 6/3857 [00:17<1:28:14,  1.37s/it]\u001b[A\n",
      "  0%|          | 7/3857 [00:17<1:04:00,  1.00it/s]\u001b[A\n",
      "  0%|          | 10/3857 [00:17<29:01,  2.21it/s] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex rodriguez: Q558664 NOT FOUND in OTHERS\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 12/3857 [00:17<22:52,  2.80it/s]\u001b[A\n",
      "  0%|          | 14/3857 [00:18<16:23,  3.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim city: Q249854 NOT FOUND in OTHERS\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 16/3857 [00:18<14:34,  4.39it/s]\u001b[A\n",
      "  0%|          | 19/3857 [00:18<09:50,  6.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randy johnson: Q123682 NOT FOUND in OTHERS\n",
      "___________________________\n",
      "pope linus: Q47144 NOT FOUND in OTHERS\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 21/3857 [00:19<11:20,  5.64it/s]\u001b[A\n",
      "  1%|          | 23/3857 [00:19<09:09,  6.97it/s]\u001b[A\n",
      "  1%|          | 25/3857 [00:19<10:12,  6.26it/s]\u001b[A\n",
      "  1%|          | 27/3857 [00:19<09:48,  6.51it/s]\u001b[A\n",
      "  1%|          | 29/3857 [00:19<08:25,  7.57it/s]\u001b[A\n",
      "  1%|          | 31/3857 [00:20<10:17,  6.19it/s]\u001b[A\n",
      "  1%|          | 32/3857 [00:20<11:32,  5.52it/s]\u001b[A\n",
      "  1%|          | 33/3857 [00:21<15:49,  4.03it/s]\u001b[A\n",
      "  1%|          | 34/3857 [00:22<29:59,  2.12it/s]\u001b[A\n",
      "  1%|          | 36/3857 [00:23<25:25,  2.51it/s]\u001b[A\n",
      "  1%|          | 37/3857 [00:23<25:49,  2.47it/s]\u001b[A\n",
      "  1%|          | 39/3857 [00:23<22:09,  2.87it/s]\u001b[A\n",
      "  1%|          | 40/3857 [00:24<26:13,  2.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paulinus of nola: Q132473 NOT FOUND in OTHERS\n",
      "___________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:31\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:93\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:129\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handle\u001b[38;5;241m.\u001b[39m_cancelled:\n\u001b[0;32m--> 129\u001b[0m         \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/events.py:80\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/tasks.py:360\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:205\u001b[0m, in \u001b[0;36m_patch_task.<locals>.step\u001b[0;34m(task, exc)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[43mstep_orig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[41], line 91\u001b[0m, in \u001b[0;36mprocess_item\u001b[0;34m(session, name, value, url, headers, semaphore, pbar)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fetch(session, url, params, headers, semaphore)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientResponseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/backoff/_async.py:151\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[41], line 15\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(session, url, params, headers, semaphore)\u001b[0m\n\u001b[1;32m     14\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Raises an exception for 4XX/5XX status codes\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/aiohttp/client_reqrep.py:1121\u001b[0m, in \u001b[0;36mClientResponse.json\u001b[0;34m(self, encoding, loads, content_type)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_encoding()\n\u001b[0;32m-> 1121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loads(stripped\u001b[38;5;241m.\u001b[39mdecode(encoding))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/tasks.py:279\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "Cell \u001b[0;32mIn[41], line 91\u001b[0m, in \u001b[0;36mprocess_item\u001b[0;34m(session, name, value, url, headers, semaphore, pbar)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fetch(session, url, params, headers, semaphore)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientResponseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/backoff/_async.py:151\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[41], line 11\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(session, url, params, headers, semaphore)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;129m@backoff\u001b[39m\u001b[38;5;241m.\u001b[39mon_exception(\n\u001b[1;32m      5\u001b[0m     backoff\u001b[38;5;241m.\u001b[39mexpo, \n\u001b[1;32m      6\u001b[0m     (aiohttp\u001b[38;5;241m.\u001b[39mClientError, aiohttp\u001b[38;5;241m.\u001b[39mhttp_exceptions\u001b[38;5;241m.\u001b[39mHttpProcessingError, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(session, url, params, headers, semaphore):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m response:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/locks.py:15\u001b[0m, in \u001b[0;36m_ContextManagerMixin.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# We have no use for the \"as ...\"  clause in the with\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# statement for locks.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/locks.py:387\u001b[0m, in \u001b[0;36mSemaphore.acquire\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/futures.py:287\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/tasks.py:349\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/futures.py:198\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cancelled_error()\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m!=\u001b[39m _FINISHED:\n",
      "\u001b[0;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 176\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(mentions))\n\u001b[0;32m--> 176\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:  \u001b[38;5;66;03m# For environments like Jupyter\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:36\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     34\u001b[0m task\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(asyncio\u001b[38;5;241m.\u001b[39mCancelledError):\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:93\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     91\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:129\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m     handle \u001b[38;5;241m=\u001b[39m ready\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handle\u001b[38;5;241m.\u001b[39m_cancelled:\n\u001b[0;32m--> 129\u001b[0m         \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/events.py:80\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/tasks.py:352\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    349\u001b[0m     future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:205\u001b[0m, in \u001b[0;36m_patch_task.<locals>.step\u001b[0;34m(task, exc)\u001b[0m\n\u001b[1;32m    203\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mget(task\u001b[38;5;241m.\u001b[39m_loop)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[43mstep_orig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/tasks.py:344\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcall_soon(\n\u001b[1;32m    342\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step, new_exc, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[43m_leave_task\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:220\u001b[0m, in \u001b[0;36m_patch_task.<locals>.leave_task\u001b[0;34m(loop, task)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menter_task\u001b[39m(loop, task):\n\u001b[1;32m    218\u001b[0m     curr_tasks[loop] \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mleave_task\u001b[39m(loop, task):\n\u001b[1;32m    221\u001b[0m     curr_tasks\u001b[38;5;241m.\u001b[39mpop(loop, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    223\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39m_enter_task \u001b[38;5;241m=\u001b[39m enter_task\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url = 'https://lamapi.hel.sintef.cloud/lookup/entity-retrieval'\n",
    "\n",
    "# Backoff decorator for handling retries with exponential backoff\n",
    "@backoff.on_exception(\n",
    "    backoff.expo, \n",
    "    (aiohttp.ClientError, aiohttp.http_exceptions.HttpProcessingError, asyncio.TimeoutError), \n",
    "    max_tries=5, \n",
    "    max_time=300\n",
    ")\n",
    "async def fetch(session, url, params, headers, semaphore):\n",
    "    async with semaphore:\n",
    "        async with session.get(url, params=params, headers=headers, timeout=30) as response:\n",
    "            try:\n",
    "                response.raise_for_status()  # Raises an exception for 4XX/5XX status codes\n",
    "                return await response.json()\n",
    "            except Exception as e:\n",
    "                return []\n",
    "async def process_item(session, name, value, url, headers, semaphore, pbar):\n",
    "    ### SOFT FILTERING CONTSTRAINT\n",
    "    #params = {\n",
    "    #    'name': name,\n",
    "    #    'token': 'lamapi_demo_2023',\n",
    "    #    'kg': 'wikidata',\n",
    "    #    'limit': 1000,\n",
    "    #    'query': f'''\n",
    "    #        {{\n",
    "    #            \"query\": {{\n",
    "    #                \"bool\": {{\n",
    "    #                    \"must\": [\n",
    "    #                        {{\n",
    "    #                            \"match\": {{\n",
    "    #                                \"name\": {{\n",
    "    #                                    \"query\": \"{name}\",\n",
    "    #                                    \"boost\": 2.0\n",
    "    #                                }}\n",
    "    #                            }}\n",
    "    #                        }}\n",
    "    #                    ],\n",
    "    #                    \"should\": [\n",
    "    #                        {{\n",
    "    #                            \"term\": {{\n",
    "    #                                \"NERtype\": \"{value[1]}\"\n",
    "    #                            }}\n",
    "    #                        }}\n",
    "    #                    ]\n",
    "    #                }}\n",
    "    #            }}\n",
    "    #        }}\n",
    "    #        ''',\n",
    "    #    'sort': [\n",
    "    #        f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "    #    ]\n",
    "    #}\n",
    "\n",
    "    ### HARD FILTERING CONTSTRAINT\n",
    "    params = {\n",
    "        'name': name,\n",
    "        'token': 'lamapi_demo_2023',\n",
    "        'kg': 'wikidata',\n",
    "        'limit': 1000,\n",
    "        'query': f'''\n",
    "            {{\n",
    "                \"query\": {{\n",
    "                    \"bool\": {{\n",
    "                        \"must\": [\n",
    "                            {{\n",
    "                                \"match\": {{\n",
    "                                    \"name\": {{\n",
    "                                        \"query\": \"{name}\",\n",
    "                                        \"boost\": 2.0\n",
    "                                    }}\n",
    "                                }}\n",
    "                            }},\n",
    "                            {{\n",
    "                                \"term\": {{\n",
    "                                    \"NERtype\": \"{value[1]}\"\n",
    "                                }}\n",
    "                            }}\n",
    "                        ]\n",
    "                    }}\n",
    "                }}\n",
    "            }}\n",
    "            ''',\n",
    "        'sort': [\n",
    "            f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    try:\n",
    "        data = await fetch(session, url, params, headers, semaphore)\n",
    "    except ClientResponseError as e:\n",
    "        if e.status == 404:\n",
    "            print(f\"404 Error: Resource not found for '{name}'\")\n",
    "            pbar.update(1)  # No need to await here\n",
    "            return 0, 0\n",
    "        else:\n",
    "            raise  # Re-raise the exception for other status codes\n",
    "\n",
    "    num_result = len(data) if data else 0\n",
    "\n",
    "    if data:\n",
    "        pbar.update(1)  # No need to await here\n",
    "        for item in data:\n",
    "            GT_id_match = re.search(r'Q(\\d+)$', value[0])\n",
    "\n",
    "            if GT_id_match:\n",
    "                GT_id = GT_id_match[0]\n",
    "                if GT_id == item.get('id'):\n",
    "                    pos_score = item.get('pos_score', 0)\n",
    "                    if pos_score:\n",
    "                        mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                    else:\n",
    "                        mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                    return mrr_increment, 1\n",
    "\n",
    "        print(f\"{name}: {GT_id_match[0]} NOT FOUND in {value[1]}\")\n",
    "        print(\"___________________________\")\n",
    "\n",
    "    return 0, 0\n",
    "\n",
    "async def main(mentions, url, pbar):\n",
    "    string_name_list = mentions\n",
    "    headers = {'accept': 'application/json'}\n",
    "    semaphore = asyncio.Semaphore(50)  # Limit to 50 concurrent requests\n",
    "    m_mrr = 0\n",
    "    cont_el = 0\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for name, type in string_name_list.items():\n",
    "            tasks.append(process_item(session, name, type, url, headers, semaphore, pbar))\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for (mrr_increment, count), (name, url_id) in zip(results, string_name_list.items()):\n",
    "            if mrr_increment == 0 and count == 0:\n",
    "                params = {\n",
    "                    'name': name,\n",
    "                    'token': 'lamapi_demo_2023',\n",
    "                    'kg': 'wikidata',\n",
    "                    'limit': 1000,\n",
    "                    'query':  f'''{{\"query\": {{\"bool\": {{\"must\": [{{\"match\": {{\"name\": {{\"query\": \"{name}\", \"boost\": 2.0, \"fuzziness\": \"AUTO\"}}}}}}]}}}}}}''',\n",
    "                    'sort': [\n",
    "                        f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "                    ]\n",
    "                }\n",
    "                id = re.search(r'Q(\\d+)$', url_id[0])[0]\n",
    "\n",
    "                response = requests.get(url, params)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    num_result = len(data) if data else 0\n",
    "                    if data:\n",
    "                        for item in data:\n",
    "                            if id == item.get('id'):\n",
    "                                pbar.update(1)  # No need to await here\n",
    "                                pos_score = item.get('pos_score', 0)\n",
    "                                if pos_score:\n",
    "                                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                                else:\n",
    "                                    mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                            \n",
    "            m_mrr += mrr_increment\n",
    "            cont_el += count\n",
    "\n",
    "        pbar.close()  # No need to await here\n",
    "\n",
    "    print(f\"Coverage of R1: {cont_el / len(mentions)}\")\n",
    "    print(f\"Measure Reciprocal Rank of R1: {m_mrr / len(mentions)}\")\n",
    "\n",
    "# Check if there's already a running event loop\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()  # Apply nest_asyncio\n",
    "    try:\n",
    "        pbar = tqdm(total=len(mentions))\n",
    "        asyncio.run(main(mentions, url, pbar))\n",
    "    except RuntimeError:  # For environments like Jupyter\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(main(mentions, url, pbar))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage with the soft filtering\n",
    "Coverage of R1: 0.9836745270795543\n",
    "\r\n",
    "Measure Reciprocal Rank of R1: 0.9616820419797453\n",
    "\n",
    "## Coverage with the hard filtering\n",
    "Coverage of R1: 0.8067357512953368\n",
    "\r\n",
    "Measure Reciprocal Rank of 13: 0.96043575129529763"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Round3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round3_2019_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R3_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(R3_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = R3_sorted_mentions[:q1_idx]\n",
    "q2 = R3_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = R3_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = R3_sorted_mentions[q3_idx:]\n",
    "\n",
    "\n",
    "sample_size = 1000 \n",
    "R3_sample_keys = []\n",
    "R3_sample_keys = R3_sample_keys + random.sample(q1, sample_size)\n",
    "R3_sample_keys = R3_sample_keys + random.sample(q2, sample_size)\n",
    "R3_sample_keys = R3_sample_keys + random.sample(q3, sample_size)\n",
    "R3_sample_keys = R3_sample_keys + random.sample(q4, sample_size)\n",
    "\n",
    "q_ids = {item[1]['name']: item[1]['id'] for item in R3_sample_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mention in the table\n",
    "tables = \"./data/Dataset/Dataset/Round3_2019/tables/\"\n",
    "cta_file = './data/Dataset/Dataset/Round3_2019/gt/CTA_Round3_gt.csv'\n",
    "os.listdir(tables)\n",
    "\n",
    "\n",
    "# Apply the function and create the 'key' column\n",
    "cta_keys = {}\n",
    "df = pd.read_csv(cta_file, header=None)\n",
    "category_list = []\n",
    "\n",
    "for row_idx in range(df.shape[0]):\n",
    "    col_idx = 2\n",
    "    while True:\n",
    "        try:\n",
    "            if pd.isna(df.iloc[row_idx,col_idx]):\n",
    "                category_list.append(\"OTHERS\")\n",
    "                break\n",
    "            urls = df.iloc[row_idx,col_idx].split(' ')\n",
    "        except IndexError as e:\n",
    "            category_list.append(\"OTHERS\")\n",
    "            break\n",
    "        \n",
    "        #print(f\"{df.iloc[row_idx,0]}->{cell_urls} @ {row_idx},{col_idx}\")\n",
    "        find = False\n",
    "        for url in urls:\n",
    "            type = url.split('/')[-1]            \n",
    "            if type == \"Person\":\n",
    "                category_list.append(\"PER\")\n",
    "                find = True\n",
    "                break\n",
    "            elif type == \"Location\":\n",
    "                category_list.append(\"LOC\")\n",
    "                find = True\n",
    "                break\n",
    "            elif type == \"Organisation\":\n",
    "                category_list.append(\"ORG\")\n",
    "                find = True\n",
    "                break\n",
    "        if find:\n",
    "            break\n",
    "        \n",
    "        col_idx += 1\n",
    "\n",
    "\n",
    "\n",
    "df[\"category\"] = category_list\n",
    "cta_keys = {}\n",
    "cta_keys[\"key\"] = (df[0] + \" \" + df[1].astype('str'), df[\"category\"])\n",
    "\n",
    "key_to_cell = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {col}\"\n",
    "            if key in set(cta_keys[\"key\"][0].values):\n",
    "                tmp_index = cta_keys[\"key\"][0].values.tolist().index(key)\n",
    "                tmp_value = cta_keys[\"key\"][1].iloc[tmp_index]\n",
    "                key_to_cell[key] = tmp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys_from_value(d, value):\n",
    "    keys = [key for key, val in d.items() if val == value]\n",
    "    return keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cea_file = './data/Dataset/Dataset/Round3_2019/gt/CEA_Round3_gt_WD.csv'\n",
    "mentions = {}\n",
    "chunk_size = 1000\n",
    "column_names = [\"table_name\", \"row\", \"col\", \"url\"] \n",
    "\n",
    "total_rows = sum(1 for line in open(cea_file)) - 1  # Exclude header\n",
    "total_iterations = (total_rows + chunk_size - 1) // chunk_size  # Ceiling division to include last chunk\n",
    "\n",
    "for chunk_cea in tqdm(pd.read_csv(cea_file, chunksize=chunk_size), total=total_iterations):\n",
    "    chunk_cea.columns = column_names\n",
    "    for _, row in chunk_cea.iterrows():\n",
    "        key = f\"{row['table_name']} {row['col']}\"\n",
    "        if key in key_to_cell.keys() and row[\"url\"] in q_ids.values():\n",
    "            data = key_to_cell[key]\n",
    "            mentions[get_keys_from_value(q_ids, row[\"url\"])] = (row[\"url\"], data)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://lamapi.hel.sintef.cloud/lookup/entity-retrieval'\n",
    "\n",
    "# Backoff decorator for handling retries with exponential backoff\n",
    "@backoff.on_exception(\n",
    "    backoff.expo, \n",
    "    (aiohttp.ClientError, aiohttp.http_exceptions.HttpProcessingError, asyncio.TimeoutError), \n",
    "    max_tries=5, \n",
    "    max_time=300\n",
    ")\n",
    "async def fetch(session, url, params, headers, semaphore):\n",
    "    async with semaphore:\n",
    "        async with session.get(url, params=params, headers=headers, timeout=30) as response:\n",
    "            try:\n",
    "                response.raise_for_status()  # Raises an exception for 4XX/5XX status codes\n",
    "                return await response.json()\n",
    "            except Exception as e:\n",
    "                return []\n",
    "async def process_item(session, name, value, url, headers, semaphore, pbar):\n",
    "    ### SOFT FILTERING CONTSTRAINT\n",
    "    #params = {\n",
    "    #    'name': name,\n",
    "    #    'token': 'lamapi_demo_2023',\n",
    "    #    'kg': 'wikidata',\n",
    "    #    'limit': 1000,\n",
    "    #    'query': f'''\n",
    "    #        {{\n",
    "    #            \"query\": {{\n",
    "    #                \"bool\": {{\n",
    "    #                    \"must\": [\n",
    "    #                        {{\n",
    "    #                            \"match\": {{\n",
    "    #                                \"name\": {{\n",
    "    #                                    \"query\": \"{name}\",\n",
    "    #                                    \"boost\": 2.0\n",
    "    #                                }}\n",
    "    #                            }}\n",
    "    #                        }}\n",
    "    #                    ],\n",
    "    #                    \"should\": [\n",
    "    #                        {{\n",
    "    #                            \"term\": {{\n",
    "    #                                \"NERtype\": \"{value[1]}\"\n",
    "    #                            }}\n",
    "    #                        }}\n",
    "    #                    ]\n",
    "    #                }}\n",
    "    #            }}\n",
    "    #        }}\n",
    "    #        ''',\n",
    "    #    'sort': [\n",
    "    #        f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "    #    ]\n",
    "    #}\n",
    "\n",
    "    ### HARD FILTERING CONTSTRAINT\n",
    "    params = {\n",
    "        'name': name,\n",
    "        'token': 'lamapi_demo_2023',\n",
    "        'kg': 'wikidata',\n",
    "        'limit': 1000,\n",
    "        'query': f'''\n",
    "            {{\n",
    "                \"query\": {{\n",
    "                    \"bool\": {{\n",
    "                        \"must\": [\n",
    "                            {{\n",
    "                                \"match\": {{\n",
    "                                    \"name\": {{\n",
    "                                        \"query\": \"{name}\",\n",
    "                                        \"boost\": 2.0\n",
    "                                    }}\n",
    "                                }}\n",
    "                            }},\n",
    "                            {{\n",
    "                                \"term\": {{\n",
    "                                    \"NERtype\": \"{value[1]}\"\n",
    "                                }}\n",
    "                            }}\n",
    "                        ]\n",
    "                    }}\n",
    "                }}\n",
    "            }}\n",
    "            ''',\n",
    "        'sort': [\n",
    "            f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    try:\n",
    "        data = await fetch(session, url, params, headers, semaphore)\n",
    "    except ClientResponseError as e:\n",
    "        if e.status == 404:\n",
    "            print(f\"404 Error: Resource not found for '{name}'\")\n",
    "            pbar.update(1)  # No need to await here\n",
    "            return 0, 0\n",
    "        else:\n",
    "            raise  # Re-raise the exception for other status codes\n",
    "\n",
    "    num_result = len(data) if data else 0\n",
    "\n",
    "    if data:\n",
    "        for item in data:\n",
    "            GT_id_match = re.search(r'Q(\\d+)$', value[0])\n",
    "            if GT_id_match:\n",
    "                GT_id = GT_id_match[0]\n",
    "                if GT_id == item.get('id'):\n",
    "                    pbar.update(1)  # No need to await here\n",
    "                    pos_score = item.get('pos_score', 0)\n",
    "                    if pos_score:\n",
    "                        mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                    else:\n",
    "                        mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                    return mrr_increment, 1\n",
    "\n",
    "        #print(f\"{name} NOT FOUND-->t{item}\")\n",
    "\n",
    "    return 0, 0\n",
    "\n",
    "async def main(mentions, url, pbar):\n",
    "    string_name_list = mentions\n",
    "    headers = {'accept': 'application/json'}\n",
    "    semaphore = asyncio.Semaphore(50)  # Limit to 50 concurrent requests\n",
    "    m_mrr = 0\n",
    "    cont_el = 0\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for name, type in string_name_list.items():\n",
    "            tasks.append(process_item(session, name, type, url, headers, semaphore, pbar))\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for (mrr_increment, count), (name, url_id) in zip(results, string_name_list.items()):\n",
    "            if mrr_increment == 0 and count == 0:\n",
    "                params = {\n",
    "                    'name': name,\n",
    "                    'token': 'lamapi_demo_2023',\n",
    "                    'kg': 'wikidata',\n",
    "                    'limit': 1000,\n",
    "                    'query':  f'''{{\"query\": {{\"bool\": {{\"must\": [{{\"match\": {{\"name\": {{\"query\": \"{name}\", \"boost\": 2.0, \"fuzziness\": \"AUTO\"}}}}}}]}}}}}}''',\n",
    "                    'sort': [\n",
    "                        f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "                    ]\n",
    "                }\n",
    "                id = re.search(r'Q(\\d+)$', url_id[0])[0]\n",
    "                \n",
    "                response = requests.get(url, params)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    #print(\"after call\")\n",
    "                    num_result = len(data) if data else 0\n",
    "                    if data:\n",
    "                        for item in data:\n",
    "                            if id == item.get('id'):\n",
    "                                pbar.update(1)  # No need to await here\n",
    "                                pos_score = item.get('pos_score', 0)\n",
    "                                if pos_score:\n",
    "                                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                                else:\n",
    "                                    mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                            \n",
    "            m_mrr += mrr_increment\n",
    "            cont_el += count\n",
    "\n",
    "        pbar.close()  # No need to await here\n",
    "\n",
    "    print(f\"Coverage of R3: {cont_el / len(mentions)}\")\n",
    "    print(f\"Measure Reciprocal Rank of R3: {m_mrr / len(mentions)}\")\n",
    "\n",
    "# Check if there's already a running event loop\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()  # Apply nest_asyncio\n",
    "    try:\n",
    "        pbar = tqdm(total=len(mentions))\n",
    "        asyncio.run(main(mentions, url, pbar))\n",
    "    except RuntimeError:  # For environments like Jupyter\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(main(mentions, url, pbar))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage with the soft filtering\r",
    "Coverage of R3: 0.9634817408704353\n",
    "\r\n",
    "Measure Reciprocal Rank of R3: 0.9472711355677341\n",
    "\n",
    "## Coverage with the hard filtering\n",
    "Coverage of R3: 0.5406758448060075\n",
    "\r\n",
    "Measure Reciprocal Rank of R3: 0.96075719649556936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2T_Round4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/2T_Round4_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R4_2T_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample extraction\n",
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(R4_2T_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = R4_2T_sorted_mentions[:q1_idx]\n",
    "q2 = R4_2T_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = R4_2T_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = R4_2T_sorted_mentions[q3_idx:]\n",
    "\n",
    "sample_size = 1000\n",
    "R4_2T_sample_keys = []\n",
    "R4_2T_sample_keys = R4_2T_sample_keys + random.sample(q1, sample_size)\n",
    "R4_2T_sample_keys = R4_2T_sample_keys + random.sample(q2, sample_size)\n",
    "R4_2T_sample_keys = R4_2T_sample_keys + random.sample(q3, sample_size)\n",
    "R4_2T_sample_keys = R4_2T_sample_keys + random.sample(q4, sample_size)\n",
    "\n",
    "q_ids = {item[1]['name']: item[1]['id'] for item in R4_2T_sample_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_item_tree_item_idsSPARQL(root_items, forward_properties=None, backward_properties=None):\n",
    "    \"\"\"Return ids of WikiData items, which are in the tree spanned by the given root items and claims relating them\n",
    "        to other items.\n",
    "\n",
    "    :param root_items: iterable[int] One or multiple item entities that are the root elements of the tree\n",
    "    :param forward_properties: iterable[int] | None property-claims to follow forward; that is, if root item R has\n",
    "        a claim P:I, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :param backward_properties: iterable[int] | None property-claims to follow in reverse; that is, if (for a root\n",
    "        item R) an item I has a claim P:R, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :return: iterable[int]: List with ids of WikiData items in the tree\n",
    "    \"\"\"\n",
    "\n",
    "    query = '''PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>'''\n",
    "    if forward_properties:\n",
    "        query +='''SELECT ?WD_id WHERE {\n",
    "                  ?tree0 (wdt:P%s)* ?WD_id .\n",
    "                  BIND (wd:%s AS ?tree0)\n",
    "                  }'''%( ','.join(map(str, forward_properties)),','.join(map(str, root_items)))\n",
    "    elif backward_properties:\n",
    "        query+='''SELECT ?WD_id WHERE {\n",
    "                    ?WD_id (wdt:P%s)* wd:Q%s .\n",
    "                    }'''%(','.join(map(str, backward_properties)), ','.join(map(str, root_items)))\n",
    "    #print(query)\n",
    "\n",
    "    url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "    data = get(url, params={'query': query, 'format': 'json'}).json()\n",
    "    \n",
    "    ids = []\n",
    "    for item in data['results']['bindings']:\n",
    "        this_id=item[\"WD_id\"][\"value\"].split(\"/\")[-1].lstrip(\"Q\")\n",
    "        #print(item)\n",
    "        try:\n",
    "            this_id = int(this_id)\n",
    "            ids.append(this_id)\n",
    "            #print(this_id)\n",
    "        except ValueError:\n",
    "            #print(\"exception\")\n",
    "            continue\n",
    "    return ids\n",
    "\n",
    "\n",
    "try:\n",
    "    organization_subclass = get_wikidata_item_tree_item_idsSPARQL([43229], backward_properties=[279])\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    country_subclass = get_wikidata_item_tree_item_idsSPARQL([6256], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    country_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    city_subclass = get_wikidata_item_tree_item_idsSPARQL([515], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    city_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    capitals_subclass = get_wikidata_item_tree_item_idsSPARQL([5119], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    capitals_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    admTerr_subclass = get_wikidata_item_tree_item_idsSPARQL([15916867], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    admTerr_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    family_subclass = get_wikidata_item_tree_item_idsSPARQL([17350442], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    family_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    sportLeague_subclass = get_wikidata_item_tree_item_idsSPARQL([623109], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    sportLeague_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    venue_subclass = get_wikidata_item_tree_item_idsSPARQL([8436], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    venue_subclass = set()\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    organization_subclass = list(set(organization_subclass) - set(country_subclass) - set(city_subclass) - set(capitals_subclass) - set(admTerr_subclass) - set(family_subclass) - set(sportLeague_subclass) - set(venue_subclass))\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    geolocation_subclass = get_wikidata_item_tree_item_idsSPARQL([2221906], backward_properties=[279])\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    food_subclass = get_wikidata_item_tree_item_idsSPARQL([2095], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    food_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    edInst_subclass = get_wikidata_item_tree_item_idsSPARQL([2385804], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    edInst_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    govAgency_subclass = get_wikidata_item_tree_item_idsSPARQL([327333], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    govAgency_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    intOrg_subclass = get_wikidata_item_tree_item_idsSPARQL([484652], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    intOrg_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    timeZone_subclass = get_wikidata_item_tree_item_idsSPARQL([12143], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    timeZone_subclass = set()\n",
    "    pass\n",
    "   \n",
    "try:\n",
    "    geolocation_subclass = list(set(geolocation_subclass) - set(food_subclass) - set(edInst_subclass) - set(govAgency_subclass) - set(intOrg_subclass) - set(timeZone_subclass))\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    human_subclass = get_wikidata_item_tree_item_idsSPARQL([5], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    human_subclass = set()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tables: 100%|██████████| 180/180 [00:15<00:00, 11.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "tables_path = \"./data/Dataset/Dataset/2T_Round4/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/2T_Round4/gt/cea.csv'\n",
    "os.listdir(tables_path)\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Read the cea_file and create a key-value dictionary\n",
    "df = pd.read_csv(cea_file, header=None)\n",
    "df[\"key\"] = df[0] + \" \" + df[1].astype(str) + \" \" + df[2].astype(str)\n",
    "cea_values_dict = dict(zip(df[\"key\"].values, df[3].values))\n",
    "cea_keys_set = set(df[\"key\"].values)\n",
    "\n",
    "# Function to process a single table file\n",
    "def process_table_file(table_file):\n",
    "    try:\n",
    "        table_name = os.path.splitext(os.path.basename(table_file))[0]\n",
    "        df = pd.read_csv(table_file)\n",
    "        local_key_to_cell = {}\n",
    "        \n",
    "        for row in range(df.shape[0]):\n",
    "            for col in range(df.shape[1]):\n",
    "                key = f\"{table_name} {row+1} {col}\"\n",
    "                if key in cea_keys_set:\n",
    "                    cell_value = df.iloc[row, col]\n",
    "                    local_key_to_cell[key] = (cell_value, cea_values_dict[key])\n",
    "                    break  # Exit inner loop early as only one match per row/col is needed\n",
    "        \n",
    "        return local_key_to_cell\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {table_file}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# List of table files\n",
    "table_files = [os.path.join(tables_path, table) for table in os.listdir(tables_path)]\n",
    "\n",
    "# Process tables sequentially\n",
    "key_to_cell = {}\n",
    "for table_file in tqdm(table_files, desc=\"Processing tables\"):\n",
    "    local_key_to_cell = process_table_file(table_file)\n",
    "    key_to_cell.update(local_key_to_cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:46<00:00,  3.86it/s]\n"
     ]
    }
   ],
   "source": [
    "tables = \"./data/Dataset/Dataset/2T_Round4/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/2T_Round4/gt/cea.csv'\n",
    "cta_file = './data/Dataset/Dataset/2T_Round4/gt/cta.csv'\n",
    "os.listdir(tables)\n",
    "\n",
    "def get_item_root(id_list):     \n",
    "    id_to_root_class = {}\n",
    "    for el in id_list:\n",
    "        inst_item = int(re.search(r'(\\d+)$', el)[0])\n",
    "        if inst_item in geolocation_subclass:\n",
    "            #id_to_root_class[el] = \"LOC\"\n",
    "            return \"LOC\"\n",
    "        elif inst_item in organization_subclass:\n",
    "            #id_to_root_class[el] = \"ORG\"\n",
    "            return \"ORG\"\n",
    "        elif inst_item in human_subclass:\n",
    "            #id_to_root_class[el] = \"PERS\"\n",
    "            return \"PERS\"      \n",
    "    \n",
    "    return \"OTHERS\"\n",
    "\n",
    "# Apply the function and create the 'key' column\n",
    "root_classes = []\n",
    "df = pd.read_csv(cta_file, header=None)\n",
    "root_categories = []\n",
    "for urls in df[2]:\n",
    "    tmp = [url.split('/')[-1] for url in urls.split(\" \")]\n",
    "    root_categories.append(get_item_root(tmp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df[\"category\"] = root_categories\n",
    "cta_keys = {}\n",
    "cta_keys[\"key\"] = (df[0] + \" \" + df[1].astype('str'), df[\"category\"])\n",
    "\n",
    "ner_type = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {col}\"\n",
    "            if key in set(cta_keys[\"key\"][0].values):\n",
    "                tmp_index = cta_keys[\"key\"][0].values.tolist().index(key)\n",
    "                tmp_value = cta_keys[\"key\"][1].iloc[tmp_index]\n",
    "                ner_type[key] = tmp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194438/194438 [00:05<00:00, 33584.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_query(name, value):\n",
    "    if value is not None:\n",
    "          ### SOFT FILTERING CONTSTRAINT\n",
    "        #params = {\n",
    "        #    'name': name,\n",
    "        #    'token': 'lamapi_demo_2023',\n",
    "        #    'kg': 'wikidata',\n",
    "        #    'limit': 1000,\n",
    "        #    'query': f'''\n",
    "        #        {{\n",
    "        #            \"query\": {{\n",
    "        #                \"bool\": {{\n",
    "        #                    \"must\": [\n",
    "        #                        {{\n",
    "        #                            \"match\": {{\n",
    "        #                                \"name\": {{\n",
    "        #                                    \"query\": \"{name}\",\n",
    "        #                                    \"boost\": 2.0\n",
    "        #                                }}\n",
    "        #                            }}\n",
    "        #                        }}\n",
    "        #                    ],\n",
    "        #                    \"should\": [\n",
    "        #                        {{\n",
    "        #                            \"term\": {{\n",
    "        #                                \"NERtype\": \"{value[1]}\"\n",
    "        #                            }}\n",
    "        #                        }}\n",
    "        #                    ]\n",
    "        #                }}\n",
    "        #            }}\n",
    "        #        }}\n",
    "        #        ''',\n",
    "        #    'sort': [\n",
    "        #        f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "        #    ]\n",
    "        #}\n",
    "    \n",
    "        ### HARD FILTERING CONTSTRAINT\n",
    "        params = {\n",
    "            'name': name,\n",
    "            'token': 'lamapi_demo_2023',\n",
    "            'kg': 'wikidata',\n",
    "            'limit': 1000,\n",
    "            'query': f'''\n",
    "                {{\n",
    "                    \"query\": {{\n",
    "                        \"bool\": {{\n",
    "                            \"must\": [\n",
    "                                {{\n",
    "                                    \"match\": {{\n",
    "                                        \"name\": {{\n",
    "                                            \"query\": \"{name}\",\n",
    "                                            \"boost\": 2.0\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                }},\n",
    "                                {{\n",
    "                                    \"term\": {{\n",
    "                                        \"NERtype\": \"{value}\"\n",
    "                                    }}\n",
    "                                }}\n",
    "                            ]\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "                ''',\n",
    "            'sort': [\n",
    "                f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        params = {\n",
    "            'name': name,\n",
    "            'token': 'lamapi_demo_2023',\n",
    "            'kg': 'wikidata',\n",
    "            'limit': 1000,\n",
    "            'query': f'''{{\"query\": {{\"bool\": {{\"must\": [{{\"match\": {{\"name\": {{\"query\": \"{name}\", \"boost\": 2.0}}}}}}]}}}}}}''',\n",
    "            'sort': [\n",
    "                f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "            ]\n",
    "        }\n",
    "    return params\n",
    "\n",
    "\n",
    "queries = []\n",
    "for key in tqdm(key_to_cell):\n",
    "    id_table, _, id_col = key.split(\" \")\n",
    "    name = key_to_cell[key][0]\n",
    "    q_id = key_to_cell[key][1]\n",
    "    new_key = f\"{id_table} {id_col}\"\n",
    "    if new_key in ner_type:\n",
    "        NER_type = ner_type[new_key]\n",
    "        query = get_query(name, NER_type)\n",
    "        match = re.search(r'Q(\\d+)$', q_id)\n",
    "        if match:\n",
    "            queries.append((query, match[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 3/4000 [00:39<14:45:24, 13.29s/it]\n",
      "\n",
      "\n",
      "  0%|          | 1/4000 [00:11<12:47:00, 11.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/4000 [00:11<5:22:17,  4.84s/it] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 3/4000 [00:11<2:59:20,  2.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 4/4000 [00:13<2:42:02,  2.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 5/4000 [00:14<1:55:32,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 6/4000 [00:14<1:21:13,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 7/4000 [00:14<1:01:32,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 10/4000 [00:15<27:37,  2.41it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 12/4000 [00:15<19:26,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 14/4000 [00:15<14:23,  4.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 18/4000 [00:15<08:10,  8.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 20/4000 [00:15<07:04,  9.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 24/4000 [00:16<08:27,  7.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 26/4000 [00:16<12:50,  5.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 28/4000 [00:17<17:55,  3.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 29/4000 [00:18<20:16,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 30/4000 [00:18<21:37,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 33/4000 [00:19<13:59,  4.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 34/4000 [00:19<17:39,  3.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 35/4000 [00:20<21:04,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 37/4000 [00:20<16:37,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 39/4000 [00:20<14:34,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 40/4000 [00:20<14:04,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 41/4000 [00:21<22:38,  2.91it/s]\u001b[A\u001b[A2024-07-16 13:01:12,999 - INFO - Backing off fetch(...) for 0.3s (aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host lamapi.hel.sintef.cloud:443 ssl:default [Connect call failed ('65.108.140.148', 443)])\n",
      "2024-07-16 13:01:13,003 - INFO - Backing off fetch(...) for 0.4s (aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host lamapi.hel.sintef.cloud:443 ssl:default [Connect call failed ('65.108.140.148', 443)])\n",
      "2024-07-16 13:01:13,006 - INFO - Backing off fetch(...) for 0.9s (aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host lamapi.hel.sintef.cloud:443 ssl:default [Connect call failed ('65.108.140.148', 443)])\n",
      "\n",
      "\n",
      "  1%|          | 42/4000 [00:21<20:05,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 44/4000 [00:22<13:18,  4.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 45/4000 [00:22<13:56,  4.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 49/4000 [00:22<08:55,  7.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 51/4000 [00:22<08:24,  7.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 55/4000 [00:23<09:04,  7.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 56/4000 [00:23<12:21,  5.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 58/4000 [00:24<12:06,  5.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 59/4000 [00:24<13:49,  4.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 60/4000 [00:24<12:48,  5.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 61/4000 [00:24<12:02,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 62/4000 [00:24<11:08,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 63/4000 [00:25<11:35,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 64/4000 [00:25<12:47,  5.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 66/4000 [00:25<11:47,  5.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 67/4000 [00:26<14:14,  4.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 68/4000 [00:26<14:34,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 69/4000 [00:26<17:31,  3.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 70/4000 [00:26<17:23,  3.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 71/4000 [00:27<14:52,  4.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 72/4000 [00:27<13:10,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 73/4000 [00:27<18:06,  3.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 74/4000 [00:28<23:17,  2.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 75/4000 [00:28<25:43,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 76/4000 [00:28<20:17,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 77/4000 [00:29<24:18,  2.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 78/4000 [00:30<30:51,  2.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 79/4000 [00:30<23:54,  2.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 80/4000 [00:30<21:40,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 81/4000 [00:30<21:54,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 83/4000 [00:31<16:11,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 84/4000 [00:31<14:06,  4.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 85/4000 [00:31<13:38,  4.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 86/4000 [00:31<11:49,  5.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 87/4000 [00:31<15:23,  4.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 90/4000 [00:32<10:40,  6.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 91/4000 [00:32<09:52,  6.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 92/4000 [00:32<12:05,  5.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 94/4000 [00:32<10:32,  6.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 95/4000 [00:33<16:30,  3.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 96/4000 [00:33<15:41,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 97/4000 [00:33<14:26,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▎         | 100/4000 [00:33<08:43,  7.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 103/4000 [00:34<06:07, 10.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 105/4000 [00:34<05:48, 11.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 107/4000 [00:34<05:21, 12.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 109/4000 [00:35<10:05,  6.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 111/4000 [00:35<08:59,  7.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 113/4000 [00:35<10:18,  6.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 114/4000 [00:35<11:08,  5.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 116/4000 [00:36<10:39,  6.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 118/4000 [00:36<08:16,  7.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 120/4000 [00:36<10:58,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 121/4000 [00:37<20:12,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 123/4000 [00:38<27:12,  2.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 124/4000 [00:39<26:10,  2.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 125/4000 [00:39<22:37,  2.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 126/4000 [00:39<18:56,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 127/4000 [00:39<16:07,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 128/4000 [00:39<14:19,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 130/4000 [00:40<12:35,  5.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 131/4000 [00:40<16:46,  3.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 132/4000 [00:41<22:26,  2.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 133/4000 [00:41<21:17,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 134/4000 [00:42<25:34,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 135/4000 [00:51<3:08:23,  2.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 138/4000 [00:51<1:27:12,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 144/4000 [00:51<35:17,  1.82it/s]  \u001b[A\u001b[A2024-07-16 13:01:43,143 - INFO - Backing off fetch(...) for 0.6s (aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host lamapi.hel.sintef.cloud:443 ssl:default [Connect call failed ('65.108.140.148', 443)])\n",
      "2024-07-16 13:01:43,148 - INFO - Backing off fetch(...) for 0.7s (aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host lamapi.hel.sintef.cloud:443 ssl:default [Connect call failed ('65.108.140.148', 443)])\n",
      "\n",
      "\n",
      "  4%|▎         | 149/4000 [00:51<21:06,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 153/4000 [00:52<14:46,  4.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 156/4000 [00:53<16:54,  3.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 159/4000 [00:53<14:16,  4.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 161/4000 [00:53<13:10,  4.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 163/4000 [00:54<12:17,  5.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 165/4000 [00:55<18:25,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 166/4000 [00:55<19:32,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 167/4000 [00:55<19:35,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 168/4000 [00:57<34:59,  1.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 169/4000 [00:57<28:43,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 170/4000 [00:57<27:19,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 172/4000 [00:58<19:00,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 173/4000 [00:58<16:23,  3.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 175/4000 [01:00<39:38,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 177/4000 [01:01<35:43,  1.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 181/4000 [01:01<18:33,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 183/4000 [01:03<26:22,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 184/4000 [01:03<28:49,  2.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 185/4000 [01:03<25:19,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 186/4000 [01:04<22:03,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 187/4000 [01:05<29:38,  2.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 190/4000 [01:05<16:25,  3.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 191/4000 [01:05<15:44,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 192/4000 [01:05<13:43,  4.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 193/4000 [01:06<19:15,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 195/4000 [01:06<14:39,  4.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 196/4000 [01:06<14:22,  4.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 197/4000 [01:06<13:23,  4.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 201/4000 [01:06<06:37,  9.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 204/4000 [01:06<04:54, 12.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 206/4000 [01:07<04:49, 13.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 208/4000 [01:08<16:04,  3.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 210/4000 [01:09<16:48,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 212/4000 [01:09<15:26,  4.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 214/4000 [01:10<16:34,  3.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 216/4000 [01:10<15:44,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 218/4000 [01:10<13:11,  4.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 219/4000 [01:11<16:28,  3.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 220/4000 [01:12<24:12,  2.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 224/4000 [01:12<13:58,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 227/4000 [01:12<09:52,  6.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 229/4000 [01:13<11:31,  5.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 230/4000 [01:14<21:32,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 231/4000 [01:14<24:26,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 232/4000 [01:15<24:54,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 233/4000 [01:15<22:23,  2.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 235/4000 [01:15<15:40,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 237/4000 [01:15<11:52,  5.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 240/4000 [01:16<08:09,  7.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 242/4000 [01:16<12:39,  4.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 244/4000 [01:17<11:46,  5.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 246/4000 [01:17<09:28,  6.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 248/4000 [01:18<14:49,  4.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 249/4000 [01:18<15:28,  4.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 251/4000 [01:18<11:59,  5.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 253/4000 [01:19<13:35,  4.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 254/4000 [01:19<13:50,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 255/4000 [01:19<14:05,  4.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 256/4000 [01:19<14:18,  4.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 258/4000 [01:19<10:06,  6.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 259/4000 [01:20<10:38,  5.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 261/4000 [01:20<07:50,  7.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 263/4000 [01:20<11:39,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 264/4000 [01:20<11:23,  5.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 266/4000 [01:21<11:46,  5.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 268/4000 [01:21<13:51,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 269/4000 [01:22<14:19,  4.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 270/4000 [01:22<16:38,  3.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 273/4000 [01:22<10:18,  6.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 275/4000 [01:23<09:02,  6.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 277/4000 [01:23<11:31,  5.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 278/4000 [01:23<12:09,  5.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 281/4000 [01:24<11:22,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 282/4000 [01:24<11:10,  5.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 284/4000 [01:24<10:41,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 285/4000 [01:25<16:00,  3.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 286/4000 [01:25<16:24,  3.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 288/4000 [01:25<12:23,  4.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 290/4000 [01:26<11:36,  5.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 291/4000 [01:26<13:36,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 292/4000 [01:26<12:45,  4.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 294/4000 [01:26<08:59,  6.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 295/4000 [01:27<12:51,  4.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 296/4000 [01:27<16:12,  3.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 297/4000 [01:27<15:07,  4.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 298/4000 [01:28<13:26,  4.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 299/4000 [01:28<12:45,  4.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 303/4000 [01:28<07:19,  8.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 304/4000 [01:28<09:26,  6.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 306/4000 [01:29<10:26,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 307/4000 [01:29<10:41,  5.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 308/4000 [01:29<15:58,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 309/4000 [01:30<20:04,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 310/4000 [01:31<24:58,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 311/4000 [01:31<21:31,  2.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 314/4000 [01:33<32:51,  1.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 315/4000 [01:33<28:39,  2.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 316/4000 [01:34<29:14,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 317/4000 [01:34<23:52,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 319/4000 [01:35<24:34,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 322/4000 [01:35<15:48,  3.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 323/4000 [01:35<14:08,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 324/4000 [01:35<16:06,  3.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 327/4000 [01:36<11:32,  5.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 329/4000 [01:36<14:42,  4.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 331/4000 [01:37<12:54,  4.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 332/4000 [01:37<15:21,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 333/4000 [01:37<16:04,  3.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 334/4000 [01:38<18:14,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 335/4000 [01:39<27:47,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 337/4000 [01:39<18:34,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 338/4000 [01:39<18:32,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 340/4000 [01:39<13:23,  4.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 342/4000 [01:41<22:42,  2.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 344/4000 [01:41<16:12,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 345/4000 [01:41<14:59,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 346/4000 [01:42<19:32,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 347/4000 [01:42<17:04,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 348/4000 [01:42<17:59,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 349/4000 [01:42<15:07,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 350/4000 [01:42<13:47,  4.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 352/4000 [01:43<15:05,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 353/4000 [01:43<13:25,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 354/4000 [01:43<14:13,  4.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 355/4000 [01:44<25:20,  2.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 356/4000 [01:44<22:43,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 357/4000 [01:45<24:53,  2.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 359/4000 [01:45<17:03,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 361/4000 [01:46<14:30,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 362/4000 [01:47<25:23,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 363/4000 [01:47<23:42,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 364/4000 [01:47<24:38,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 367/4000 [01:48<14:04,  4.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 368/4000 [01:48<12:55,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 369/4000 [01:48<13:28,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 370/4000 [01:48<11:44,  5.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 372/4000 [01:48<08:36,  7.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 373/4000 [01:48<08:18,  7.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 374/4000 [01:49<10:21,  5.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 375/4000 [01:49<13:59,  4.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 376/4000 [01:50<19:21,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 379/4000 [01:50<11:25,  5.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 380/4000 [01:52<33:32,  1.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 381/4000 [01:52<29:50,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 384/4000 [01:53<20:41,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 386/4000 [01:53<15:09,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 387/4000 [01:53<13:47,  4.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 389/4000 [01:53<10:08,  5.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 391/4000 [01:54<11:48,  5.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 393/4000 [01:54<09:13,  6.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 395/4000 [01:54<10:22,  5.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 397/4000 [01:54<10:17,  5.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 399/4000 [01:55<08:56,  6.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 400/4000 [01:55<11:16,  5.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 401/4000 [01:55<10:34,  5.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 405/4000 [01:55<07:52,  7.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 406/4000 [01:57<24:53,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 407/4000 [01:58<22:51,  2.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 409/4000 [02:00<37:42,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 410/4000 [02:00<35:51,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 411/4000 [02:00<29:47,  2.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 412/4000 [02:01<27:50,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 414/4000 [02:01<18:39,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 416/4000 [02:01<12:58,  4.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 417/4000 [02:01<13:18,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 419/4000 [02:02<10:32,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 420/4000 [02:02<10:05,  5.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 421/4000 [02:02<10:10,  5.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 422/4000 [02:02<11:41,  5.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 423/4000 [02:02<12:09,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 425/4000 [02:02<08:48,  6.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 427/4000 [02:03<09:35,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 428/4000 [02:03<09:50,  6.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 430/4000 [02:03<07:41,  7.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 432/4000 [02:07<40:19,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 433/4000 [02:07<35:10,  1.69it/s]\u001b[A\u001b[A2024-07-16 13:02:58,504 - INFO - Backing off fetch(...) for 0.9s (TimeoutError)\n",
      "\n",
      "\n",
      " 11%|█         | 435/4000 [02:07<23:42,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 442/4000 [02:07<09:02,  6.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 445/4000 [02:07<07:37,  7.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 448/4000 [02:09<17:49,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 450/4000 [02:11<26:18,  2.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 452/4000 [02:12<21:57,  2.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 453/4000 [02:12<20:05,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 455/4000 [02:12<15:09,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 457/4000 [02:12<13:51,  4.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 459/4000 [02:12<10:57,  5.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 461/4000 [02:13<12:09,  4.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 463/4000 [02:13<12:59,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 464/4000 [02:14<11:52,  4.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 465/4000 [02:14<17:42,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 466/4000 [02:16<35:57,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 467/4000 [02:16<33:56,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 468/4000 [02:17<28:35,  2.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 469/4000 [02:17<29:53,  1.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 470/4000 [02:18<34:49,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 471/4000 [02:18<28:57,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 472/4000 [02:18<25:17,  2.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 474/4000 [02:19<16:12,  3.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 476/4000 [02:19<13:30,  4.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 477/4000 [02:19<14:18,  4.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 478/4000 [02:20<25:33,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 480/4000 [02:21<19:03,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 483/4000 [02:21<15:08,  3.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 485/4000 [02:22<13:14,  4.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 486/4000 [02:22<11:58,  4.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 487/4000 [02:22<12:22,  4.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 488/4000 [02:22<11:26,  5.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 489/4000 [02:22<12:30,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 490/4000 [02:23<18:29,  3.16it/s]\u001b[A\u001b[A2024-07-16 13:03:14,780 - INFO - Backing off fetch(...) for 0.2s (TimeoutError)\n",
      "\n",
      "\n",
      " 12%|█▏        | 492/4000 [02:23<15:43,  3.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 493/4000 [02:23<13:51,  4.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 494/4000 [02:24<12:47,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 495/4000 [02:24<11:40,  5.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 496/4000 [02:24<10:18,  5.66it/s]\u001b[A\u001b[A2024-07-16 13:03:15,817 - INFO - Backing off fetch(...) for 0.1s (TimeoutError)\n",
      "\n",
      "\n",
      " 12%|█▏        | 498/4000 [02:25<15:10,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 501/4000 [02:25<08:54,  6.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 503/4000 [02:25<10:27,  5.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 504/4000 [02:26<14:08,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 505/4000 [02:26<15:29,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 506/4000 [02:26<13:29,  4.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 507/4000 [02:26<11:52,  4.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 508/4000 [02:28<33:35,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 510/4000 [02:28<25:22,  2.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 511/4000 [02:29<23:22,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 513/4000 [02:29<17:16,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 514/4000 [02:29<19:01,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 515/4000 [02:30<15:52,  3.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 517/4000 [02:30<11:00,  5.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 518/4000 [02:30<12:05,  4.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 519/4000 [02:31<19:04,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 521/4000 [02:31<12:28,  4.65it/s]\u001b[A\u001b[A2024-07-16 13:03:22,858 - INFO - Backing off fetch(...) for 0.6s (aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host lamapi.hel.sintef.cloud:443 ssl:default [Temporary failure in name resolution])\n",
      "2024-07-16 13:03:22,865 - INFO - Backing off fetch(...) for 0.6s (aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host lamapi.hel.sintef.cloud:443 ssl:default [Temporary failure in name resolution])\n",
      "2024-07-16 13:03:22,870 - INFO - Backing off fetch(...) for 0.0s (aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host lamapi.hel.sintef.cloud:443 ssl:default [Temporary failure in name resolution])\n",
      "\n",
      "\n",
      " 13%|█▎        | 523/4000 [02:31<16:00,  3.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 524/4000 [02:32<16:45,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 526/4000 [02:32<13:08,  4.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 528/4000 [02:32<12:25,  4.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 529/4000 [02:33<16:15,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 530/4000 [02:34<21:36,  2.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 532/4000 [02:34<14:57,  3.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 533/4000 [02:34<14:48,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 534/4000 [02:34<15:08,  3.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 535/4000 [02:35<14:34,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 536/4000 [02:35<20:37,  2.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 538/4000 [02:36<18:10,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 542/4000 [02:36<09:36,  6.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 543/4000 [02:37<17:23,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 545/4000 [02:37<16:49,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 547/4000 [02:38<12:56,  4.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 548/4000 [02:38<16:46,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 550/4000 [02:39<17:12,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 552/4000 [02:39<12:52,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 553/4000 [02:39<12:43,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 557/4000 [02:40<14:04,  4.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 558/4000 [02:41<15:30,  3.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 559/4000 [02:41<15:59,  3.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 560/4000 [02:42<25:58,  2.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 561/4000 [02:42<22:27,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 563/4000 [02:43<16:48,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 564/4000 [02:43<16:30,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 565/4000 [02:44<24:39,  2.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 566/4000 [02:44<21:29,  2.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 569/4000 [02:44<12:34,  4.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 570/4000 [02:44<12:26,  4.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 571/4000 [02:45<12:51,  4.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 574/4000 [02:45<09:34,  5.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 577/4000 [02:45<07:30,  7.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 579/4000 [02:45<07:03,  8.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 583/4000 [02:46<05:59,  9.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 584/4000 [02:46<08:32,  6.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 586/4000 [02:46<07:01,  8.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 588/4000 [02:47<07:49,  7.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 591/4000 [02:47<06:57,  8.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 594/4000 [02:47<05:47,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 596/4000 [02:48<07:23,  7.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 598/4000 [02:48<12:06,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 599/4000 [02:49<11:45,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 600/4000 [02:49<12:22,  4.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 601/4000 [02:50<21:22,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 602/4000 [02:51<26:12,  2.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 603/4000 [02:51<24:55,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 606/4000 [02:51<15:40,  3.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 607/4000 [02:52<18:46,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 609/4000 [02:52<14:22,  3.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 611/4000 [02:53<17:23,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 612/4000 [02:54<25:20,  2.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 613/4000 [02:56<43:24,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 614/4000 [02:56<35:50,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 615/4000 [02:56<30:19,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 617/4000 [02:56<18:47,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 618/4000 [02:57<17:04,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 619/4000 [02:57<14:14,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 621/4000 [02:57<12:23,  4.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 622/4000 [02:57<11:17,  4.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 623/4000 [02:58<15:19,  3.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 624/4000 [02:58<14:18,  3.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 625/4000 [02:58<12:06,  4.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 626/4000 [02:58<12:02,  4.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 627/4000 [02:58<10:44,  5.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 628/4000 [02:59<11:02,  5.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 630/4000 [02:59<12:02,  4.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 631/4000 [02:59<13:04,  4.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 632/4000 [03:00<16:23,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 634/4000 [03:00<11:09,  5.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 635/4000 [03:00<12:02,  4.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 636/4000 [03:01<14:04,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 637/4000 [03:01<18:24,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 638/4000 [03:01<17:25,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 639/4000 [03:02<17:19,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 641/4000 [03:02<11:36,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 642/4000 [03:02<10:33,  5.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 643/4000 [03:03<18:59,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 645/4000 [03:03<13:53,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 647/4000 [03:03<10:53,  5.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 648/4000 [03:03<10:23,  5.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 649/4000 [03:04<13:23,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 651/4000 [03:04<11:47,  4.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 652/4000 [03:04<10:38,  5.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 653/4000 [03:05<15:39,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 654/4000 [03:05<13:31,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 655/4000 [03:06<20:02,  2.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 657/4000 [03:07<23:27,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 658/4000 [03:07<20:34,  2.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 660/4000 [03:07<13:47,  4.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 661/4000 [03:07<13:19,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 662/4000 [03:08<18:13,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 663/4000 [03:08<16:02,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 664/4000 [03:09<19:40,  2.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 665/4000 [03:09<16:18,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 666/4000 [03:09<16:00,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 668/4000 [03:09<10:20,  5.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 669/4000 [03:09<10:16,  5.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 670/4000 [03:10<15:50,  3.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 671/4000 [03:10<18:40,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 672/4000 [03:11<25:55,  2.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 675/4000 [03:11<13:38,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 677/4000 [03:12<13:14,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 678/4000 [03:12<14:59,  3.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 680/4000 [03:13<13:59,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 682/4000 [03:13<10:49,  5.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 683/4000 [03:13<11:11,  4.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 684/4000 [03:13<12:38,  4.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 686/4000 [03:13<09:05,  6.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 687/4000 [03:14<12:07,  4.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 691/4000 [03:14<09:14,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 694/4000 [03:16<18:26,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 695/4000 [03:16<17:25,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 696/4000 [03:17<17:08,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 697/4000 [03:17<16:56,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 698/4000 [03:17<16:33,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 700/4000 [03:18<15:06,  3.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 701/4000 [03:18<16:58,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 702/4000 [03:19<19:04,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 703/4000 [03:19<18:01,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 704/4000 [03:19<14:58,  3.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 705/4000 [03:20<19:20,  2.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 706/4000 [03:20<16:47,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 710/4000 [03:21<16:52,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 711/4000 [03:21<18:26,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 713/4000 [03:22<15:12,  3.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 714/4000 [03:22<18:39,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 715/4000 [03:23<17:25,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 717/4000 [03:23<14:43,  3.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 719/4000 [03:23<13:31,  4.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 720/4000 [03:24<12:18,  4.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 721/4000 [03:24<16:21,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 723/4000 [03:25<15:11,  3.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 724/4000 [03:25<15:32,  3.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 726/4000 [03:26<18:43,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 730/4000 [03:26<11:18,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 732/4000 [03:26<10:25,  5.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 734/4000 [03:27<09:08,  5.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 735/4000 [03:27<13:09,  4.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 737/4000 [03:27<09:50,  5.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 739/4000 [03:28<08:44,  6.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 740/4000 [03:28<08:29,  6.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 741/4000 [03:29<17:34,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 742/4000 [03:29<16:10,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 745/4000 [03:29<09:40,  5.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 746/4000 [03:30<22:18,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 747/4000 [03:31<20:33,  2.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 751/4000 [03:31<09:59,  5.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 755/4000 [03:31<08:39,  6.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 757/4000 [03:33<14:46,  3.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 758/4000 [03:34<22:56,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 760/4000 [03:34<17:23,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 762/4000 [03:34<14:01,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 763/4000 [03:35<17:54,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 765/4000 [03:35<14:35,  3.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 766/4000 [03:36<17:16,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 767/4000 [03:36<16:45,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 769/4000 [03:37<17:21,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 772/4000 [03:37<10:56,  4.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 774/4000 [03:37<11:07,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 776/4000 [03:38<10:57,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 777/4000 [03:38<10:56,  4.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 778/4000 [03:38<10:43,  5.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 779/4000 [03:38<11:01,  4.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 780/4000 [03:39<10:13,  5.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 782/4000 [03:39<08:09,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 783/4000 [03:40<16:50,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 785/4000 [03:40<12:25,  4.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 787/4000 [03:40<10:51,  4.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 789/4000 [03:40<08:12,  6.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 790/4000 [03:41<15:26,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 791/4000 [03:41<14:38,  3.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 792/4000 [03:41<13:19,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 793/4000 [03:42<15:44,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 794/4000 [03:42<20:17,  2.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 797/4000 [03:43<12:21,  4.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 798/4000 [03:44<19:29,  2.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 799/4000 [03:45<26:08,  2.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 800/4000 [03:45<21:44,  2.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 801/4000 [03:45<24:18,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 802/4000 [03:46<23:05,  2.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 804/4000 [03:46<20:20,  2.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 805/4000 [03:47<18:29,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 807/4000 [03:47<12:38,  4.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 808/4000 [03:47<12:02,  4.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 809/4000 [03:47<12:20,  4.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 810/4000 [03:49<30:37,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 811/4000 [03:50<44:36,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 812/4000 [03:51<38:53,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 813/4000 [03:51<32:08,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 814/4000 [03:51<29:47,  1.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 815/4000 [03:52<23:40,  2.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 817/4000 [03:52<19:10,  2.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 819/4000 [03:52<13:40,  3.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 823/4000 [03:53<08:10,  6.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 825/4000 [03:53<06:51,  7.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 828/4000 [03:53<05:07, 10.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 830/4000 [03:53<06:28,  8.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 832/4000 [03:53<06:10,  8.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 834/4000 [03:54<05:34,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 836/4000 [03:54<08:47,  6.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 837/4000 [03:55<09:45,  5.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 838/4000 [03:55<10:27,  5.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 839/4000 [03:57<33:37,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 841/4000 [03:57<24:29,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 842/4000 [03:59<33:34,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 843/4000 [03:59<29:01,  1.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 844/4000 [04:01<42:49,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 846/4000 [04:01<26:03,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 847/4000 [04:01<23:30,  2.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 848/4000 [04:01<21:02,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 851/4000 [04:02<20:08,  2.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 852/4000 [04:03<18:58,  2.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 853/4000 [04:03<16:38,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 855/4000 [04:03<11:17,  4.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 856/4000 [04:03<12:24,  4.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 857/4000 [04:03<11:42,  4.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 860/4000 [04:04<11:38,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 861/4000 [04:04<13:35,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 862/4000 [04:05<13:13,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 864/4000 [04:05<10:57,  4.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 866/4000 [04:05<08:46,  5.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 867/4000 [04:05<09:03,  5.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 869/4000 [04:06<09:15,  5.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 870/4000 [04:07<19:39,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 871/4000 [04:07<16:41,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 872/4000 [04:07<16:19,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 873/4000 [04:07<13:31,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 875/4000 [04:08<10:18,  5.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 876/4000 [04:08<10:52,  4.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 879/4000 [04:08<08:04,  6.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 880/4000 [04:08<07:36,  6.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 882/4000 [04:08<06:59,  7.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 883/4000 [04:09<07:40,  6.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 884/4000 [04:09<09:51,  5.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 886/4000 [04:09<08:44,  5.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 888/4000 [04:09<07:15,  7.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 889/4000 [04:10<11:51,  4.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 891/4000 [04:10<11:26,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 892/4000 [04:11<10:16,  5.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 893/4000 [04:11<12:42,  4.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 895/4000 [04:11<09:53,  5.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 896/4000 [04:11<09:59,  5.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 897/4000 [04:11<08:57,  5.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 899/4000 [04:12<07:07,  7.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▎       | 900/4000 [04:12<07:26,  6.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 902/4000 [04:12<08:49,  5.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 904/4000 [04:12<06:46,  7.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 907/4000 [04:13<06:08,  8.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 908/4000 [04:13<09:58,  5.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 909/4000 [04:13<10:46,  4.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 910/4000 [04:14<09:43,  5.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 912/4000 [04:14<12:47,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 913/4000 [04:15<12:40,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 914/4000 [04:15<11:13,  4.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 916/4000 [04:15<09:25,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 921/4000 [04:15<05:05, 10.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 923/4000 [04:16<08:49,  5.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 924/4000 [04:16<09:52,  5.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 925/4000 [04:16<09:58,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 926/4000 [04:16<09:07,  5.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 927/4000 [04:17<11:27,  4.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 928/4000 [04:17<11:20,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 931/4000 [04:18<16:10,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 932/4000 [04:19<15:59,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 934/4000 [04:19<12:50,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 935/4000 [04:19<11:23,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 938/4000 [04:19<07:10,  7.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 940/4000 [04:20<09:27,  5.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 942/4000 [04:20<09:33,  5.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 943/4000 [04:20<08:51,  5.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 944/4000 [04:21<10:39,  4.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 945/4000 [04:21<10:31,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 946/4000 [04:21<10:12,  4.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 947/4000 [04:21<12:26,  4.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 948/4000 [04:22<13:09,  3.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 949/4000 [04:22<13:34,  3.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 950/4000 [04:22<11:23,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 952/4000 [04:22<08:17,  6.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 955/4000 [04:23<07:06,  7.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 956/4000 [04:23<10:11,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 957/4000 [04:23<10:46,  4.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 959/4000 [04:24<09:31,  5.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 960/4000 [04:24<08:49,  5.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 964/4000 [04:24<05:10,  9.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 966/4000 [04:25<11:25,  4.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 967/4000 [04:25<11:31,  4.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 969/4000 [04:25<08:42,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 971/4000 [04:26<10:30,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 973/4000 [04:26<08:56,  5.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 974/4000 [04:26<09:32,  5.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 976/4000 [04:27<08:36,  5.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 977/4000 [04:27<12:39,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 978/4000 [04:27<12:08,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 979/4000 [04:28<11:10,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 980/4000 [04:28<13:23,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 983/4000 [04:28<10:26,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 984/4000 [04:29<10:45,  4.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 985/4000 [04:29<10:06,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 986/4000 [04:30<18:08,  2.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 987/4000 [04:30<16:13,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 989/4000 [04:30<10:47,  4.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 990/4000 [04:30<10:41,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 992/4000 [04:30<08:08,  6.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 993/4000 [04:31<15:41,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 995/4000 [04:32<12:29,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 996/4000 [04:32<13:27,  3.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 997/4000 [04:32<13:56,  3.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 999/4000 [04:33<13:01,  3.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1001/4000 [04:33<09:47,  5.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1003/4000 [04:33<07:57,  6.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1005/4000 [04:33<06:25,  7.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1007/4000 [04:34<08:53,  5.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1009/4000 [04:34<09:36,  5.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1010/4000 [04:35<14:48,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1011/4000 [04:35<14:51,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1012/4000 [04:36<15:55,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1013/4000 [04:36<13:27,  3.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1015/4000 [04:36<13:25,  3.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1017/4000 [04:37<11:26,  4.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1018/4000 [04:37<11:13,  4.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1021/4000 [04:37<07:53,  6.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1022/4000 [04:37<08:33,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1023/4000 [04:38<17:57,  2.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1024/4000 [04:39<22:17,  2.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1027/4000 [04:39<13:09,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1028/4000 [04:40<16:12,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1030/4000 [04:40<15:20,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1031/4000 [04:41<21:58,  2.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1032/4000 [04:42<22:31,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1034/4000 [04:42<18:16,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1038/4000 [04:43<10:14,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1039/4000 [04:44<15:36,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1043/4000 [04:44<11:12,  4.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1044/4000 [04:44<11:02,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1046/4000 [04:45<09:51,  5.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1047/4000 [04:45<09:11,  5.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1048/4000 [04:45<10:13,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 1049/4000 [04:45<11:45,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 1052/4000 [04:46<08:06,  6.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 1054/4000 [04:46<06:22,  7.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 1057/4000 [04:46<04:27, 10.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 1059/4000 [04:46<04:06, 11.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1062/4000 [04:46<03:40, 13.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1064/4000 [04:47<05:42,  8.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1066/4000 [04:47<08:58,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1067/4000 [04:48<13:47,  3.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1068/4000 [04:48<13:47,  3.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1069/4000 [04:49<18:26,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1070/4000 [04:49<17:55,  2.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1072/4000 [04:50<12:57,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1073/4000 [04:50<11:11,  4.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1074/4000 [04:50<11:49,  4.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1075/4000 [04:50<10:18,  4.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1076/4000 [04:50<10:30,  4.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1079/4000 [04:51<06:40,  7.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1081/4000 [04:51<05:27,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1084/4000 [04:51<06:29,  7.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1085/4000 [04:52<08:05,  6.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1089/4000 [04:52<05:16,  9.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1091/4000 [04:52<05:10,  9.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1093/4000 [04:52<04:48, 10.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1095/4000 [04:52<05:05,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1097/4000 [04:52<04:36, 10.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1099/4000 [04:53<06:54,  7.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1101/4000 [04:54<09:44,  4.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1102/4000 [04:54<10:42,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1104/4000 [04:54<09:02,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1107/4000 [04:54<06:11,  7.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1109/4000 [04:55<05:31,  8.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1111/4000 [04:55<08:13,  5.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1114/4000 [04:55<06:56,  6.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1117/4000 [04:56<06:35,  7.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1118/4000 [04:56<07:25,  6.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1119/4000 [04:56<07:31,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1121/4000 [04:56<06:38,  7.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1122/4000 [04:57<07:55,  6.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1123/4000 [04:57<08:10,  5.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1124/4000 [04:57<08:19,  5.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1126/4000 [04:57<07:15,  6.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1129/4000 [04:58<06:47,  7.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1131/4000 [04:58<07:40,  6.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1132/4000 [04:59<09:26,  5.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1135/4000 [04:59<07:25,  6.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1136/4000 [04:59<07:05,  6.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1138/4000 [04:59<06:57,  6.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1139/4000 [04:59<07:20,  6.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 1142/4000 [05:00<07:50,  6.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 1147/4000 [05:01<07:16,  6.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 1148/4000 [05:01<07:58,  5.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1150/4000 [05:01<06:47,  6.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1151/4000 [05:02<09:28,  5.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1152/4000 [05:02<09:07,  5.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1153/4000 [05:02<09:12,  5.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1156/4000 [05:02<08:46,  5.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1159/4000 [05:03<06:18,  7.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1160/4000 [05:03<07:13,  6.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1161/4000 [05:03<08:01,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1163/4000 [05:03<06:55,  6.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1164/4000 [05:04<08:17,  5.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1167/4000 [05:04<06:58,  6.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1168/4000 [05:04<06:52,  6.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1170/4000 [05:04<05:32,  8.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1171/4000 [05:04<05:26,  8.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1173/4000 [05:05<05:16,  8.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1175/4000 [05:05<06:04,  7.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1177/4000 [05:05<07:20,  6.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 1179/4000 [05:06<08:31,  5.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1181/4000 [05:06<07:26,  6.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1183/4000 [05:07<13:26,  3.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1186/4000 [05:07<08:51,  5.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1189/4000 [05:08<08:17,  5.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1191/4000 [05:08<07:06,  6.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1193/4000 [05:08<06:31,  7.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1195/4000 [05:08<06:35,  7.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1196/4000 [05:08<06:16,  7.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 1198/4000 [05:09<05:51,  7.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1201/4000 [05:09<04:58,  9.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1204/4000 [05:09<05:11,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1205/4000 [05:10<06:02,  7.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1207/4000 [05:10<04:58,  9.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1209/4000 [05:10<07:07,  6.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1210/4000 [05:10<06:57,  6.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1212/4000 [05:10<05:29,  8.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1214/4000 [05:11<05:06,  9.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1216/4000 [05:11<05:33,  8.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1218/4000 [05:12<09:12,  5.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1220/4000 [05:12<08:16,  5.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1222/4000 [05:12<07:15,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1227/4000 [05:12<04:22, 10.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1229/4000 [05:13<05:14,  8.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1231/4000 [05:13<07:39,  6.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1232/4000 [05:13<07:31,  6.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1233/4000 [05:14<10:16,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1235/4000 [05:14<07:42,  5.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1237/4000 [05:14<06:22,  7.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1239/4000 [05:15<07:46,  5.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1242/4000 [05:15<06:15,  7.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1243/4000 [05:15<08:06,  5.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1244/4000 [05:16<08:58,  5.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1245/4000 [05:16<11:22,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1247/4000 [05:16<11:03,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 1249/4000 [05:17<08:01,  5.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 1251/4000 [05:17<06:16,  7.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 1253/4000 [05:17<05:48,  7.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 1255/4000 [05:17<06:22,  7.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 1258/4000 [05:18<06:29,  7.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1260/4000 [05:18<05:34,  8.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1262/4000 [05:18<07:24,  6.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1263/4000 [05:19<09:43,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1264/4000 [05:19<10:00,  4.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1266/4000 [05:19<07:35,  6.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1269/4000 [05:19<05:43,  7.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1270/4000 [05:20<06:25,  7.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1274/4000 [05:20<04:06, 11.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1276/4000 [05:20<04:30, 10.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1278/4000 [05:21<07:16,  6.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1282/4000 [05:21<05:09,  8.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1284/4000 [05:22<08:31,  5.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1287/4000 [05:22<06:44,  6.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1289/4000 [05:23<12:16,  3.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1290/4000 [05:23<11:31,  3.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1291/4000 [05:24<10:24,  4.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1292/4000 [05:24<15:29,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1293/4000 [05:24<13:07,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1296/4000 [05:25<09:40,  4.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1297/4000 [05:25<10:08,  4.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1298/4000 [05:26<15:38,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1299/4000 [05:26<15:59,  2.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1301/4000 [05:27<15:36,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1302/4000 [05:27<14:35,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1303/4000 [05:28<14:23,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1304/4000 [05:28<13:31,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1305/4000 [05:28<14:28,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1306/4000 [05:28<12:52,  3.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1307/4000 [05:29<15:05,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1308/4000 [05:29<15:07,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1310/4000 [05:29<09:39,  4.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1311/4000 [05:30<11:27,  3.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1313/4000 [05:30<10:32,  4.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1315/4000 [05:30<07:35,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1317/4000 [05:30<05:44,  7.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1319/4000 [05:31<07:35,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1321/4000 [05:31<06:27,  6.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1323/4000 [05:31<07:03,  6.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1324/4000 [05:32<06:43,  6.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1325/4000 [05:32<06:54,  6.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1326/4000 [05:32<07:26,  5.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1327/4000 [05:32<07:20,  6.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1328/4000 [05:32<09:39,  4.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1329/4000 [05:33<17:10,  2.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1332/4000 [05:33<08:44,  5.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1334/4000 [05:34<08:21,  5.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1336/4000 [05:35<14:14,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1337/4000 [05:35<13:27,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1339/4000 [05:35<10:01,  4.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 1340/4000 [05:39<43:59,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 1341/4000 [05:40<40:17,  1.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1351/4000 [05:40<10:18,  4.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1361/4000 [05:40<05:09,  8.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1367/4000 [05:41<04:16, 10.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1371/4000 [05:41<05:09,  8.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1374/4000 [05:42<05:06,  8.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1377/4000 [05:43<08:45,  4.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1379/4000 [05:44<08:49,  4.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1381/4000 [05:44<09:12,  4.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1383/4000 [05:45<10:30,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1385/4000 [05:45<11:28,  3.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1386/4000 [05:46<11:19,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1387/4000 [05:46<12:35,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1388/4000 [05:46<11:44,  3.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1389/4000 [05:46<10:20,  4.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1392/4000 [05:47<08:03,  5.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1393/4000 [05:47<09:14,  4.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1394/4000 [05:47<09:34,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1396/4000 [05:48<09:51,  4.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1397/4000 [05:48<09:34,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 1399/4000 [05:49<09:57,  4.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1400/4000 [05:49<09:00,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1403/4000 [05:50<10:29,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1405/4000 [05:50<12:36,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1406/4000 [05:51<13:56,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1408/4000 [05:51<10:02,  4.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1410/4000 [05:51<07:57,  5.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1411/4000 [05:51<09:04,  4.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1412/4000 [05:51<08:08,  5.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1413/4000 [05:52<07:39,  5.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1415/4000 [05:52<08:59,  4.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1417/4000 [05:52<06:58,  6.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 1418/4000 [05:53<08:02,  5.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1420/4000 [05:53<06:49,  6.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1421/4000 [05:53<08:10,  5.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1424/4000 [05:53<06:43,  6.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1426/4000 [05:54<05:31,  7.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1428/4000 [05:54<05:27,  7.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1434/4000 [05:54<02:48, 15.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1437/4000 [05:55<04:31,  9.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1439/4000 [05:55<05:25,  7.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1441/4000 [05:56<10:46,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1442/4000 [05:56<09:56,  4.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1446/4000 [05:57<07:07,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1448/4000 [05:57<06:29,  6.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 1452/4000 [05:57<04:52,  8.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 1455/4000 [05:57<04:06, 10.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 1457/4000 [05:58<04:22,  9.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 1459/4000 [05:58<04:04, 10.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1461/4000 [05:58<04:24,  9.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1463/4000 [05:58<04:35,  9.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1465/4000 [05:59<05:06,  8.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1467/4000 [05:59<04:49,  8.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1468/4000 [05:59<08:05,  5.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1471/4000 [06:00<05:24,  7.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1473/4000 [06:00<05:28,  7.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1475/4000 [06:00<06:40,  6.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1476/4000 [06:00<07:10,  5.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1478/4000 [06:01<06:17,  6.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1479/4000 [06:01<09:04,  4.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1480/4000 [06:01<09:23,  4.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1481/4000 [06:02<12:39,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1483/4000 [06:02<09:12,  4.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1484/4000 [06:03<14:14,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1487/4000 [06:03<10:19,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1488/4000 [06:04<10:03,  4.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1489/4000 [06:04<11:58,  3.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1490/4000 [06:04<10:53,  3.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1492/4000 [06:05<08:53,  4.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1493/4000 [06:05<09:21,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1495/4000 [06:05<07:14,  5.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1497/4000 [06:05<07:12,  5.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 1499/4000 [06:06<07:05,  5.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1501/4000 [06:06<06:10,  6.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1503/4000 [06:06<04:53,  8.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1505/4000 [06:07<12:06,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1506/4000 [06:08<12:53,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1507/4000 [06:08<11:29,  3.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1508/4000 [06:08<12:21,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1510/4000 [06:08<09:02,  4.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1511/4000 [06:09<11:27,  3.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1515/4000 [06:09<06:06,  6.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1517/4000 [06:09<05:45,  7.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1519/4000 [06:10<05:34,  7.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1521/4000 [06:10<06:39,  6.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1522/4000 [06:10<06:47,  6.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1524/4000 [06:11<07:37,  5.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1525/4000 [06:11<09:24,  4.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1528/4000 [06:11<06:13,  6.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1531/4000 [06:12<06:28,  6.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1532/4000 [06:12<06:10,  6.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1533/4000 [06:12<05:49,  7.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1534/4000 [06:12<08:26,  4.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1536/4000 [06:13<07:43,  5.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1537/4000 [06:13<07:02,  5.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1539/4000 [06:13<08:57,  4.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1540/4000 [06:14<14:25,  2.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 1542/4000 [06:15<11:38,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 1543/4000 [06:15<10:29,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 1544/4000 [06:15<09:10,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 1545/4000 [06:15<08:06,  5.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 1547/4000 [06:15<06:04,  6.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 1548/4000 [06:15<07:10,  5.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1550/4000 [06:16<05:25,  7.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1553/4000 [06:16<05:57,  6.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1554/4000 [06:16<06:47,  6.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1555/4000 [06:16<06:58,  5.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1557/4000 [06:17<09:08,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1559/4000 [06:17<07:00,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1561/4000 [06:18<08:00,  5.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1562/4000 [06:19<12:49,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1563/4000 [06:19<11:14,  3.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1566/4000 [06:19<07:42,  5.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1568/4000 [06:19<06:28,  6.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1572/4000 [06:19<04:51,  8.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1573/4000 [06:20<08:34,  4.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1575/4000 [06:21<08:29,  4.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1576/4000 [06:21<09:31,  4.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1577/4000 [06:21<09:04,  4.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1580/4000 [06:21<06:27,  6.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1581/4000 [06:22<11:07,  3.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1582/4000 [06:23<11:42,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1583/4000 [06:23<11:27,  3.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1585/4000 [06:23<11:18,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1587/4000 [06:24<08:51,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1589/4000 [06:24<07:59,  5.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1590/4000 [06:24<08:39,  4.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1592/4000 [06:25<07:37,  5.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1593/4000 [06:26<14:54,  2.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1595/4000 [06:26<12:07,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1596/4000 [06:26<13:14,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1597/4000 [06:27<11:12,  3.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1598/4000 [06:27<10:35,  3.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1599/4000 [06:27<09:03,  4.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1601/4000 [06:27<09:45,  4.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1602/4000 [06:28<09:24,  4.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1603/4000 [06:28<09:43,  4.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1604/4000 [06:28<08:41,  4.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1605/4000 [06:29<12:06,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1606/4000 [06:29<11:08,  3.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1609/4000 [06:29<05:53,  6.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1611/4000 [06:29<07:16,  5.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1612/4000 [06:29<06:39,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1613/4000 [06:30<10:17,  3.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1615/4000 [06:31<09:56,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1617/4000 [06:31<07:34,  5.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1618/4000 [06:31<07:15,  5.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 1620/4000 [06:31<06:24,  6.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1621/4000 [06:32<08:58,  4.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1623/4000 [06:32<10:54,  3.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1626/4000 [06:33<07:41,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1628/4000 [06:33<06:25,  6.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1630/4000 [06:33<05:24,  7.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1631/4000 [06:33<07:04,  5.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1632/4000 [06:34<08:47,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1633/4000 [06:34<13:00,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1635/4000 [06:35<09:10,  4.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1637/4000 [06:35<08:40,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1638/4000 [06:35<09:24,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1639/4000 [06:36<10:02,  3.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1640/4000 [06:36<09:37,  4.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1642/4000 [06:36<07:45,  5.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1644/4000 [06:36<06:11,  6.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1645/4000 [06:36<07:14,  5.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1648/4000 [06:37<05:19,  7.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1649/4000 [06:37<05:43,  6.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 1650/4000 [06:37<07:28,  5.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 1651/4000 [06:38<08:49,  4.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 1653/4000 [06:41<35:20,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 1656/4000 [06:43<25:10,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1661/4000 [06:43<13:09,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1666/4000 [06:43<07:51,  4.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1672/4000 [06:43<04:49,  8.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1676/4000 [06:43<04:44,  8.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1680/4000 [06:44<03:42, 10.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1685/4000 [06:44<04:20,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1688/4000 [06:45<05:39,  6.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1690/4000 [06:46<06:59,  5.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1692/4000 [06:47<08:20,  4.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1693/4000 [06:47<07:55,  4.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1694/4000 [06:47<07:43,  4.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1695/4000 [06:48<11:41,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1697/4000 [06:48<09:50,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1698/4000 [06:48<09:47,  3.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 1699/4000 [06:48<09:26,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▎     | 1700/4000 [06:49<10:15,  3.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1702/4000 [06:49<07:02,  5.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1703/4000 [06:49<08:18,  4.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1705/4000 [06:50<09:33,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1706/4000 [06:50<10:42,  3.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1707/4000 [06:51<13:20,  2.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1709/4000 [06:52<16:21,  2.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1710/4000 [06:52<15:41,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1711/4000 [06:53<17:41,  2.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1712/4000 [06:53<15:56,  2.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1713/4000 [06:54<16:49,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1714/4000 [06:54<13:35,  2.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1715/4000 [06:54<11:00,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1716/4000 [06:54<09:00,  4.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1718/4000 [06:54<06:04,  6.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1720/4000 [06:54<06:43,  5.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1722/4000 [06:55<05:34,  6.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1723/4000 [06:55<05:32,  6.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1724/4000 [06:56<10:33,  3.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1725/4000 [06:56<10:57,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1726/4000 [06:56<09:11,  4.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1728/4000 [06:57<10:54,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1729/4000 [06:57<13:13,  2.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1730/4000 [06:57<11:30,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1732/4000 [06:58<08:35,  4.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1733/4000 [06:58<12:34,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1735/4000 [06:59<11:50,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1736/4000 [06:59<10:26,  3.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1737/4000 [07:00<13:49,  2.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1738/4000 [07:00<13:40,  2.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1739/4000 [07:00<12:09,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 1741/4000 [07:00<07:43,  4.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 1742/4000 [07:01<11:29,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 1743/4000 [07:01<12:25,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 1744/4000 [07:02<13:44,  2.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 1746/4000 [07:02<09:14,  4.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 1749/4000 [07:02<05:36,  6.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1751/4000 [07:02<04:45,  7.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1753/4000 [07:03<05:33,  6.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1754/4000 [07:03<07:00,  5.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1755/4000 [07:03<06:24,  5.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1756/4000 [07:03<06:44,  5.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1758/4000 [07:04<04:59,  7.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1760/4000 [07:04<08:51,  4.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1761/4000 [07:05<13:12,  2.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1763/4000 [07:05<09:06,  4.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1764/4000 [07:06<11:21,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1765/4000 [07:06<11:37,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1767/4000 [07:06<08:05,  4.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1769/4000 [07:07<06:47,  5.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1770/4000 [07:07<10:45,  3.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1771/4000 [07:08<12:01,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1774/4000 [07:08<07:55,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1775/4000 [07:08<09:48,  3.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1777/4000 [07:09<08:18,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1779/4000 [07:09<06:21,  5.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1781/4000 [07:09<05:55,  6.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1782/4000 [07:09<05:49,  6.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1784/4000 [07:10<07:18,  5.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1785/4000 [07:10<06:44,  5.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1786/4000 [07:10<06:55,  5.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1788/4000 [07:10<05:47,  6.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1789/4000 [07:11<06:14,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1790/4000 [07:11<11:56,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1792/4000 [07:12<08:42,  4.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1793/4000 [07:12<08:31,  4.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1795/4000 [07:12<06:07,  5.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 1798/4000 [07:12<04:34,  8.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1800/4000 [07:13<06:44,  5.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1801/4000 [07:13<07:56,  4.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1802/4000 [07:14<08:17,  4.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1804/4000 [07:14<06:12,  5.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1805/4000 [07:14<07:20,  4.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1806/4000 [07:14<08:06,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1807/4000 [07:14<07:50,  4.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1808/4000 [07:15<08:11,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1809/4000 [07:15<08:39,  4.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1811/4000 [07:15<05:47,  6.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1812/4000 [07:15<05:22,  6.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1813/4000 [07:16<07:46,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1814/4000 [07:16<07:13,  5.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1815/4000 [07:16<08:50,  4.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1816/4000 [07:16<08:50,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1818/4000 [07:17<06:36,  5.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 1819/4000 [07:17<06:22,  5.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1821/4000 [07:17<06:20,  5.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1823/4000 [07:17<04:41,  7.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1825/4000 [07:17<03:42,  9.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1827/4000 [07:17<03:31, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1829/4000 [07:18<05:41,  6.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1830/4000 [07:18<06:23,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1831/4000 [07:19<06:55,  5.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1832/4000 [07:19<06:51,  5.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1836/4000 [07:19<04:24,  8.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1838/4000 [07:19<04:29,  8.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1839/4000 [07:19<04:33,  7.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1840/4000 [07:20<09:32,  3.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1841/4000 [07:20<08:30,  4.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1842/4000 [07:21<13:17,  2.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1843/4000 [07:21<11:18,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1844/4000 [07:22<10:23,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 1847/4000 [07:22<07:37,  4.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 1851/4000 [07:22<04:45,  7.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 1852/4000 [07:22<05:11,  6.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 1853/4000 [07:23<05:34,  6.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 1854/4000 [07:23<09:49,  3.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 1855/4000 [07:24<10:06,  3.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 1858/4000 [07:24<07:47,  4.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1862/4000 [07:25<05:49,  6.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1863/4000 [07:25<07:18,  4.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1864/4000 [07:26<10:04,  3.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1866/4000 [07:26<09:50,  3.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1867/4000 [07:26<08:40,  4.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1868/4000 [07:26<07:34,  4.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1869/4000 [07:27<11:22,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1871/4000 [07:27<08:11,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1872/4000 [07:27<07:52,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1873/4000 [07:28<09:59,  3.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1874/4000 [07:28<08:45,  4.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1876/4000 [07:28<06:00,  5.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1877/4000 [07:29<10:43,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1880/4000 [07:29<06:44,  5.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1881/4000 [07:29<06:58,  5.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1882/4000 [07:30<09:52,  3.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1883/4000 [07:30<09:03,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1885/4000 [07:31<09:52,  3.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1886/4000 [07:31<09:19,  3.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1887/4000 [07:32<14:34,  2.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1888/4000 [07:32<11:51,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1889/4000 [07:32<10:24,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1890/4000 [07:33<12:44,  2.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1891/4000 [07:34<17:54,  1.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1893/4000 [07:34<13:08,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1894/4000 [07:35<14:30,  2.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1896/4000 [07:35<11:01,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1897/4000 [07:35<09:54,  3.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 1898/4000 [07:36<12:50,  2.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1900/4000 [07:36<09:09,  3.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1901/4000 [07:36<08:59,  3.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1904/4000 [07:36<05:51,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1905/4000 [07:36<05:30,  6.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1906/4000 [07:37<06:10,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1908/4000 [07:37<06:23,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1909/4000 [07:37<07:06,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1912/4000 [07:38<04:17,  8.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1914/4000 [07:38<05:03,  6.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1916/4000 [07:39<10:03,  3.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1917/4000 [07:40<12:13,  2.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1919/4000 [07:40<09:09,  3.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1921/4000 [07:41<09:27,  3.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1922/4000 [07:41<08:32,  4.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1923/4000 [07:41<08:18,  4.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1924/4000 [07:41<09:47,  3.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1925/4000 [07:41<08:17,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1926/4000 [07:42<07:10,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1927/4000 [07:42<07:40,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1929/4000 [07:42<05:09,  6.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1933/4000 [07:42<03:06, 11.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1935/4000 [07:43<04:53,  7.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1937/4000 [07:43<06:29,  5.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 1939/4000 [07:43<05:13,  6.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 1941/4000 [07:44<07:13,  4.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 1943/4000 [07:48<24:42,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 1947/4000 [07:49<16:43,  2.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1951/4000 [07:49<10:26,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1953/4000 [07:49<09:15,  3.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1958/4000 [07:49<05:28,  6.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1961/4000 [07:49<04:20,  7.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1965/4000 [07:50<03:25,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1969/4000 [07:50<02:34, 13.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1972/4000 [07:50<03:30,  9.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1975/4000 [07:52<06:33,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1977/4000 [07:55<17:37,  1.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 1979/4000 [07:56<16:42,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1980/4000 [07:56<15:49,  2.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1981/4000 [07:57<18:53,  1.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1982/4000 [07:58<17:37,  1.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1983/4000 [07:58<14:38,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1984/4000 [07:58<12:05,  2.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1985/4000 [07:58<09:54,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1986/4000 [07:59<14:05,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1987/4000 [07:59<12:26,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1989/4000 [07:59<08:10,  4.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1990/4000 [07:59<07:36,  4.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1992/4000 [08:00<08:01,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1994/4000 [08:00<07:40,  4.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1995/4000 [08:01<08:19,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1996/4000 [08:01<07:13,  4.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1997/4000 [08:01<06:22,  5.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 1998/4000 [08:01<08:12,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2001/4000 [08:02<05:47,  5.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2002/4000 [08:02<07:08,  4.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2004/4000 [08:02<06:10,  5.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2006/4000 [08:02<05:19,  6.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2007/4000 [08:03<05:51,  5.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2008/4000 [08:03<05:20,  6.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2009/4000 [08:03<05:02,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2011/4000 [08:03<06:01,  5.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2012/4000 [08:04<09:39,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2014/4000 [08:05<10:01,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2015/4000 [08:05<08:34,  3.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2016/4000 [08:05<10:55,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2017/4000 [08:06<11:03,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2018/4000 [08:06<09:21,  3.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2019/4000 [08:06<08:36,  3.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 2020/4000 [08:06<10:12,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2021/4000 [08:07<10:06,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2022/4000 [08:07<09:32,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2023/4000 [08:08<13:07,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2024/4000 [08:08<13:08,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2026/4000 [08:08<08:38,  3.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2027/4000 [08:09<11:31,  2.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2028/4000 [08:09<09:49,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2029/4000 [08:09<09:36,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2030/4000 [08:10<12:16,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2031/4000 [08:10<10:49,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2032/4000 [08:10<10:49,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2033/4000 [08:11<09:04,  3.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2034/4000 [08:11<08:53,  3.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2036/4000 [08:11<07:23,  4.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2038/4000 [08:11<06:11,  5.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2041/4000 [08:12<06:58,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2043/4000 [08:12<05:44,  5.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2044/4000 [08:13<05:44,  5.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2046/4000 [08:13<04:50,  6.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2047/4000 [08:13<07:48,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2048/4000 [08:14<10:30,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 2050/4000 [08:14<08:31,  3.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 2051/4000 [08:15<08:40,  3.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 2052/4000 [08:15<08:26,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 2056/4000 [08:16<07:47,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 2058/4000 [08:16<06:33,  4.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 2059/4000 [08:16<06:21,  5.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2060/4000 [08:17<07:47,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2061/4000 [08:17<07:02,  4.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2062/4000 [08:17<08:07,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2063/4000 [08:17<09:30,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2064/4000 [08:18<09:10,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2065/4000 [08:18<11:17,  2.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2066/4000 [08:19<10:51,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2067/4000 [08:19<12:29,  2.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2068/4000 [08:20<15:55,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2069/4000 [08:20<16:06,  2.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2070/4000 [08:20<13:07,  2.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2072/4000 [08:21<13:12,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2073/4000 [08:22<13:57,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2074/4000 [08:22<12:16,  2.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2076/4000 [08:22<07:57,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2078/4000 [08:23<10:18,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2079/4000 [08:23<10:36,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2080/4000 [08:24<09:52,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2081/4000 [08:24<08:16,  3.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2083/4000 [08:24<05:41,  5.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2086/4000 [08:24<03:38,  8.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2089/4000 [08:24<03:05, 10.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2092/4000 [08:25<03:02, 10.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2095/4000 [08:25<02:59, 10.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2097/4000 [08:25<03:17,  9.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 2099/4000 [08:25<03:05, 10.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2101/4000 [08:26<05:35,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2102/4000 [08:27<07:17,  4.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2103/4000 [08:27<07:04,  4.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2104/4000 [08:27<07:05,  4.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2105/4000 [08:27<06:17,  5.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2107/4000 [08:27<04:49,  6.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2108/4000 [08:27<04:30,  6.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2109/4000 [08:28<08:53,  3.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2110/4000 [08:28<08:39,  3.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2112/4000 [08:29<09:23,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2113/4000 [08:29<09:43,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2114/4000 [08:30<09:20,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2116/4000 [08:31<12:25,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2118/4000 [08:31<08:54,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2120/4000 [08:31<06:41,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2121/4000 [08:31<06:57,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2122/4000 [08:31<06:28,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2123/4000 [08:32<07:28,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2124/4000 [08:32<07:27,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2125/4000 [08:32<09:06,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2126/4000 [08:33<08:05,  3.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2129/4000 [08:33<05:32,  5.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2131/4000 [08:33<04:30,  6.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2132/4000 [08:33<04:27,  6.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2133/4000 [08:34<07:31,  4.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2134/4000 [08:34<06:40,  4.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2135/4000 [08:35<10:18,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2137/4000 [08:35<06:54,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2138/4000 [08:35<06:40,  4.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2139/4000 [08:36<09:12,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 2142/4000 [08:36<06:32,  4.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 2143/4000 [08:36<06:44,  4.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 2146/4000 [08:36<04:10,  7.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 2148/4000 [08:37<06:38,  4.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 2149/4000 [08:37<06:44,  4.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2151/4000 [08:38<08:53,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2152/4000 [08:38<08:26,  3.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2153/4000 [08:39<07:41,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2155/4000 [08:39<05:22,  5.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2156/4000 [08:39<05:08,  5.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2157/4000 [08:39<05:00,  6.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2158/4000 [08:39<05:02,  6.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2159/4000 [08:39<04:50,  6.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2160/4000 [08:40<08:34,  3.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2163/4000 [08:40<05:19,  5.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2164/4000 [08:40<05:13,  5.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2165/4000 [08:40<05:20,  5.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2166/4000 [08:41<07:05,  4.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2168/4000 [08:41<04:49,  6.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2170/4000 [08:41<06:09,  4.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2171/4000 [08:42<07:08,  4.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2172/4000 [08:44<18:38,  1.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2175/4000 [08:45<13:50,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2176/4000 [08:45<15:33,  1.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2177/4000 [08:46<15:11,  2.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2178/4000 [08:46<13:51,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 2179/4000 [08:46<11:14,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2180/4000 [08:46<09:34,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2182/4000 [08:47<06:18,  4.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2186/4000 [08:47<03:18,  9.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2188/4000 [08:47<03:21,  8.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2190/4000 [08:47<04:12,  7.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2192/4000 [08:48<04:07,  7.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2194/4000 [08:48<04:16,  7.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2197/4000 [08:48<03:09,  9.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2199/4000 [08:48<03:08,  9.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2201/4000 [08:48<02:43, 11.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2203/4000 [08:49<02:45, 10.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2205/4000 [08:49<04:28,  6.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2207/4000 [08:49<04:51,  6.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2208/4000 [08:50<04:35,  6.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2209/4000 [08:50<05:23,  5.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2211/4000 [08:50<04:17,  6.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2212/4000 [08:50<05:13,  5.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2213/4000 [08:51<05:35,  5.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2216/4000 [08:51<03:43,  7.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2217/4000 [08:51<03:57,  7.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2218/4000 [08:51<03:52,  7.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 2219/4000 [08:51<04:41,  6.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2220/4000 [08:52<06:31,  4.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2221/4000 [08:53<14:26,  2.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2223/4000 [08:54<12:47,  2.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2224/4000 [08:54<11:53,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2225/4000 [08:54<09:45,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2226/4000 [08:54<08:47,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2228/4000 [08:54<05:56,  4.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2229/4000 [08:55<08:06,  3.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2231/4000 [08:56<10:11,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2233/4000 [08:56<07:34,  3.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2234/4000 [08:56<07:03,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2236/4000 [08:57<10:11,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2237/4000 [08:57<09:15,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2238/4000 [08:58<09:22,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2239/4000 [08:58<09:44,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2241/4000 [08:59<08:53,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2243/4000 [08:59<09:06,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2244/4000 [09:00<08:18,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2245/4000 [09:00<07:15,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2248/4000 [09:01<11:48,  2.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2249/4000 [09:02<13:31,  2.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2250/4000 [09:03<17:21,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2251/4000 [09:04<17:19,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2252/4000 [09:04<15:47,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2253/4000 [09:05<16:32,  1.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2255/4000 [09:05<10:13,  2.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2256/4000 [09:05<10:38,  2.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2257/4000 [09:05<08:46,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2258/4000 [09:06<07:58,  3.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 2260/4000 [09:06<05:17,  5.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2261/4000 [09:06<04:58,  5.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2262/4000 [09:06<07:23,  3.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2263/4000 [09:07<07:26,  3.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2266/4000 [09:07<05:59,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2267/4000 [09:07<06:41,  4.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2269/4000 [09:08<05:57,  4.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2271/4000 [09:09<07:44,  3.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2272/4000 [09:09<06:52,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2274/4000 [09:09<05:14,  5.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2275/4000 [09:09<04:48,  5.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2277/4000 [09:09<03:48,  7.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2279/4000 [09:09<03:08,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2281/4000 [09:10<05:23,  5.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2282/4000 [09:10<05:01,  5.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2284/4000 [09:10<03:58,  7.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2286/4000 [09:11<06:50,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2287/4000 [09:11<06:27,  4.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2288/4000 [09:11<05:49,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2289/4000 [09:12<05:42,  5.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2290/4000 [09:12<05:03,  5.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2292/4000 [09:12<03:47,  7.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2293/4000 [09:12<04:55,  5.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2294/4000 [09:12<04:25,  6.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2296/4000 [09:12<03:46,  7.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2297/4000 [09:13<04:56,  5.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 2299/4000 [09:13<04:42,  6.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▊    | 2300/4000 [09:13<05:04,  5.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2302/4000 [09:14<04:52,  5.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2303/4000 [09:14<04:52,  5.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2304/4000 [09:14<05:31,  5.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2305/4000 [09:15<08:13,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2306/4000 [09:15<07:50,  3.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2307/4000 [09:16<11:41,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2308/4000 [09:16<10:26,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2310/4000 [09:16<06:27,  4.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2312/4000 [09:16<05:09,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2313/4000 [09:17<08:49,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2314/4000 [09:17<08:01,  3.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2315/4000 [09:17<07:37,  3.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2317/4000 [09:18<06:27,  4.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2319/4000 [09:18<05:01,  5.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2320/4000 [09:19<09:09,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2322/4000 [09:19<07:32,  3.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2324/4000 [09:19<05:25,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2325/4000 [09:19<05:12,  5.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2327/4000 [09:20<03:54,  7.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2329/4000 [09:20<03:56,  7.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2331/4000 [09:20<05:24,  5.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2334/4000 [09:21<04:17,  6.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2335/4000 [09:22<07:29,  3.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2337/4000 [09:22<05:33,  4.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2339/4000 [09:22<05:05,  5.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2340/4000 [09:22<05:14,  5.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 2343/4000 [09:22<03:54,  7.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 2344/4000 [09:23<04:29,  6.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 2345/4000 [09:23<04:48,  5.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 2346/4000 [09:23<04:44,  5.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 2347/4000 [09:23<04:39,  5.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 2349/4000 [09:24<07:43,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2350/4000 [09:24<06:50,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2353/4000 [09:24<04:14,  6.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2355/4000 [09:25<06:17,  4.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2356/4000 [09:26<08:19,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2358/4000 [09:26<06:17,  4.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2359/4000 [09:26<06:31,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2361/4000 [09:26<04:47,  5.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2362/4000 [09:27<04:45,  5.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2363/4000 [09:27<05:41,  4.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2364/4000 [09:27<05:54,  4.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2366/4000 [09:27<04:19,  6.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2367/4000 [09:27<04:14,  6.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2369/4000 [09:28<04:10,  6.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2371/4000 [09:28<04:25,  6.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2372/4000 [09:28<04:13,  6.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2375/4000 [09:29<03:16,  8.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2376/4000 [09:29<03:14,  8.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2378/4000 [09:29<02:57,  9.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2380/4000 [09:29<02:52,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2381/4000 [09:29<03:04,  8.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2382/4000 [09:29<03:09,  8.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2383/4000 [09:30<04:21,  6.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2384/4000 [09:30<04:56,  5.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2385/4000 [09:30<06:27,  4.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2387/4000 [09:31<09:12,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2388/4000 [09:32<10:03,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2389/4000 [09:32<09:02,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 2390/4000 [09:32<07:24,  3.62it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='lamapi.hel.sintef.cloud', port=443): Max retries exceeded with url: /lookup/entity-retrieval?name=Mark+Maguyre&token=lamapi_demo_2023&kg=wikidata&limit=1000&query=%7B%22query%22%3A+%7B%22bool%22%3A+%7B%22must%22%3A+%5B%7B%22match%22%3A+%7B%22name%22%3A+%7B%22query%22%3A+%22Mark+Maguyre%22%2C+%22boost%22%3A+2.0%2C+%22fuzziness%22%3A+%22AUTO%22%7D%7D%7D%5D%7D%7D%7D&sort=%7B%22popularity%22%3A+%7B%22order%22%3A+%22desc%22%7D%7D (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f126507c3d0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:492\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    491\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 492\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1097\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1097\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:218\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f126507c3d0>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='lamapi.hel.sintef.cloud', port=443): Max retries exceeded with url: /lookup/entity-retrieval?name=Mark+Maguyre&token=lamapi_demo_2023&kg=wikidata&limit=1000&query=%7B%22query%22%3A+%7B%22bool%22%3A+%7B%22must%22%3A+%5B%7B%22match%22%3A+%7B%22name%22%3A+%7B%22query%22%3A+%22Mark+Maguyre%22%2C+%22boost%22%3A+2.0%2C+%22fuzziness%22%3A+%22AUTO%22%7D%7D%7D%5D%7D%7D%7D&sort=%7B%22popularity%22%3A+%7B%22order%22%3A+%22desc%22%7D%7D (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f126507c3d0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(queries))\n\u001b[0;32m---> 98\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:  \u001b[38;5;66;03m# For environments like Jupyter\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:31\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     29\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nest_asyncio.py:99\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[17], line 70\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(queries, url, pbar)\u001b[0m\n\u001b[1;32m     67\u001b[0m name \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     68\u001b[0m param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboost\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: 2.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuzziness\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUTO\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 70\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     72\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='lamapi.hel.sintef.cloud', port=443): Max retries exceeded with url: /lookup/entity-retrieval?name=Mark+Maguyre&token=lamapi_demo_2023&kg=wikidata&limit=1000&query=%7B%22query%22%3A+%7B%22bool%22%3A+%7B%22must%22%3A+%5B%7B%22match%22%3A+%7B%22name%22%3A+%7B%22query%22%3A+%22Mark+Maguyre%22%2C+%22boost%22%3A+2.0%2C+%22fuzziness%22%3A+%22AUTO%22%7D%7D%7D%5D%7D%7D%7D&sort=%7B%22popularity%22%3A+%7B%22order%22%3A+%22desc%22%7D%7D (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f126507c3d0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "## QUERY CORRETTA CON FUZZYYYY\n",
    "\n",
    "url = 'https://lamapi.hel.sintef.cloud/lookup/entity-retrieval'\n",
    "sample_size = 4000\n",
    "queries = random.sample(queries, sample_size)\n",
    "\n",
    "# Backoff decorator for handling retries with exponential backoff\n",
    "@backoff.on_exception(\n",
    "    backoff.expo, \n",
    "    (aiohttp.ClientError, aiohttp.http_exceptions.HttpProcessingError, asyncio.TimeoutError), \n",
    "    max_tries=5, \n",
    "    max_time=300\n",
    ")\n",
    "async def fetch(session, url, params, headers, semaphore):\n",
    "    async with semaphore:\n",
    "        async with session.get(url, params=params, headers=headers, timeout=30) as response:\n",
    "            try:\n",
    "                response.raise_for_status()  # Raises an exception for 4XX/5XX status codes\n",
    "                return await response.json()\n",
    "            except Exception as e:\n",
    "                return []\n",
    "async def process_item(session, url, id, headers, params, semaphore, pbar):\n",
    "\n",
    "    try:\n",
    "        data = await fetch(session, url, params, headers, semaphore)\n",
    "    except ClientResponseError as e:\n",
    "        if e.status == 404:\n",
    "            print(f\"404 Error: Resource not found for '{name}'\")\n",
    "            pbar.update(1)  # No need to await here\n",
    "            return 0, 0\n",
    "        else:\n",
    "            raise  # Re-raise the exception for other status codes\n",
    "\n",
    "    num_result = len(data) if data else 0\n",
    "\n",
    "    if data:\n",
    "        for item in data:\n",
    "            if id == item.get('id'):\n",
    "                pbar.update(1)  # No need to await here\n",
    "                pos_score = item.get('pos_score', 0)\n",
    "                if pos_score:\n",
    "                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                else:\n",
    "                    mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                return mrr_increment, 1\n",
    "\n",
    "        #print(f\"{name}: {GT_id_match[0]} NOT FOUND in {value[1]}\")\n",
    "        #print(\"___________________________\")\n",
    "        #print(f\"{name} NOT FOUND-->t{item}\")\n",
    "\n",
    "    return 0, 0\n",
    "\n",
    "async def main(queries, url, pbar):\n",
    "    headers = {'accept': 'application/json'}\n",
    "    semaphore = asyncio.Semaphore(50)  # Limit to 50 concurrent requests\n",
    "    m_mrr = 0\n",
    "    cont_el = 0\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for param, id in queries:            \n",
    "            tasks.append(process_item(session, url, id, headers, param, semaphore, pbar))\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for (mrr_increment, count), (param, id) in zip(results, queries):\n",
    "            if mrr_increment == 0 and count == 0:\n",
    "                name = param['name']\n",
    "                param['query'] = f'{{\"query\": {{\"bool\": {{\"must\": [{{\"match\": {{\"name\": {{\"query\": \"{name}\", \"boost\": 2.0, \"fuzziness\": \"AUTO\"}}}}}}]}}}}}}'\n",
    "\n",
    "                response = requests.get(url, params=param)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    #print(\"after call\")\n",
    "                    num_result = len(data) if data else 0\n",
    "                    if data:\n",
    "                        for item in data:\n",
    "                            if id == item.get('id'):\n",
    "                                pbar.update(1)  # No need to await here\n",
    "                                pos_score = item.get('pos_score', 0)\n",
    "                                if pos_score:\n",
    "                                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                                else:\n",
    "                                    mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                            \n",
    "            m_mrr += mrr_increment\n",
    "            cont_el += count\n",
    "\n",
    "        pbar.close()  # No need to await here\n",
    "\n",
    "    print(f\"Coverage of 2T: {cont_el / len(queries)}\")\n",
    "    print(f\"Measure Reciprocal Rank of 2T: {m_mrr / len(queries)}\")\n",
    "\n",
    "# Check if there's already a running event loop\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()  # Apply nest_asyncio\n",
    "    try:\n",
    "        pbar = tqdm(total=len(queries))\n",
    "        asyncio.run(main(queries, url, pbar))\n",
    "    except RuntimeError:  # For environments like Jupyter\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(main(queries, url, pbar))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query\n",
    "Coverage of R4: 0.48625\n",
    "\r\n",
    "Measure Reciprocal Rank of R4: 0.55204350000000288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Round4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/Round4_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    R4_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample extraction\n",
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(R4_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = R4_sorted_mentions[:q1_idx]\n",
    "q2 = R4_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = R4_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = R4_sorted_mentions[q3_idx:]\n",
    "\n",
    "sample_size = 1000\n",
    "R4_sample_keys = []\n",
    "R4_sample_keys = R4_sample_keys + random.sample(q1, sample_size)\n",
    "R4_sample_keys = R4_sample_keys + random.sample(q2, sample_size)\n",
    "R4_sample_keys = R4_sample_keys + random.sample(q3, sample_size)\n",
    "R4_sample_keys = R4_sample_keys + random.sample(q4, sample_size)\n",
    "\n",
    "q_ids = {item[1]['name']: item[1]['id'] for item in R4_sample_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_item_tree_item_idsSPARQL(root_items, forward_properties=None, backward_properties=None):\n",
    "    \"\"\"Return ids of WikiData items, which are in the tree spanned by the given root items and claims relating them\n",
    "        to other items.\n",
    "\n",
    "    :param root_items: iterable[int] One or multiple item entities that are the root elements of the tree\n",
    "    :param forward_properties: iterable[int] | None property-claims to follow forward; that is, if root item R has\n",
    "        a claim P:I, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :param backward_properties: iterable[int] | None property-claims to follow in reverse; that is, if (for a root\n",
    "        item R) an item I has a claim P:R, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :return: iterable[int]: List with ids of WikiData items in the tree\n",
    "    \"\"\"\n",
    "\n",
    "    query = '''PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>'''\n",
    "    if forward_properties:\n",
    "        query +='''SELECT ?WD_id WHERE {\n",
    "                  ?tree0 (wdt:P%s)* ?WD_id .\n",
    "                  BIND (wd:%s AS ?tree0)\n",
    "                  }'''%( ','.join(map(str, forward_properties)),','.join(map(str, root_items)))\n",
    "    elif backward_properties:\n",
    "        query+='''SELECT ?WD_id WHERE {\n",
    "                    ?WD_id (wdt:P%s)* wd:Q%s .\n",
    "                    }'''%(','.join(map(str, backward_properties)), ','.join(map(str, root_items)))\n",
    "    #print(query)\n",
    "\n",
    "    url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "    data = get(url, params={'query': query, 'format': 'json'}).json()\n",
    "    \n",
    "    ids = []\n",
    "    for item in data['results']['bindings']:\n",
    "        this_id=item[\"WD_id\"][\"value\"].split(\"/\")[-1].lstrip(\"Q\")\n",
    "        #print(item)\n",
    "        try:\n",
    "            this_id = int(this_id)\n",
    "            ids.append(this_id)\n",
    "            #print(this_id)\n",
    "        except ValueError:\n",
    "            #print(\"exception\")\n",
    "            continue\n",
    "    return ids\n",
    "\n",
    "\n",
    "try:\n",
    "    organization_subclass = get_wikidata_item_tree_item_idsSPARQL([43229], backward_properties=[279])\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    country_subclass = get_wikidata_item_tree_item_idsSPARQL([6256], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    country_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    city_subclass = get_wikidata_item_tree_item_idsSPARQL([515], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    city_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    capitals_subclass = get_wikidata_item_tree_item_idsSPARQL([5119], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    capitals_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    admTerr_subclass = get_wikidata_item_tree_item_idsSPARQL([15916867], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    admTerr_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    family_subclass = get_wikidata_item_tree_item_idsSPARQL([17350442], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    family_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    sportLeague_subclass = get_wikidata_item_tree_item_idsSPARQL([623109], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    sportLeague_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    venue_subclass = get_wikidata_item_tree_item_idsSPARQL([8436], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    venue_subclass = set()\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    organization_subclass = list(set(organization_subclass) - set(country_subclass) - set(city_subclass) - set(capitals_subclass) - set(admTerr_subclass) - set(family_subclass) - set(sportLeague_subclass) - set(venue_subclass))\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    geolocation_subclass = get_wikidata_item_tree_item_idsSPARQL([2221906], backward_properties=[279])\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    food_subclass = get_wikidata_item_tree_item_idsSPARQL([2095], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    food_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    edInst_subclass = get_wikidata_item_tree_item_idsSPARQL([2385804], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    edInst_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    govAgency_subclass = get_wikidata_item_tree_item_idsSPARQL([327333], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    govAgency_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    intOrg_subclass = get_wikidata_item_tree_item_idsSPARQL([484652], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    intOrg_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    timeZone_subclass = get_wikidata_item_tree_item_idsSPARQL([12143], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    timeZone_subclass = set()\n",
    "    pass\n",
    "   \n",
    "try:\n",
    "    geolocation_subclass = list(set(geolocation_subclass) - set(food_subclass) - set(edInst_subclass) - set(govAgency_subclass) - set(intOrg_subclass) - set(timeZone_subclass))\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/Round4_2020/tables/\"\n",
    "cta_file = './data/Dataset/Dataset/Round4_2020/gt/cta.csv'\n",
    "os.listdir(tables)\n",
    "\n",
    "def get_item_root(id_list):    \n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    id_to_root_class = {}\n",
    "    \n",
    "    for el in tqdm(id_list, desc=\"Processing IDs\"):\n",
    "        if el not in id_to_root_class:\n",
    "            query = f\"\"\"\n",
    "            SELECT ?instanceClass ?instanceClassLabel WHERE {{\n",
    "              wd:{el} wdt:P31 ?instanceClass .\n",
    "              SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE]\" }}\n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            # Set the query and request JSON response\n",
    "            sparql.setQuery(query)\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            #time.sleep(0.5)\n",
    "            \n",
    "            try:\n",
    "                results = sparql.query().convert()\n",
    "                if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "                    inst_item = int(results[\"results\"][\"bindings\"][0]['instanceClassLabel']['value'][1:])\n",
    "                    if inst_item in geolocation_subclass:\n",
    "                        id_to_root_class[el] = \"LOC\"\n",
    "                    elif inst_item in organization_subclass:\n",
    "                        id_to_root_class[el] = \"ORG\"\n",
    "                    elif inst_item == 5 or el == \"Q5\":\n",
    "                        id_to_root_class[el] = \"PERS\"\n",
    "                    else:\n",
    "                        id_to_root_class[el] = \"OTHERS\"\n",
    "                else:\n",
    "                    id_to_root_class[el] = \"OTHERS\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {el}: {e}\")\n",
    "                time.sleep(0.5)\n",
    "                id_to_root_class[el] = None          \n",
    "    \n",
    "    return id_to_root_class\n",
    "\n",
    "# Apply the function and create the 'key' column\n",
    "root_classes = []\n",
    "df = pd.read_csv(cta_file, header=None)\n",
    "ids = [url.split('/')[-1] for url in df[2]]\n",
    "\n",
    "root_classes = get_item_root(ids)\n",
    "\n",
    "# Map root classes to categories\n",
    "root_categories = []\n",
    "for el in ids:\n",
    "    root_categories.append(root_classes[el])\n",
    "\n",
    "\n",
    "df[\"category\"] = root_categories\n",
    "cta_keys = {}\n",
    "cta_keys[\"key\"] = (df[0] + \" \" + df[1].astype('str'), df[\"category\"])\n",
    "\n",
    "key_to_cell = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {col}\"\n",
    "            if key in set(cta_keys[\"key\"][0].values):\n",
    "                tmp_index = cta_keys[\"key\"][0].values.tolist().index(key)\n",
    "                tmp_value = cta_keys[\"key\"][1].iloc[tmp_index]\n",
    "                key_to_cell[key] = tmp_value\n",
    "                #print(f\"key: {key} -> key_to_cell[key]: {key_to_cell[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/Round4_2020/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/Round4_2020/gt/cea.csv'\n",
    "os.listdir(tables)\n",
    "df = pd.read_csv(cea_file, header=None)\n",
    "df[\"key\"] = df[0] + \" \" + df[1].astype('str') + \" \" + df[2].astype('str')\n",
    "cea_keys = (df[\"key\"].values, df[3])\n",
    "cea_values_dict = dict(zip(df[\"key\"].values, df[3].values))\n",
    "break\n",
    "ner_type = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {row+1} {col}\"\n",
    "            if key in cea_keys[0]:\n",
    "                cell_value = df.iloc[row, col]\n",
    "                ner_type[key] = (cell_value, cea_keys[1][cea_keys[0] == key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./R4_key_to_cell.json', 'w') as json_file:\n",
    "    json.dump(key_to_cell, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to the JSON file\n",
    "file_path = \"./R4_ner_type.json\"\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, 'r') as f:\n",
    "    ner_type = json.load(f)\n",
    "\n",
    "with open('./R4_key_to_cell.json', 'r') as f:\n",
    "    key_to_cell = json.load(f)\n",
    "\n",
    "# Now key_to_cell contains the dictionary loaded from the JSON file\n",
    "print(\"Dictionary loaded from JSON file:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(name, value):\n",
    "    if value is not None:\n",
    "          ### SOFT FILTERING CONTSTRAINT\n",
    "        #params = {\n",
    "        #    'name': name,\n",
    "        #    'token': 'lamapi_demo_2023',\n",
    "        #    'kg': 'wikidata',\n",
    "        #    'limit': 1000,\n",
    "        #    'query': f'''\n",
    "        #        {{\n",
    "        #            \"query\": {{\n",
    "        #                \"bool\": {{\n",
    "        #                    \"must\": [\n",
    "        #                        {{\n",
    "        #                            \"match\": {{\n",
    "        #                                \"name\": {{\n",
    "        #                                    \"query\": \"{name}\",\n",
    "        #                                    \"boost\": 2.0\n",
    "        #                                }}\n",
    "        #                            }}\n",
    "        #                        }}\n",
    "        #                    ],\n",
    "        #                    \"should\": [\n",
    "        #                        {{\n",
    "        #                            \"term\": {{\n",
    "        #                                \"NERtype\": \"{value[1]}\"\n",
    "        #                            }}\n",
    "        #                        }}\n",
    "        #                    ]\n",
    "        #                }}\n",
    "        #            }}\n",
    "        #        }}\n",
    "        #        ''',\n",
    "        #    'sort': [\n",
    "        #        f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "        #    ]\n",
    "        #}\n",
    "    \n",
    "        ### HARD FILTERING CONTSTRAINT\n",
    "        params = {\n",
    "            'name': name,\n",
    "            'token': 'lamapi_demo_2023',\n",
    "            'kg': 'wikidata',\n",
    "            'limit': 1000,\n",
    "            'query': f'''\n",
    "                {{\n",
    "                    \"query\": {{\n",
    "                        \"bool\": {{\n",
    "                            \"must\": [\n",
    "                                {{\n",
    "                                    \"match\": {{\n",
    "                                        \"name\": {{\n",
    "                                            \"query\": \"{name}\",\n",
    "                                            \"boost\": 2.0\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                }},\n",
    "                                {{\n",
    "                                    \"term\": {{\n",
    "                                        \"NERtype\": \"{value}\"\n",
    "                                    }}\n",
    "                                }}\n",
    "                            ]\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "                ''',\n",
    "            'sort': [\n",
    "                f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        params = {\n",
    "            'name': name,\n",
    "            'token': 'lamapi_demo_2023',\n",
    "            'kg': 'wikidata',\n",
    "            'limit': 1000,\n",
    "            'query': f'{{\"query\": {{\"bool\": {{\"must\": [{{\"match\": {{\"name\": {{\"query\": \"{name}\", \"boost\": 2.0}}}}}}]}}}}}}',\n",
    "            'sort': [\n",
    "                f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "            ]\n",
    "        }\n",
    "    return params\n",
    "\n",
    "\n",
    "queries = []\n",
    "for key in tqdm(key_to_cell):\n",
    "    id_table, _, id_col = key.split(\" \")\n",
    "    name = key_to_cell[key]\n",
    "    q_id = cea_values_dict[key]\n",
    "    new_key = f\"{id_table} {id_col}\"\n",
    "    if new_key in ner_type:\n",
    "        NER_type = ner_type[new_key]\n",
    "        query = get_query(name, NER_type)\n",
    "        queries.append((query, re.search(r'Q(\\d+)$', q_id)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUERY CORRETTA CON FUZZYYYY\n",
    "\n",
    "url = 'https://lamapi.hel.sintef.cloud/lookup/entity-retrieval'\n",
    "sample_size = 4000\n",
    "queries = random.sample(queries, sample_size)\n",
    "\n",
    "# Backoff decorator for handling retries with exponential backoff\n",
    "@backoff.on_exception(\n",
    "    backoff.expo, \n",
    "    (aiohttp.ClientError, aiohttp.http_exceptions.HttpProcessingError, asyncio.TimeoutError), \n",
    "    max_tries=5, \n",
    "    max_time=300\n",
    ")\n",
    "async def fetch(session, url, params, headers, semaphore):\n",
    "    async with semaphore:\n",
    "        async with session.get(url, params=params, headers=headers, ssl=False, timeout=30) as response:\n",
    "            try:\n",
    "                response.raise_for_status()  # Raises an exception for 4XX/5XX status codes\n",
    "                return await response.json()\n",
    "            except Exception as e:\n",
    "                return []\n",
    "async def process_item(session, url, id, headers, params, semaphore, pbar):\n",
    "\n",
    "    try:\n",
    "        data = await fetch(session, url, params, headers, semaphore)\n",
    "    except ClientResponseError as e:\n",
    "        if e.status == 404:\n",
    "            print(f\"404 Error: Resource not found for '{name}'\")\n",
    "            pbar.update(1)  # No need to await here\n",
    "            return 0, 0\n",
    "        else:\n",
    "            raise  # Re-raise the exception for other status codes\n",
    "\n",
    "    num_result = len(data) if data else 0\n",
    "\n",
    "    if data:\n",
    "        for item in data:\n",
    "            if id == item.get('id'):\n",
    "                pbar.update(1)  # No need to await here\n",
    "                pos_score = item.get('pos_score', 0)\n",
    "                if pos_score:\n",
    "                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                else:\n",
    "                    mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                return mrr_increment, 1\n",
    "\n",
    "        \n",
    "        #print(f\"{name} NOT FOUND-->t{item}\")\n",
    "\n",
    "    return 0, 0\n",
    "\n",
    "async def main(queries, url, pbar):\n",
    "    headers = {'accept': 'application/json'}\n",
    "    semaphore = asyncio.Semaphore(50)  # Limit to 50 concurrent requests\n",
    "    m_mrr = 0\n",
    "    cont_el = 0\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for param, id in queries:\n",
    "            tasks.append(process_item(session, url, id, headers, param, semaphore, pbar))\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for (mrr_increment, count), (param, id) in zip(results, queries):\n",
    "            if mrr_increment == 0 and count == 0:\n",
    "                name = param['name']\n",
    "                param['query'] = f'{{\"query\": {{\"bool\": {{\"must\": [{{\"match\": {{\"name\": {{\"query\": \"{name}\", \"boost\": 2.0, \"fuzziness\": \"AUTO\"}}}}}}]}}}}}}'\n",
    "\n",
    "                response = requests.get(url, params=param)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    #print(\"after call\")\n",
    "                    num_result = len(data) if data else 0\n",
    "                    if data:\n",
    "                        for item in data:\n",
    "                            if id == item.get('id'):\n",
    "                                pbar.update(1)  # No need to await here\n",
    "                                pos_score = item.get('pos_score', 0)\n",
    "                                if pos_score:\n",
    "                                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                                else:\n",
    "                                    mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                            \n",
    "            m_mrr += mrr_increment\n",
    "            cont_el += count\n",
    "\n",
    "        pbar.close()  # No need to await here\n",
    "\n",
    "    print(f\"Coverage of R4: {cont_el / len(queries)}\")\n",
    "    print(f\"Measure Reciprocal Rank of R4: {m_mrr / len(queries)}\")\n",
    "\n",
    "# Check if there's already a running event loop\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()  # Apply nest_asyncio\n",
    "    try:\n",
    "        pbar = tqdm(total=len(queries))\n",
    "        asyncio.run(main(queries, url, pbar))\n",
    "    except RuntimeError:  # For environments like Jupyter\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(main(queries, url, pbar))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query\n",
    "Coverage of R4: 0.94025\n",
    "\r\n",
    "Measure Reciprocal Rank of R4: 0.9150119999999621"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HardTableR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/HardTablesR3_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    HT3_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(HT3_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = HT3_sorted_mentions[:q1_idx]\n",
    "q2 = HT3_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = HT3_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = HT3_sorted_mentions[q3_idx:]\n",
    "\n",
    "sample_size = 1000\n",
    "HT3_sample_keys = []\n",
    "HT3_sample_keys = HT3_sample_keys + random.sample(q1, sample_size)\n",
    "HT3_sample_keys = HT3_sample_keys + random.sample(q2, sample_size)\n",
    "HT3_sample_keys = HT3_sample_keys + random.sample(q3, sample_size)\n",
    "HT3_sample_keys = HT3_sample_keys + random.sample(q4, sample_size)\n",
    "\n",
    "q_ids = {item[1]['name']: item[1]['id'] for item in HT3_sample_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_item_tree_item_idsSPARQL(root_items, forward_properties=None, backward_properties=None):\n",
    "    \"\"\"Return ids of WikiData items, which are in the tree spanned by the given root items and claims relating them\n",
    "        to other items.\n",
    "\n",
    "    :param root_items: iterable[int] One or multiple item entities that are the root elements of the tree\n",
    "    :param forward_properties: iterable[int] | None property-claims to follow forward; that is, if root item R has\n",
    "        a claim P:I, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :param backward_properties: iterable[int] | None property-claims to follow in reverse; that is, if (for a root\n",
    "        item R) an item I has a claim P:R, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :return: iterable[int]: List with ids of WikiData items in the tree\n",
    "    \"\"\"\n",
    "\n",
    "    query = '''PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>'''\n",
    "    if forward_properties:\n",
    "        query +='''SELECT ?WD_id WHERE {\n",
    "                  ?tree0 (wdt:P%s)* ?WD_id .\n",
    "                  BIND (wd:%s AS ?tree0)\n",
    "                  }'''%( ','.join(map(str, forward_properties)),','.join(map(str, root_items)))\n",
    "    elif backward_properties:\n",
    "        query+='''SELECT ?WD_id WHERE {\n",
    "                    ?WD_id (wdt:P%s)* wd:Q%s .\n",
    "                    }'''%(','.join(map(str, backward_properties)), ','.join(map(str, root_items)))\n",
    "    #print(query)\n",
    "\n",
    "    url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "    data = get(url, params={'query': query, 'format': 'json'}).json()\n",
    "    \n",
    "    ids = []\n",
    "    for item in data['results']['bindings']:\n",
    "        this_id=item[\"WD_id\"][\"value\"].split(\"/\")[-1].lstrip(\"Q\")\n",
    "        #print(item)\n",
    "        try:\n",
    "            this_id = int(this_id)\n",
    "            ids.append(this_id)\n",
    "            #print(this_id)\n",
    "        except ValueError:\n",
    "            #print(\"exception\")\n",
    "            continue\n",
    "    return ids\n",
    "\n",
    "\n",
    "try:\n",
    "    organization_subclass = get_wikidata_item_tree_item_idsSPARQL([43229], backward_properties=[279])\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    country_subclass = get_wikidata_item_tree_item_idsSPARQL([6256], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    country_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    city_subclass = get_wikidata_item_tree_item_idsSPARQL([515], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    city_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    capitals_subclass = get_wikidata_item_tree_item_idsSPARQL([5119], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    capitals_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    admTerr_subclass = get_wikidata_item_tree_item_idsSPARQL([15916867], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    admTerr_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    family_subclass = get_wikidata_item_tree_item_idsSPARQL([17350442], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    family_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    sportLeague_subclass = get_wikidata_item_tree_item_idsSPARQL([623109], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    sportLeague_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    venue_subclass = get_wikidata_item_tree_item_idsSPARQL([8436], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    venue_subclass = set()\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    organization_subclass = list(set(organization_subclass) - set(country_subclass) - set(city_subclass) - set(capitals_subclass) - set(admTerr_subclass) - set(family_subclass) - set(sportLeague_subclass) - set(venue_subclass))\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    geolocation_subclass = get_wikidata_item_tree_item_idsSPARQL([2221906], backward_properties=[279])\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    food_subclass = get_wikidata_item_tree_item_idsSPARQL([2095], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    food_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    edInst_subclass = get_wikidata_item_tree_item_idsSPARQL([2385804], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    edInst_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    govAgency_subclass = get_wikidata_item_tree_item_idsSPARQL([327333], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    govAgency_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    intOrg_subclass = get_wikidata_item_tree_item_idsSPARQL([484652], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    intOrg_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    timeZone_subclass = get_wikidata_item_tree_item_idsSPARQL([12143], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    timeZone_subclass = set()\n",
    "    pass\n",
    "   \n",
    "try:\n",
    "    geolocation_subclass = list(set(geolocation_subclass) - set(food_subclass) - set(edInst_subclass) - set(govAgency_subclass) - set(intOrg_subclass) - set(timeZone_subclass))\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    human_subclass = get_wikidata_item_tree_item_idsSPARQL([5], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    human_subclass = set()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2692/2692 [00:56<00:00, 47.24it/s] \n"
     ]
    }
   ],
   "source": [
    "tables = \"./data/Dataset/Dataset/HardTablesR2/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/HardTablesR2/gt/cea.csv'\n",
    "cta_file = './data/Dataset/Dataset/HardTablesR2/gt/cta.csv'\n",
    "os.listdir(tables)\n",
    "\n",
    "def get_item_root(id_list):     \n",
    "    id_to_root_class = {}\n",
    "    for el in id_list:\n",
    "        inst_item = int(re.search(r'(\\d+)$', el)[0])\n",
    "        if inst_item in geolocation_subclass:\n",
    "            #id_to_root_class[el] = \"LOC\"\n",
    "            return \"LOC\"\n",
    "        elif inst_item in organization_subclass:\n",
    "            #id_to_root_class[el] = \"ORG\"\n",
    "            return \"ORG\"\n",
    "        elif inst_item in human_subclass:\n",
    "            #id_to_root_class[el] = \"PERS\"\n",
    "            return \"PERS\"      \n",
    "    \n",
    "    return \"OTHERS\"\n",
    "\n",
    "# Apply the function and create the 'key' column\n",
    "root_classes = []\n",
    "df = pd.read_csv(cta_file, header=None)\n",
    "root_categories = []\n",
    "for urls in df[2]:\n",
    "    tmp = [url.split('/')[-1] for url in urls.split(\" \")]\n",
    "    root_categories.append(get_item_root(tmp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df[\"category\"] = root_categories\n",
    "cta_keys = {}\n",
    "cta_keys[\"key\"] = (df[0] + \" \" + df[1].astype('str'), df[\"category\"])\n",
    "\n",
    "ner_type = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    pattern = r'^\\.'\n",
    "    if re.match(pattern, table):\n",
    "        continue\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {col}\"\n",
    "            if key in set(cta_keys[\"key\"][0].values):\n",
    "                tmp_index = cta_keys[\"key\"][0].values.tolist().index(key)\n",
    "                tmp_value = cta_keys[\"key\"][1].iloc[tmp_index]\n",
    "                ner_type[key] = tmp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted mentions saved to ./data/HT3_ner_type.json\n"
     ]
    }
   ],
   "source": [
    "json_file_path = \"./data/HT3_ner_type.json\"\n",
    "\n",
    "# Save the sorted_mentions dictionary to a JSON file\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(ner_type, json_file, indent=4)\n",
    "\n",
    "print(f\"Sorted mentions saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HardTableR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# READ THE JSON\n",
    "#####################\n",
    "\n",
    "json_file_path = \"./data/HardTablesR2_sorted_mentions.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    HT2_sorted_mentions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT OVER THE QUARTILES\n",
    "\n",
    "n = len(HT2_sorted_mentions)\n",
    "q1_idx = n // 4\n",
    "q2_idx = n // 2\n",
    "q3_idx = 3 * n // 4\n",
    "\n",
    "# Step 3: Split the list into quartiles\n",
    "q1 = HT2_sorted_mentions[:q1_idx]\n",
    "q2 = HT2_sorted_mentions[q1_idx:q2_idx]\n",
    "q3 = HT2_sorted_mentions[q2_idx:q3_idx]\n",
    "q4 = HT2_sorted_mentions[q3_idx:]\n",
    "\n",
    "sample_size = 1000\n",
    "HT2_sample_keys = []\n",
    "HT2_sample_keys = HT2_sample_keys + random.sample(q1, sample_size)\n",
    "HT2_sample_keys = HT2_sample_keys + random.sample(q2, sample_size)\n",
    "HT2_sample_keys = HT2_sample_keys + random.sample(q3, sample_size)\n",
    "HT2_sample_keys = HT2_sample_keys + random.sample(q4, sample_size)\n",
    "\n",
    "q_ids = {item[1]['name']: item[1]['id'] for item in HT2_sample_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_item_tree_item_idsSPARQL(root_items, forward_properties=None, backward_properties=None):\n",
    "    \"\"\"Return ids of WikiData items, which are in the tree spanned by the given root items and claims relating them\n",
    "        to other items.\n",
    "\n",
    "    :param root_items: iterable[int] One or multiple item entities that are the root elements of the tree\n",
    "    :param forward_properties: iterable[int] | None property-claims to follow forward; that is, if root item R has\n",
    "        a claim P:I, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :param backward_properties: iterable[int] | None property-claims to follow in reverse; that is, if (for a root\n",
    "        item R) an item I has a claim P:R, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :return: iterable[int]: List with ids of WikiData items in the tree\n",
    "    \"\"\"\n",
    "\n",
    "    query = '''PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>'''\n",
    "    if forward_properties:\n",
    "        query +='''SELECT ?WD_id WHERE {\n",
    "                  ?tree0 (wdt:P%s)* ?WD_id .\n",
    "                  BIND (wd:%s AS ?tree0)\n",
    "                  }'''%( ','.join(map(str, forward_properties)),','.join(map(str, root_items)))\n",
    "    elif backward_properties:\n",
    "        query+='''SELECT ?WD_id WHERE {\n",
    "                    ?WD_id (wdt:P%s)* wd:Q%s .\n",
    "                    }'''%(','.join(map(str, backward_properties)), ','.join(map(str, root_items)))\n",
    "    #print(query)\n",
    "\n",
    "    url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "    data = get(url, params={'query': query, 'format': 'json'}).json()\n",
    "    \n",
    "    ids = []\n",
    "    for item in data['results']['bindings']:\n",
    "        this_id=item[\"WD_id\"][\"value\"].split(\"/\")[-1].lstrip(\"Q\")\n",
    "        #print(item)\n",
    "        try:\n",
    "            this_id = int(this_id)\n",
    "            ids.append(this_id)\n",
    "            #print(this_id)\n",
    "        except ValueError:\n",
    "            #print(\"exception\")\n",
    "            continue\n",
    "    return ids\n",
    "\n",
    "\n",
    "try:\n",
    "    organization_subclass = get_wikidata_item_tree_item_idsSPARQL([43229], backward_properties=[279])\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    country_subclass = get_wikidata_item_tree_item_idsSPARQL([6256], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    country_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    city_subclass = get_wikidata_item_tree_item_idsSPARQL([515], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    city_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    capitals_subclass = get_wikidata_item_tree_item_idsSPARQL([5119], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    capitals_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    admTerr_subclass = get_wikidata_item_tree_item_idsSPARQL([15916867], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    admTerr_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    family_subclass = get_wikidata_item_tree_item_idsSPARQL([17350442], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    family_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    sportLeague_subclass = get_wikidata_item_tree_item_idsSPARQL([623109], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    sportLeague_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    venue_subclass = get_wikidata_item_tree_item_idsSPARQL([8436], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    venue_subclass = set()\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    organization_subclass = list(set(organization_subclass) - set(country_subclass) - set(city_subclass) - set(capitals_subclass) - set(admTerr_subclass) - set(family_subclass) - set(sportLeague_subclass) - set(venue_subclass))\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    geolocation_subclass = get_wikidata_item_tree_item_idsSPARQL([2221906], backward_properties=[279])\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    food_subclass = get_wikidata_item_tree_item_idsSPARQL([2095], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    food_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    edInst_subclass = get_wikidata_item_tree_item_idsSPARQL([2385804], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    edInst_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    govAgency_subclass = get_wikidata_item_tree_item_idsSPARQL([327333], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    govAgency_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    intOrg_subclass = get_wikidata_item_tree_item_idsSPARQL([484652], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    intOrg_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    timeZone_subclass = get_wikidata_item_tree_item_idsSPARQL([12143], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    timeZone_subclass = set()\n",
    "    pass\n",
    "   \n",
    "try:\n",
    "    geolocation_subclass = list(set(geolocation_subclass) - set(food_subclass) - set(edInst_subclass) - set(govAgency_subclass) - set(intOrg_subclass) - set(timeZone_subclass))\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    human_subclass = get_wikidata_item_tree_item_idsSPARQL([5], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    human_subclass = set()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tables_path = \"./data/Dataset/Dataset/HardTablesR2/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/HardTablesR2/gt/cea.csv'\n",
    "os.listdir(tables_path)\n",
    "# Initialize logging\n",
    "#logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Read the cea_file and create a key-value dictionary\n",
    "df = pd.read_csv(cea_file, header=None)\n",
    "df[\"key\"] = df[0] + \" \" + df[1].astype(str) + \" \" + df[2].astype(str)\n",
    "cea_values_dict = dict(zip(df[\"key\"].values, df[3].values))\n",
    "cea_keys_set = set(df[\"key\"].values)\n",
    "\n",
    "# Function to process a single table file\n",
    "def process_table_file(table_file):\n",
    "    try:\n",
    "        table_name = os.path.splitext(os.path.basename(table_file))[0]\n",
    "        df = pd.read_csv(table_file)\n",
    "        local_key_to_cell = {}\n",
    "        \n",
    "        for row in range(df.shape[0]):\n",
    "            for col in range(df.shape[1]):\n",
    "                key = f\"{table_name} {row+1} {col}\"\n",
    "                if key in cea_keys_set:\n",
    "                    cell_value = df.iloc[row, col]\n",
    "                    local_key_to_cell[key] = (cell_value, cea_values_dict[key])\n",
    "                    break  # Exit inner loop early as only one match per row/col is needed\n",
    "        \n",
    "        return local_key_to_cell\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {table_file}: {e}\")\n",
    "        return {}\n",
    "\n",
    "pattern = r'^\\.'\n",
    "\n",
    "# Create a list of file paths, excluding files that start with a dot\n",
    "table_files = [os.path.join(tables_path, table) for table in os.listdir(tables_path) if not re.match(pattern, table)]\n",
    "\n",
    "# Process tables sequentially\n",
    "key_to_cell = {}\n",
    "for table_file in tqdm(table_files, desc=\"Processing tables\"):\n",
    "    local_key_to_cell = process_table_file(table_file)\n",
    "    key_to_cell.update(local_key_to_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = \"./data/Dataset/Dataset/HardTablesR2/tables/\"\n",
    "cea_file = './data/Dataset/Dataset/HardTablesR2/gt/cea.csv'\n",
    "cta_file = './data/Dataset/Dataset/HardTablesR2/gt/cta.csv'\n",
    "os.listdir(tables)\n",
    "\n",
    "def get_item_root(id_list):     \n",
    "    id_to_root_class = {}\n",
    "    for el in id_list:\n",
    "        inst_item = int(re.search(r'(\\d+)$', el)[0])\n",
    "        if inst_item in geolocation_subclass:\n",
    "            #id_to_root_class[el] = \"LOC\"\n",
    "            return \"LOC\"\n",
    "        elif inst_item in organization_subclass:\n",
    "            #id_to_root_class[el] = \"ORG\"\n",
    "            return \"ORG\"\n",
    "        elif inst_item in human_subclass:\n",
    "            #id_to_root_class[el] = \"PERS\"\n",
    "            return \"PERS\"      \n",
    "    \n",
    "    return \"OTHERS\"\n",
    "\n",
    "# Apply the function and create the 'key' column\n",
    "root_classes = []\n",
    "df = pd.read_csv(cta_file, header=None)\n",
    "root_categories = []\n",
    "for urls in df[2]:\n",
    "    tmp = [url.split('/')[-1] for url in urls.split(\" \")]\n",
    "    root_categories.append(get_item_root(tmp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df[\"category\"] = root_categories\n",
    "cta_keys = {}\n",
    "cta_keys[\"key\"] = (df[0] + \" \" + df[1].astype('str'), df[\"category\"])\n",
    "\n",
    "ner_type = {}\n",
    "for table in tqdm(os.listdir(tables)):\n",
    "    pattern = r'^\\.'\n",
    "    if re.match(pattern, table):\n",
    "        continue\n",
    "    table_file = os.path.join(tables, table)\n",
    "    table_name = table.split(\".\")[0]\n",
    "    df = pd.read_csv(table_file)\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            key = f\"{table_name} {col}\"\n",
    "            if key in set(cta_keys[\"key\"][0].values):\n",
    "                tmp_index = cta_keys[\"key\"][0].values.tolist().index(key)\n",
    "                tmp_value = cta_keys[\"key\"][1].iloc[tmp_index]\n",
    "                ner_type[key] = tmp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(name, value):\n",
    "    if value is not None:\n",
    "          ### SOFT FILTERING CONTSTRAINT\n",
    "        #params = {\n",
    "        #    'name': name,\n",
    "        #    'token': 'lamapi_demo_2023',\n",
    "        #    'kg': 'wikidata',\n",
    "        #    'limit': 1000,\n",
    "        #    'query': f'''\n",
    "        #        {{\n",
    "        #            \"query\": {{\n",
    "        #                \"bool\": {{\n",
    "        #                    \"must\": [\n",
    "        #                        {{\n",
    "        #                            \"match\": {{\n",
    "        #                                \"name\": {{\n",
    "        #                                    \"query\": \"{name}\",\n",
    "        #                                    \"boost\": 2.0\n",
    "        #                                }}\n",
    "        #                            }}\n",
    "        #                        }}\n",
    "        #                    ],\n",
    "        #                    \"should\": [\n",
    "        #                        {{\n",
    "        #                            \"term\": {{\n",
    "        #                                \"NERtype\": \"{value[1]}\"\n",
    "        #                            }}\n",
    "        #                        }}\n",
    "        #                    ]\n",
    "        #                }}\n",
    "        #            }}\n",
    "        #        }}\n",
    "        #        ''',\n",
    "        #    'sort': [\n",
    "        #        f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "        #    ]\n",
    "        #}\n",
    "    \n",
    "        ### HARD FILTERING CONTSTRAINT\n",
    "        params = {\n",
    "            'name': name,\n",
    "            'token': 'lamapi_demo_2023',\n",
    "            'kg': 'wikidata',\n",
    "            'limit': 1000,\n",
    "            'query': f'''\n",
    "                {{\n",
    "                    \"query\": {{\n",
    "                        \"bool\": {{\n",
    "                            \"must\": [\n",
    "                                {{\n",
    "                                    \"match\": {{\n",
    "                                        \"name\": {{\n",
    "                                            \"query\": \"{name}\",\n",
    "                                            \"boost\": 2.0\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                }},\n",
    "                                {{\n",
    "                                    \"term\": {{\n",
    "                                        \"NERtype\": \"{value[1]}\"\n",
    "                                    }}\n",
    "                                }}\n",
    "                            ]\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "                ''',\n",
    "            'sort': [\n",
    "                f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        params = {\n",
    "            'name': name,\n",
    "            'token': 'lamapi_demo_2023',\n",
    "            'kg': 'wikidata',\n",
    "            'limit': 1000,\n",
    "            'query': f'{{\"query\": {{\"bool\": {{\"must\": [{{\"match\": {{\"name\": {{\"query\": \"{name}\", \"boost\": 2.0}}}}}}]}}}}}}',\n",
    "            'sort': [\n",
    "                f'''{{\"popularity\": {{\"order\": \"desc\"}}}}'''\n",
    "            ]\n",
    "        }\n",
    "    return params\n",
    "\n",
    "\n",
    "queries = []\n",
    "for key in tqdm(key_to_cell):\n",
    "    id_table, _, id_col = key.split(\" \")\n",
    "    name = key_to_cell[key][0]\n",
    "    q_id = key_to_cell[key][1]\n",
    "    new_key = f\"{id_table} {id_col}\"\n",
    "    if new_key in ner_type:\n",
    "        NER_type = ner_type[new_key]\n",
    "        query = get_query(name, NER_type)\n",
    "        match = re.search(r'Q(\\d+)$', q_id)\n",
    "        if match:\n",
    "            queries.append((query, match[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import requests\n",
    "import nest_asyncio\n",
    "import backoff\n",
    "from tqdm import tqdm\n",
    "from aiohttp import ClientResponseError\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# URL and sample size\n",
    "url = 'https://lamapi.hel.sintef.cloud/lookup/entity-retrieval'\n",
    "sample_size = 4000\n",
    "\n",
    "# Generate sample queries\n",
    "queries = random.sample(queries, sample_size)\n",
    "\n",
    "# Backoff decorator for handling retries with exponential backoff\n",
    "@backoff.on_exception(\n",
    "    backoff.expo, \n",
    "    (aiohttp.ClientError, aiohttp.http_exceptions.HttpProcessingError, asyncio.TimeoutError), \n",
    "    max_tries=5, \n",
    "    max_time=300\n",
    ")\n",
    "async def fetch(session, url, params, headers, semaphore):\n",
    "    async with semaphore:\n",
    "        async with session.get(url, params=params, headers=headers, timeout=30) as response:\n",
    "            try:\n",
    "                response.raise_for_status()  # Raises an exception for 4XX/5XX status codes\n",
    "                return await response.json()\n",
    "            except Exception as e:\n",
    "                return []\n",
    "\n",
    "async def process_item(session, url, id, headers, params, semaphore, pbar):\n",
    "    try:\n",
    "        data = await fetch(session, url, params, headers, semaphore)\n",
    "    except ClientResponseError as e:\n",
    "        if e.status == 404:\n",
    "            print(f\"404 Error: Resource not found for '{params}'\")\n",
    "            pbar.update(1)  # No need to await here\n",
    "            return 0, 0\n",
    "        else:\n",
    "            raise  # Re-raise the exception for other status codes\n",
    "\n",
    "    num_result = len(data) if data else 0\n",
    "\n",
    "    if data:\n",
    "        for item in data:\n",
    "            if id == item.get('id'):\n",
    "                pbar.update(1)  # No need to await here\n",
    "                pos_score = item.get('pos_score', 0)\n",
    "                if pos_score:\n",
    "                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                else:\n",
    "                    mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                return mrr_increment, 1\n",
    "\n",
    "    return 0, 0\n",
    "\n",
    "async def main(queries, url, pbar):\n",
    "    headers = {'accept': 'application/json'}\n",
    "    semaphore = asyncio.Semaphore(50)  # Limit to 50 concurrent requests\n",
    "    m_mrr = 0\n",
    "    cont_el = 0\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for param, id in queries:\n",
    "            # Convert numpy int64 to standard Python int\n",
    "            param = {k: int(v) if isinstance(v, (np.int64, np.int32)) else v for k, v in param.items()}\n",
    "            tasks.append(process_item(session, url, id, headers, param, semaphore, pbar))\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "        print(\"fuzzy\")\n",
    "        \n",
    "        for (mrr_increment, count), (param, id) in zip(results, queries):\n",
    "            if mrr_increment == 0 and count == 0:\n",
    "                name = param['name']\n",
    "                param['query'] = f'{{\"query\": {{\"bool\": {{\"should\": [{{\"match\": {{\"name\": {{\"query\": \"{name}\", \"boost\": 2.0, \"fuzziness\": \"AUTO\"}}}}}}]}}}}}}'\n",
    "\n",
    "                response = requests.get(url, params=param)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    num_result = len(data) if data else 0\n",
    "                    if data:\n",
    "                        for item in data:\n",
    "                            if id == item.get('id'):\n",
    "                                pbar.update(1)  # No need to await here\n",
    "                                pos_score = item.get('pos_score', 0)\n",
    "                                if pos_score:\n",
    "                                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                                else:\n",
    "                                    mrr_increment = 1 / num_result  # Assume worst case for MRR if pos_score is 0\n",
    "                            \n",
    "            m_mrr += mrr_increment\n",
    "            cont_el += count\n",
    "\n",
    "        pbar.close()  # No need to await here\n",
    "\n",
    "    print(f\"Coverage of HT2: {cont_el / len(queries)}\")\n",
    "    print(f\"Measure Reciprocal Rank of HT2: {m_mrr / len(queries)}\")\n",
    "\n",
    "\n",
    "# Check if there's already a running event loop\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()  # Apply nest_asyncio\n",
    "    try:\n",
    "        pbar = tqdm(total=len(queries))\n",
    "        asyncio.run(main(queries, url, pbar))\n",
    "    except RuntimeError:  # For environments like Jupyter\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(main(queries, url, pbar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
