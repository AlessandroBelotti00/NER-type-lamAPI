{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tables: 100%|██████████| 1750/1750 [00:04<00:00, 383.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "json_file_path = \"C:/ALESSANDRO/Università/MAGISTRALE/SINTEF_thesis/lamAPI/work/_HTR2/HTR2_NER_query_type.json\"\n",
    "\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    HTR2_type = json.load(file)\n",
    "\n",
    "\n",
    "tables_path = \"C:/ALESSANDRO/Università/MAGISTRALE/SINTEF_thesis/lamAPI/data/Dataset/Dataset/HardTablesR2/tables/\"\n",
    "cea_file = 'C:/ALESSANDRO/Università/MAGISTRALE/SINTEF_thesis/lamAPI/data/Dataset/Dataset/HardTablesR2/gt/cea.csv'\n",
    "cta_file = 'C:/ALESSANDRO/Università/MAGISTRALE/SINTEF_thesis/lamAPI/data/Dataset/Dataset/HardTablesR2/gt/cta.csv'\n",
    "\n",
    "\n",
    "os.listdir(tables_path)\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Read the cea_file and create a key-value dictionary\n",
    "df_cea = pd.read_csv(cea_file, header=None)\n",
    "df_cea[\"key\"] = df_cea[0] + \" \" + df_cea[1].astype(str) + \" \" + df_cea[2].astype(str)\n",
    "df_cea[\"key_col\"] = df_cea[0] + \" \" + df_cea[2].astype(str)\n",
    "cea_values_dict = dict(zip(df_cea[\"key_col\"].values, df_cea[3].values))\n",
    "\n",
    "cea_keys_set = set(df_cea[\"key\"].values)\n",
    "cea_values_dict_cell = dict(zip(df_cea[\"key\"].values, df_cea[3].values))\n",
    "\n",
    "# Function to process a single table file\n",
    "def process_table_file(table_file):\n",
    "    try:\n",
    "        table_name = os.path.splitext(os.path.basename(table_file))[0]\n",
    "        df = pd.read_csv(table_file)\n",
    "        qid_to_value = {}\n",
    "\n",
    "        for row in range(df.shape[0]):\n",
    "            for col in range(df.shape[1]):\n",
    "                key = f\"{table_name} {row+1} {col}\"\n",
    "                if key in cea_keys_set:\n",
    "                    cell_value = df.iloc[row, col]\n",
    "                    qid = cea_values_dict_cell[key].split('/')[-1]  # Extract the QID from the URL\n",
    "                    qid_to_value[cell_value] = qid\n",
    "                    break  # Exit inner loop early as only one match per row/col is needed\n",
    "\n",
    "        return qid_to_value\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {table_file}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# List of table files\n",
    "table_files = [\n",
    "    os.path.join(tables_path, table)\n",
    "    for table in os.listdir(tables_path)\n",
    "    if not table.startswith('.')\n",
    "]\n",
    "\n",
    "# Process tables sequentially\n",
    "HTR2_id_to_name = {}\n",
    "for table_file in tqdm(table_files, desc=\"Processing tables\"):\n",
    "    local_key_to_cell = process_table_file(table_file)\n",
    "    HTR2_id_to_name.update(local_key_to_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/28038 [00:00<00:00, 77890.85it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_query(name, value):\n",
    "    name = str(name).replace('\"', ' ')\n",
    "    if value is not None:\n",
    "        # hard filtering constraint\n",
    "        query_dict = {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [\n",
    "                        {\"match\": {\"name\": {\"query\": name, \"boost\": 2.0}}},\n",
    "                        {\"term\": {\"NERtype\": value}}  # Ensures `value` matches at least one in the array\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        params = {\n",
    "            'name': name,\n",
    "            'token': 'lamapi_demo_2023',\n",
    "            'kg': 'wikidata',\n",
    "            'limit': 20,\n",
    "            'query': json.dumps(query_dict),  # Convert the query dictionary to a JSON string\n",
    "            'sort': [\n",
    "                '{\"popularity\": {\"order\": \"desc\"}}'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "queries = []\n",
    "for name, id  in tqdm(HTR2_id_to_name.items()):\n",
    "    if id in HTR2_type:\n",
    "        types_list = HTR2_type[id]\n",
    "\n",
    "        ########################################################\n",
    "        ##  modificare se types_list è una lista di tipi\n",
    "        ########################################################\n",
    "    \n",
    "        query = get_query(name, types_list)\n",
    "\n",
    "        queries.append((query, id, types_list))\n",
    "        if len(queries) == 100:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:06<?, ?it/s]\n",
      "Limit 10:   0%|          | 0/9 [00:00<?, ?it/s]2025-01-28 10:06:23,072 - INFO - Backing off fetch(...) for 0.3s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:06:23,081 - INFO - Backing off fetch(...) for 1.0s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:06:23,091 - INFO - Backing off fetch(...) for 0.4s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:06:23,101 - INFO - Backing off fetch(...) for 0.2s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:06:23,110 - INFO - Backing off fetch(...) for 0.2s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:06:23,119 - INFO - Backing off fetch(...) for 1.0s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:06:23,124 - INFO - Backing off fetch(...) for 0.7s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:06:23,130 - INFO - Backing off fetch(...) for 0.1s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:06:23,134 - INFO - Backing off fetch(...) for 0.2s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:07:14,062 - INFO - Backing off fetch(...) for 0.8s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:07:14,070 - INFO - Backing off fetch(...) for 0.9s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:07:14,078 - INFO - Backing off fetch(...) for 1.1s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:07:14,089 - INFO - Backing off fetch(...) for 1.4s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:07:14,096 - INFO - Backing off fetch(...) for 1.0s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:07:14,109 - INFO - Backing off fetch(...) for 1.9s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:07:14,118 - INFO - Backing off fetch(...) for 0.6s (asyncio.exceptions.TimeoutError)\n",
      "2025-01-28 10:07:14,123 - INFO - Backing off fetch(...) for 0.3s (asyncio.exceptions.TimeoutError)\n",
      "Limit 10:   0%|          | 0/9 [01:42<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 119>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(queries))\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m--> 124\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masyncio\u001b[38;5;241m.\u001b[39mrun(main(queries[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m10\u001b[39m],\u001b[38;5;250m \u001b[39murl,\u001b[38;5;250m \u001b[39mpbar,el))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:  \u001b[38;5;66;03m# For environments like Jupyter\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n",
      "File \u001b[1;32mc:\\Users\\abelo\\anaconda3\\envs\\v_env\\lib\\site-packages\\nest_asyncio.py:35\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     33\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32mc:\\Users\\abelo\\anaconda3\\envs\\v_env\\lib\\site-packages\\nest_asyncio.py:83\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     81\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abelo\\anaconda3\\envs\\v_env\\lib\\site-packages\\nest_asyncio.py:106\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m     heappop(scheduled)\n\u001b[0;32m    101\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    104\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 106\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[0;32m    109\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[1;32mc:\\Users\\abelo\\anaconda3\\envs\\v_env\\lib\\selectors.py:324\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 324\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32mc:\\Users\\abelo\\anaconda3\\envs\\v_env\\lib\\selectors.py:315\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 315\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import backoff\n",
    "import nest_asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Assume queries is a list of tuples [(param1, id1), (param2, id2), ...]\n",
    "\n",
    "failed_queries = {}\n",
    "url = 'https://lamapi.hel.sintef.cloud/lookup/entity-retrieval'\n",
    "\n",
    "@backoff.on_exception(\n",
    "    backoff.expo,\n",
    "    (aiohttp.ClientError, aiohttp.http_exceptions.HttpProcessingError, asyncio.TimeoutError),\n",
    "    max_tries=10,\n",
    "    max_time=400\n",
    ")\n",
    "async def fetch(session, url, params, headers, semaphore):\n",
    "    async with semaphore:\n",
    "        async with session.get(url, params=params, headers=headers, timeout=50) as response:\n",
    "            try:\n",
    "                response.raise_for_status()\n",
    "                return await response.json()\n",
    "            except asyncio.TimeoutError:\n",
    "                print(f\"Request timed out for params: {params}\")\n",
    "                return []\n",
    "            except aiohttp.ClientError as e:\n",
    "                print(f\"ClientError for params : {str(e)}\")\n",
    "                return []\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error for params {params}: {str(e)}\")\n",
    "                return []\n",
    "\n",
    "async def process_item(session, url, id, headers, params, semaphore, pbar):\n",
    "    try:\n",
    "        data = await fetch(session, url, params, headers, semaphore)\n",
    "    except aiohttp.ClientResponseError as e:\n",
    "        if e.status == 404:\n",
    "            print(f\"404 Error: Resource not found for '{id}'\")\n",
    "            pbar.update(1)\n",
    "            return 0, 0\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    num_result = len(data) if data else 0\n",
    "\n",
    "    if data:\n",
    "        for item in data:\n",
    "            if id == item.get('id'):\n",
    "                pbar.update(1)\n",
    "                pos_score = item.get('pos_score', 0)\n",
    "                if pos_score:\n",
    "                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                else:\n",
    "                    mrr_increment = 1 / num_result\n",
    "                return mrr_increment, 1\n",
    "\n",
    "    return 0, 0\n",
    "\n",
    "async def main(queries, url, failed_queries, l):\n",
    "    headers = {'accept': 'application/json'}\n",
    "    semaphore = asyncio.Semaphore(50)\n",
    "    m_mrr = 0\n",
    "    cont_el = 0\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        pbar = tqdm_asyncio(total=len(queries), desc=f\"Limit {l}\")\n",
    "        for param, id, _ in queries:\n",
    "            tasks.append(process_item(session, url, id, headers, param, semaphore, pbar))\n",
    "\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        for (mrr_increment, count), (param, id, item_NERtype) in zip(results, queries):\n",
    "            if mrr_increment == 0 and count == 0:\n",
    "                failed_queries[id] = (id, item_NERtype)\n",
    "                \n",
    "                param['limit'] = l\n",
    "                print(f\"Limit set to {l}\")\n",
    "                \n",
    "                query_dict = json.loads(param['query'])\n",
    "\n",
    "                if \"query\" in query_dict and \"bool\" in query_dict[\"query\"] and \"must\" in query_dict[\"query\"][\"bool\"]:\n",
    "                    for condition in query_dict[\"query\"][\"bool\"][\"must\"]:\n",
    "                        if \"match\" in condition and \"name\" in condition[\"match\"]:\n",
    "                            condition[\"match\"][\"name\"][\"fuzziness\"] = \"AUTO\"\n",
    "\n",
    "                param['query'] = json.dumps(query_dict)\n",
    "\n",
    "                response = requests.get(url, params=param)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    num_result = len(data) if data else 0\n",
    "                    if data:\n",
    "                        for item in data:\n",
    "                            if id == item.get('id'):\n",
    "                                pbar.update(1)\n",
    "                                pos_score = item.get('pos_score', 0)\n",
    "                                if pos_score:\n",
    "                                    mrr_increment = (num_result - (pos_score * num_result)) / num_result\n",
    "                                else:\n",
    "                                    mrr_increment = 1 / num_result\n",
    "\n",
    "                m_mrr += mrr_increment\n",
    "                cont_el += count\n",
    "            else:\n",
    "                m_mrr += mrr_increment\n",
    "                cont_el += count\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "    print(f\"Coverage of 2T (l={l}): {cont_el / len(queries)}\")\n",
    "    print(f\"Measure Reciprocal Rank of 2T (l={l}): {m_mrr / len(queries)}\")\n",
    "\n",
    "    return cont_el / len(queries), m_mrr / len(queries)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()  # Apply nest_asyncio\n",
    "    try:\n",
    "        pbar = tqdm(total=len(queries))\n",
    "        for el in range(10,100,10):\n",
    "            print(f\"limit {el}: {asyncio.run(main(queries[1:10], url, pbar,el))}\")\n",
    "    except RuntimeError:  # For environments like Jupyter\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(main(queries, url, pbar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
