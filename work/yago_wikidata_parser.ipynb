{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c242f0f9-c9e3-4f3b-8d15-96050eeeb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import os\n",
    "import sys\n",
    "from pymongo import MongoClient\n",
    "from json.decoder import JSONDecodeError\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef38472-3087-45f2-ae9b-fdd8757076a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoClient(host=['mongo:27017'], document_class=dict, tz_aware=False, connect=True)\n"
     ]
    }
   ],
   "source": [
    "# MongoDB connection setup\n",
    "MONGO_ENDPOINT, MONGO_ENDPOINT_PORT = os.environ[\"MONGO_ENDPOINT\"].split(\":\")\n",
    "MONGO_ENDPOINT_PORT = int(MONGO_ENDPOINT_PORT)\n",
    "MONGO_ENDPOINT_USERNAME = os.environ[\"MONGO_INITDB_ROOT_USERNAME\"]\n",
    "MONGO_ENDPOINT_PASSWORD = os.environ[\"MONGO_INITDB_ROOT_PASSWORD\"]\n",
    "DB_NAME = f\"wikidata\"\n",
    "\n",
    "client = MongoClient(MONGO_ENDPOINT, MONGO_ENDPOINT_PORT, username=MONGO_ENDPOINT_USERNAME, password=MONGO_ENDPOINT_PASSWORD)\n",
    "print(client)\n",
    "\n",
    "log_c = client.wikidata.log\n",
    "items_c = client[DB_NAME].items\n",
    "objects_c = client[DB_NAME].objects\n",
    "literals_c = client[DB_NAME].literals\n",
    "types_c = client[DB_NAME].types\n",
    "\n",
    "c_ref = {\n",
    "    \"items\": items_c,\n",
    "    \"objects\":objects_c, \n",
    "    \"literals\":literals_c, \n",
    "    \"types\":types_c\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16daa576-49bf-4fd5-960f-a034684916a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_buffer(buffer):\n",
    "    for key in buffer:\n",
    "        if len(buffer[key]) > 0:\n",
    "            c_ref[key].insert_many(buffer[key])\n",
    "            buffer[key] = []\n",
    "\n",
    "def get_wikidata_item_tree_item_idsSPARQL(root_items, forward_properties=None, backward_properties=None):\n",
    "    \"\"\"Return ids of WikiData items, which are in the tree spanned by the given root items and claims relating them\n",
    "        to other items.\n",
    "\n",
    "    :param root_items: iterable[int] One or multiple item entities that are the root elements of the tree\n",
    "    :param forward_properties: iterable[int] | None property-claims to follow forward; that is, if root item R has\n",
    "        a claim P:I, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :param backward_properties: iterable[int] | None property-claims to follow in reverse; that is, if (for a root\n",
    "        item R) an item I has a claim P:R, and P is in the list, the search will branch recursively to item I as well.\n",
    "    :return: iterable[int]: List with ids of WikiData items in the tree\n",
    "    \"\"\"\n",
    "\n",
    "    query = '''PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>'''\n",
    "    if forward_properties:\n",
    "        query +='''SELECT ?WD_id WHERE {\n",
    "                  ?tree0 (wdt:P%s)* ?WD_id .\n",
    "                  BIND (wd:%s AS ?tree0)\n",
    "                  }'''%( ','.join(map(str, forward_properties)),','.join(map(str, root_items)))\n",
    "    elif backward_properties:\n",
    "        query+='''SELECT ?WD_id WHERE {\n",
    "                    ?WD_id (wdt:P%s)* wd:Q%s .\n",
    "                    }'''%(','.join(map(str, backward_properties)), ','.join(map(str, root_items)))\n",
    "    #print(query)\n",
    "\n",
    "    url = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'\n",
    "    data = get(url, params={'query': query, 'format': 'json'}).json()\n",
    "    \n",
    "    ids = []\n",
    "    for item in data['results']['bindings']:\n",
    "        this_id=item[\"WD_id\"][\"value\"].split(\"/\")[-1].lstrip(\"Q\")\n",
    "        #print(item)\n",
    "        try:\n",
    "            this_id = int(this_id)\n",
    "            ids.append(this_id)\n",
    "            #print(this_id)\n",
    "        except ValueError:\n",
    "            #print(\"exception\")\n",
    "            continue\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ccbd4c-be3e-4b23-a8b8-d93e3f9397fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"./data/def_mapping.json\"\n",
    "\n",
    "try:\n",
    "    # Open the JSON file for reading\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        mapping = json.load(json_file)\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{json_file_path}' not found.\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON data: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data from JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b855d5-e433-489e-a4fc-136eaba530e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size_processed = 0\n",
    "num_entities_processed = 0\n",
    "\n",
    "def update_average_size(new_size):\n",
    "    global total_size_processed, num_entities_processed\n",
    "    total_size_processed += new_size\n",
    "    num_entities_processed += 1\n",
    "    return total_size_processed / num_entities_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ed23701-37de-4229-b2d7-1a68a0dd1e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 136/433964 [01:15<66:47:03,  1.80it/s]\n",
      "  0%|          | 2/432781 [00:00<23:18:07,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgium --> LOC/ORG\n",
      "___________________\n",
      "happiness --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/433065 [00:00<21:09:30,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington --> PERS\n",
      "___________________\n",
      "Jack Bauer --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/433271 [00:01<19:45:32,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Douglas Adams --> PERS\n",
      "___________________\n",
      "Paul Otlet --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/433234 [00:01<21:07:28,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikidata --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/432522 [00:01<21:36:18,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portugal --> LOC/ORG\n",
      "___________________\n",
      "Antarctica --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/432799 [00:02<35:38:29,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internet --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/433417 [00:02<39:38:33,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supercalifragilisticexpialidocious --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/433520 [00:02<41:45:22,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/429711 [00:03<45:11:11,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People's Republic of China --> LOC/ORG\n",
      "___________________\n",
      "Brazil --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/430691 [00:04<32:00:52,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yorkshire --> LOC\n",
      "___________________\n",
      "pizza --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/425393 [00:04<33:20:34,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany --> LOC/ORG\n",
      "___________________\n",
      "George W. Bush --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/425355 [00:05<33:04:41,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malta --> OTHERS\n",
      "___________________\n",
      "Talisker distillery --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/425339 [00:05<26:05:08,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tours --> LOC\n",
      "___________________\n",
      "Diego Velázquez --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/425043 [00:06<23:34:07,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chile --> LOC/ORG\n",
      "___________________\n",
      "dictatorship --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/425360 [00:06<23:17:24,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Wikipedia --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/425655 [00:06<29:39:29,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augusto Pinochet --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/425592 [00:07<28:10:05,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bahrain --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/426168 [00:07<27:00:45,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astrobiology --> OTHERS\n",
      "___________________\n",
      "Pioneer plaque --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/427211 [00:07<23:17:45,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zoology --> OTHERS\n",
      "___________________\n",
      "Gmina Kurów --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/428192 [00:08<27:28:39,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encyclopédie --> OTHERS\n",
      "___________________\n",
      "Rhône-Alpes --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/428242 [00:08<34:47:10,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charles Baudelaire --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/429077 [00:09<33:22:48,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Museum of Fine Arts of Lyon --> LOC/ORG\n",
      "___________________\n",
      "anatomy --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/429528 [00:09<28:53:22,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mount Vesuvius --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/430180 [00:10<30:30:45,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avenue des Champs-Élysées --> LOC\n",
      "___________________\n",
      "hydrogen --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/430286 [00:10<24:14:44,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oslo --> LOC\n",
      "___________________\n",
      "Bonn --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 43/431061 [00:10<22:52:41,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Saints' Day --> OTHERS\n",
      "___________________\n",
      "The Intouchables --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/431754 [00:10<19:46:42,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lisbon --> LOC\n",
      "___________________\n",
      "Beaujolais wine --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 47/431687 [00:11<19:41:04,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nicolaus Copernicus --> PERS\n",
      "___________________\n",
      "Neil Young --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 48/432024 [00:11<20:40:40,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planet --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/432584 [00:12<25:57:19,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 51/432726 [00:12<25:28:20,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rennes --> LOC\n",
      "___________________\n",
      "Lille --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 53/432653 [00:13<38:08:49,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanuatu --> LOC/ORG\n",
      "___________________\n",
      "chlorine --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 55/433183 [00:13<31:05:23,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Holland --> LOC/ORG\n",
      "___________________\n",
      "titanium --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 56/433507 [00:13<30:36:37,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanadium --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 58/434068 [00:14<34:17:49,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre Corneille --> PERS\n",
      "___________________\n",
      "Groningen --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 60/434463 [00:14<28:10:12,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fungus --> OTHERS\n",
      "___________________\n",
      "Massachusetts --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 62/433256 [00:15<23:28:32,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Israel --> LOC\n",
      "___________________\n",
      "Lausanne --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 64/433128 [00:15<20:58:56,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabriel Gonzáles Videla --> PERS\n",
      "___________________\n",
      "Laos --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 66/433797 [00:15<20:58:31,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Bond --> OTHERS\n",
      "___________________\n",
      "Andrei Tarkovsky --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 68/433279 [00:16<19:30:39,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plato --> PERS\n",
      "___________________\n",
      "Tajikistan --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 70/432291 [00:16<23:23:09,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thailand --> LOC\n",
      "___________________\n",
      "Meryl Streep --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 72/431989 [00:17<23:29:09,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Arab Emirates --> LOC\n",
      "___________________\n",
      "platinum --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 74/432231 [00:17<23:22:58,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novosibirsk --> LOC\n",
      "___________________\n",
      "Nizhny Novgorod --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 76/432839 [00:17<22:56:01,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omsk --> LOC\n",
      "___________________\n",
      "Suez Canal --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 77/433414 [00:18<29:57:40,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erta Ale --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 79/432196 [00:18<31:39:45,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mali --> LOC\n",
      "___________________\n",
      "Angola --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 81/433174 [00:19<27:41:11,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brač --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 82/433346 [00:19<26:23:09,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow --> OTHERS\n",
      "___________________\n",
      "Donald Tusk --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 84/434432 [00:19<24:35:48,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toilet paper orientation --> OTHERS\n",
      "___________________\n",
      "Reggiolo --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 86/435454 [00:20<28:39:17,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More Than Life at Stake --> OTHERS\n",
      "___________________\n",
      "Hermann Brunner --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 88/436196 [00:20<23:03:28,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warburg --> LOC/ORG\n",
      "___________________\n",
      "Ob --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 90/437186 [00:21<28:04:30,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIS Alpine Ski World Cup --> OTHERS\n",
      "___________________\n",
      "Czterej pancerni i pies --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 92/436790 [00:21<24:26:05,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrei Sakharov --> PERS\n",
      "___________________\n",
      "Sierra Leone --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 94/436518 [00:21<22:00:09,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudan --> LOC/ORG\n",
      "___________________\n",
      "Italo Balbo --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 96/436638 [00:22<27:03:08,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narendra Modi --> PERS\n",
      "___________________\n",
      "geography --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 98/437275 [00:22<24:15:58,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Trek --> OTHERS\n",
      "___________________\n",
      "Limburg --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/438069 [00:23<23:09:55,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antimony --> OTHERS\n",
      "___________________\n",
      "unbinilium --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/438199 [00:23<25:18:20,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indira Gandhi --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 102/438234 [00:23<25:26:29,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hector Berlioz --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 103/438800 [00:23<31:55:55,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groß Borstel --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 105/438842 [00:24<32:50:18,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puerto Rico --> LOC\n",
      "___________________\n",
      "Saarland --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 107/439063 [00:24<27:48:24,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illinois --> LOC/ORG\n",
      "___________________\n",
      "Oscar Luigi Scalfaro --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 109/440067 [00:25<25:39:35,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dubnium --> OTHERS\n",
      "___________________\n",
      "Cottian Alps --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 110/440291 [00:25<24:42:12,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ban Ki-moon --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 112/440786 [00:26<26:43:46,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kofi Annan --> PERS\n",
      "___________________\n",
      "meitnerium --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 114/441123 [00:26<30:41:55,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pennine Alps --> LOC\n",
      "___________________\n",
      "Leonard Cohen --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 115/441674 [00:26<28:52:49,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhaetian Alps --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 117/441816 [00:27<30:02:28,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago --> LOC\n",
      "___________________\n",
      "nihonium --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 119/442040 [00:27<25:11:24,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Osama bin Laden --> PERS\n",
      "___________________\n",
      "Friedrich Hayek --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 121/442892 [00:28<23:08:23,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "José Joaquín Prieto --> PERS\n",
      "___________________\n",
      "Arachnida --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 123/443803 [00:28<21:22:04,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tripura --> LOC/ORG\n",
      "___________________\n",
      "Dave Arneson --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 125/444582 [00:28<23:23:46,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uetersen --> LOC/ORG\n",
      "___________________\n",
      "Otho --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 127/445362 [00:29<24:02:43,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titus --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 128/445792 [00:29<22:32:05,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field hockey --> OTHERS\n",
      "___________________\n",
      "Eschwege --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 130/446625 [00:29<24:06:33,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loire --> LOC\n",
      "___________________\n",
      "hacker --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 131/446650 [00:29<24:47:10,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mexico City --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 133/447063 [00:30<24:25:34,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mississippi --> LOC/ORG\n",
      "___________________\n",
      "Uttarakhand --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 134/447530 [00:30<25:15:21,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cublize --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 136/447863 [00:30<24:53:34,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard Wagner --> PERS\n",
      "___________________\n",
      "Nagpur --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 137/448368 [00:31<22:53:01,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyon Cathedral --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 138/448409 [00:31<25:33:48,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Mexico --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 140/449168 [00:31<28:42:15,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramesses I --> PERS\n",
      "___________________\n",
      "Caracas --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 142/450214 [00:32<26:00:58,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finkenwerder --> LOC/ORG\n",
      "___________________\n",
      "Billstedt --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 144/451238 [00:32<24:58:30,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avast Antivirus --> OTHERS\n",
      "___________________\n",
      "Blankenese --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 146/452025 [00:33<23:25:21,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eimsbüttel --> LOC/ORG\n",
      "___________________\n",
      "Valenzuela --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 148/452801 [00:33<23:01:45,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antipolo --> LOC\n",
      "___________________\n",
      "Primo Nebiolo --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 149/453326 [00:33<23:30:39,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bergstedt --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 151/453639 [00:33<24:05:59,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbe --> LOC\n",
      "___________________\n",
      "Dejen Gebremeskel --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 153/454599 [00:34<22:17:51,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neckar --> LOC\n",
      "___________________\n",
      "Abel Mutai --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 154/454831 [00:34<21:46:05,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North Sea --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 156/455352 [00:34<22:43:27,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabaco --> LOC\n",
      "___________________\n",
      "Kiel --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 157/455480 [00:35<24:22:27,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potsdam --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 158/455990 [00:35<26:16:44,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erick Barrondo --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 160/456063 [00:35<25:17:16,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Düsseldorf --> LOC\n",
      "___________________\n",
      "Wiesbaden --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 162/456770 [00:36<23:43:29,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saarbrücken --> LOC\n",
      "___________________\n",
      "Robert Grabarz --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 163/457262 [00:36<22:55:32,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samara Governorate --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 164/457547 [00:36<26:14:32,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaliningrad Oblast --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 166/457872 [00:36<25:53:19,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomasz Majewski --> PERS\n",
      "___________________\n",
      "Helsinki --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 168/458684 [00:37<26:39:54,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Murmansk Oblast --> LOC\n",
      "___________________\n",
      "Ashton Eaton --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 170/459616 [00:37<26:06:49,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eilbek --> LOC/ORG\n",
      "___________________\n",
      "Gordian III --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 172/460659 [00:38<25:39:11,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poppenbüttel --> LOC/ORG\n",
      "___________________\n",
      "Rahlstedt --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 173/460838 [00:38<25:48:24,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gadolinium --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 175/461011 [00:38<26:34:13,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wohldorf-Ohlstedt --> LOC/ORG\n",
      "___________________\n",
      "English --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 176/461428 [00:38<27:55:35,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangka Belitung Islands --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 178/462389 [00:39<27:02:49,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diplomacy --> OTHERS\n",
      "___________________\n",
      "Bengkulu --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 179/462720 [00:39<26:29:39,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olivier Giroud --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 181/463590 [00:40<28:20:12,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yann M'Vila --> PERS\n",
      "___________________\n",
      "Sidney Govou --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 183/464316 [00:40<26:21:33,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Djibril Cissé --> PERS\n",
      "___________________\n",
      "Bacary Sagna --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 184/464775 [00:40<35:34:16,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hermann Maier --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 185/465174 [00:41<35:26:21,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Givors --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 186/465624 [00:41<33:22:01,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rivolet --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 187/466077 [00:41<31:58:36,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 189/466683 [00:42<28:13:50,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009 --> OTHERS\n",
      "___________________\n",
      "Newfoundland and Labrador --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 191/467642 [00:42<25:12:12,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gare de Lyon-Vaise --> OTHERS\n",
      "___________________\n",
      "2005 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 193/468646 [00:42<26:27:32,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chambost-Allières --> LOC/ORG\n",
      "___________________\n",
      "history of Lyon --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 194/469107 [00:43<42:10:27,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 196/469900 [00:43<33:29:13,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1906 --> OTHERS\n",
      "___________________\n",
      "ACF Fiorentina --> ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 198/470885 [00:44<27:17:38,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1909 --> OTHERS\n",
      "___________________\n",
      "Gare de Lyon-Gorge-de-Loup --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 200/471784 [00:44<25:43:19,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993 --> OTHERS\n",
      "___________________\n",
      "1996 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 202/472612 [00:44<27:14:59,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komi Republic --> LOC/ORG\n",
      "___________________\n",
      "1912 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 204/473163 [00:45<26:19:33,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 --> OTHERS\n",
      "___________________\n",
      "Edmonton --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 206/473200 [00:45<25:59:19,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duisburg --> LOC/ORG\n",
      "___________________\n",
      "Jacques Chirac --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 207/473652 [00:45<27:05:43,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arica y Parinacota Region --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 208/474096 [00:46<29:10:29,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarapacá Region --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 209/474037 [00:46<35:37:48,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mannheim --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 210/474325 [00:46<38:28:45,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victoria --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 211/474777 [00:47<43:24:15,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totma --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 212/475147 [00:47<44:36:53,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goku --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 213/475685 [00:48<47:08:09,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Government of the Soviet Union --> ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 214/476086 [00:48<58:41:56,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 2 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 215/476538 [00:48<51:27:24,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1922 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 217/477095 [00:49<38:19:04,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naryan-Mar --> LOC\n",
      "___________________\n",
      "Georges Pompidou --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 218/477416 [00:49<33:27:53,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluche --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 219/477864 [00:49<32:42:32,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 220/478167 [00:50<31:21:17,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iriga --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 222/478970 [00:50<44:43:48,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naga --> LOC\n",
      "___________________\n",
      "Alto Hospicio --> ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 223/479265 [00:51<46:16:43,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nissedal --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 224/479660 [00:51<56:02:47,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langenzenn --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 225/479942 [00:52<56:27:43,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seljord --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 226/480351 [00:53<75:11:28,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 9 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 227/480868 [00:53<74:05:38,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kongens Lyngby --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 228/481163 [00:53<66:16:58,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokke Municipality --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 229/481568 [00:54<61:11:50,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 10 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 230/481976 [00:54<58:57:30,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 13 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 231/482386 [00:55<58:21:14,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 17 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 232/482586 [00:55<52:42:07,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skien --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 233/482995 [00:56<61:52:36,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 23 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 234/483420 [00:56<62:11:01,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauron --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 235/483553 [00:57<61:09:31,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proton --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 236/483971 [00:57<61:13:03,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "December 8 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 238/484784 [00:58<52:19:42,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 5 --> OTHERS\n",
      "___________________\n",
      "February 12 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 239/484901 [00:58<51:26:10,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Angry Men --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 240/485306 [00:58<53:17:56,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 28 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 241/485823 [00:59<60:54:20,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Altengamme --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 242/486243 [00:59<58:00:12,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 4 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 243/486660 [01:00<52:30:12,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 10 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 244/487194 [01:00<46:09:25,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Dónde Están Corazón? --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 245/487718 [01:00<41:22:29,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reitbrook --> LOC/ORG\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 246/487982 [01:00<38:25:42,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaroslavl --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 247/488397 [01:01<38:57:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 19 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 248/488810 [01:01<39:43:03,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 22 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 249/489283 [01:01<39:41:20,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heroes of Might and Magic V: Hammers of Fate --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 250/489594 [01:01<37:08:36,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanaa --> LOC\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 251/490027 [01:02<37:03:54,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 252/490457 [01:02<36:52:54,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 253/490892 [01:02<36:38:11,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1973 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 254/491240 [01:03<39:23:05,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thirty Years' War --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 255/491354 [01:03<38:45:18,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ludwig Erhard --> PERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 256/491768 [01:03<39:16:32,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 13 --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 257/492298 [01:04<45:03:12,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kick-Ass --> OTHERS\n",
      "___________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 120\u001b[0m\n\u001b[1;32m    116\u001b[0m sitelinks \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msitelinks\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m    117\u001b[0m popularity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sitelinks) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sitelinks) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(mapping\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    121\u001b[0m     all_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m labels:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################################\n",
    "###  WITH MULTIPLE CLUSTERING\n",
    "################################\n",
    "\n",
    "wikidata_dump_path = './data/latest-all.json.bz2'\n",
    "initial_estimated_average_size = 800\n",
    "BATCH_SIZE = 100 # Number of entities to insert in a single batch\n",
    "compressed_file_size = os.path.getsize(wikidata_dump_path)\n",
    "initial_total_lines_estimate = compressed_file_size / initial_estimated_average_size\n",
    "\n",
    "DATATYPES_MAPPINGS = {\n",
    "    'external-id': 'STRING',\n",
    "    'quantity': 'NUMBER',\n",
    "    'globe-coordinate': 'STRING',\n",
    "    'string': 'STRING',\n",
    "    'monolingualtext': 'STRING',\n",
    "    'commonsMedia': 'STRING',\n",
    "    'time': 'DATETIME',\n",
    "    'url': 'STRING',\n",
    "    'geo-shape': 'GEOSHAPE',\n",
    "    'math': 'MATH',\n",
    "    'musical-notation': 'MUSICAL_NOTATION',\n",
    "    'tabular-data': 'TABULAR_DATA'\n",
    "}\n",
    "DATATYPES = list(set(DATATYPES_MAPPINGS.values()))\n",
    "\n",
    "buffer = {\n",
    "    \"items\": [],\n",
    "    \"objects\": [], \n",
    "    \"literals\": [], \n",
    "    \"types\": []\n",
    "}\n",
    "\n",
    "def check_skip(obj, datatype):\n",
    "    temp = obj.get(\"mainsnak\", obj)\n",
    "    if \"datavalue\" not in temp:\n",
    "        return True\n",
    "\n",
    "    skip = {\n",
    "        \"wikibase-lexeme\",\n",
    "        \"wikibase-form\",\n",
    "        \"wikibase-sense\"\n",
    "    }\n",
    "\n",
    "    return datatype in skip\n",
    "\n",
    "\n",
    "\n",
    "def get_value(obj, datatype):\n",
    "    temp = obj.get(\"mainsnak\", obj)\n",
    "    if datatype == \"globe-coordinate\":\n",
    "        latitude = temp[\"datavalue\"][\"value\"][\"latitude\"]\n",
    "        longitude = temp[\"datavalue\"][\"value\"][\"longitude\"]\n",
    "        value = f\"{latitude},{longitude}\"\n",
    "    else:\n",
    "        keys = {\n",
    "            \"quantity\": \"amount\",\n",
    "            \"monolingualtext\": \"text\",\n",
    "            \"time\": \"time\",\n",
    "        }\n",
    "        if datatype in keys:\n",
    "            key = keys[datatype]\n",
    "            value = temp[\"datavalue\"][\"value\"][key]\n",
    "        else:\n",
    "            value = temp[\"datavalue\"][\"value\"]\n",
    "    return value\n",
    "\n",
    "global initial_total_lines_estimate\n",
    "\n",
    "\n",
    "try:\n",
    "    geolocation_subclass = get_wikidata_item_tree_item_idsSPARQL([2221906], backward_properties=[279])\n",
    "    food_subclass =  get_wikidata_item_tree_item_idsSPARQL([2095], backward_properties=[279])\n",
    "    edInst_subclass =  get_wikidata_item_tree_item_idsSPARQL([2385804], backward_properties=[279])\n",
    "    govAgency_subclass =  get_wikidata_item_tree_item_idsSPARQL([327333], backward_properties=[279])\n",
    "    intOrg_subclass =  get_wikidata_item_tree_item_idsSPARQL([484652], backward_properties=[279])\n",
    "    timeZone_subclass =  get_wikidata_item_tree_item_idsSPARQL([12143], backward_properties=[279])    \n",
    "    geolocation_subclass = list(set(geolocation_subclass)-set(food_subclass))\n",
    "    \n",
    "    organization_subclass=get_wikidata_item_tree_item_idsSPARQL([43229], backward_properties=[279])    \n",
    "    country_subclass =  get_wikidata_item_tree_item_idsSPARQL([6256], backward_properties=[279])    \n",
    "    city_subclass =  get_wikidata_item_tree_item_idsSPARQL([515], backward_properties=[279])    \n",
    "    capitals_subclass =  get_wikidata_item_tree_item_idsSPARQL([5119], backward_properties=[279])\n",
    "\n",
    "    admTerr_subclass =  get_wikidata_item_tree_item_idsSPARQL([15916867], backward_properties=[279])\n",
    "\n",
    "    family_subclass =  get_wikidata_item_tree_item_idsSPARQL([17350442], backward_properties=[279])\n",
    "    sportLeague_subclass =  get_wikidata_item_tree_item_idsSPARQL([623109], backward_properties=[279])\n",
    "    venue_subclass =  get_wikidata_item_tree_item_idsSPARQL([8436], backward_properties=[279])\n",
    "    organization_subclass = list(set(organization_subclass)-set(country_subclass)-set(city_subclass)-\n",
    "                             set(capitals_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "\n",
    "with bz2.open(wikidata_dump_path, 'rt', encoding='utf-8') as f:\n",
    "    count = 1000\n",
    "    \n",
    "    ORG = []\n",
    "    PERS = []\n",
    "    LOC = []\n",
    "    OTHERS = []\n",
    "\n",
    "    pbar = tqdm(total=initial_total_lines_estimate)\n",
    "    for i, line in enumerate(f):\n",
    "        try:\n",
    "            # Parse JSON data from each line\n",
    "            item = json.loads(line[:-2])\n",
    "\n",
    "            entity = item['id']\n",
    "            labels = item.get(\"labels\", {})\n",
    "            english_label = labels.get(\"en\", {}).get(\"value\", \"\")\n",
    "            aliases = item.get(\"aliases\", {})\n",
    "            description = item.get('descriptions', {}).get('en', {})\n",
    "            category = \"entity\"\n",
    "            sitelinks = item.get(\"sitelinks\", {})\n",
    "            popularity = len(sitelinks) if len(sitelinks) > 0 else 1\n",
    "\n",
    "            \n",
    "            if entity in list(mapping.values()):\n",
    "                all_labels = {}\n",
    "                for lang in labels:\n",
    "                    all_labels[lang] = labels[lang][\"value\"]\n",
    "            \n",
    "                all_aliases = {}\n",
    "                for lang in aliases:\n",
    "                    all_aliases[lang] = []\n",
    "                    for alias in aliases[lang]:\n",
    "                        all_aliases[lang].append(alias[\"value\"])\n",
    "                    all_aliases[lang] = list(set(all_aliases[lang]))\n",
    "            \n",
    "                found = False\n",
    "                for predicate in item[\"claims\"]:\n",
    "                    if predicate == \"P279\":\n",
    "                        found = True\n",
    "            \n",
    "                if found:\n",
    "                    category = \"type\"\n",
    "                if entity[0] == \"P\":\n",
    "                    category = \"predicate\"\n",
    "        \n",
    "                line_size = len(line)\n",
    "                current_average_size = update_average_size(line_size)\n",
    "                pbar.total = round(compressed_file_size / current_average_size)\n",
    "                pbar.update(1)\n",
    "    \n",
    "                ###############################################################\n",
    "                # ORGANIZATION EXTRACTION\n",
    "                # All items with the root class Organization (Q43229) excluding country (Q6256), city (Q515), capitals (Q5119), \n",
    "                # administrative territorial entity of a single country (Q15916867), venue (Q17350442), sports league (Q623109) \n",
    "                # and family (Q8436)\n",
    "                \n",
    "                # LOCATION EXTRACTION\n",
    "                # All items with the root class Geographic Location (Q2221906) excluding: food (Q2095), educational institution (Q2385804), \n",
    "                # government agency (Q327333), international organization (Q484652) and time zone (Q12143)\n",
    "                \n",
    "                # PERSON EXTRACTION\n",
    "                # All items with the statement is instance of (P31) human (Q5) are classiﬁed as person.\n",
    "    \n",
    "                NERtype = None\n",
    "    \n",
    "                if item.get(\"type\") == \"item\" and \"claims\" in item:\n",
    "                    p31_claims = item[\"claims\"].get(\"P31\", [])\n",
    "                               \n",
    "                    for claim in p31_claims:\n",
    "                        mainsnak = claim.get(\"mainsnak\", {})\n",
    "                        datavalue = mainsnak.get(\"datavalue\", {})\n",
    "                        numeric_id = datavalue.get(\"value\", {}).get(\"numeric-id\")\n",
    "                        \n",
    "                        if numeric_id == 5:\n",
    "                            NERtype = \"PERS\" \n",
    "                        elif numeric_id in organization_subclass and numeric_id in geolocation_subclass:\n",
    "                            NERtype = \"LOC/ORG\"\n",
    "                        elif numeric_id in geolocation_subclass or any(k.lower() in description.get('value', '').lower() for k in [\"district\", \"city\", \"country\", \"capital\"]):\n",
    "                            NERtype = \"LOC\"\n",
    "                        elif numeric_id in organization_subclass:\n",
    "                            NERtype = \"ORG\"  \n",
    "                        else:\n",
    "                            NERtype = \"OTHERS\"\n",
    "                    print(f\"{english_label} --> {NERtype}\")\n",
    "                    print(\"___________________\")\n",
    "                     \n",
    "                ################################################################   \n",
    "                ################################################################   \n",
    "                # URL EXTRACTION\n",
    "            \n",
    "                try:\n",
    "                    lang = labels.get(\"en\", {}).get(\"language\", \"\")\n",
    "                    tmp={}\n",
    "                    tmp[\"WD_id\"] = item['id']\n",
    "                    tmp[\"WP_id\"] = labels.get(\"en\", {}).get(\"value\", \"\")\n",
    "            \n",
    "                    url_dict={}\n",
    "                    url_dict[\"wikidata\"] = \"http://www.wikidata.org/wiki/\"+tmp[\"WD_id\"]\n",
    "                    url_dict[\"wikipedia\"] = \"http://\"+lang+\".wikipedia.org/wiki/\"+tmp[\"WP_id\"].replace(\" \",\"_\")\n",
    "                    url_dict[\"dbpedia\"] = \"http://dbpedia.org/resource/\"+tmp[\"WP_id\"].capitalize().replace(\" \",\"_\")\n",
    "                    \n",
    "            \n",
    "                except json.decoder.JSONDecodeError:\n",
    "                   pass\n",
    "                \n",
    "                ################################################################    \n",
    "        \n",
    "                objects = {}\n",
    "                literals = {datatype: {} for datatype in DATATYPES}\n",
    "                types = {\"P31\": []}\n",
    "                join = {\n",
    "                    \"items\": {\n",
    "                        \"id_entity\": i,\n",
    "                        \"entity\": entity,\n",
    "                        \"description\": description,\n",
    "                        \"labels\": all_labels,\n",
    "                        \"aliases\": all_aliases,\n",
    "                        \"types\": types,\n",
    "                        \"popularity\": popularity,\n",
    "                        \"kind\": category,   # kind (entity, type or predicate, disambiguation or category)\n",
    "                        ######################\n",
    "                        # new updates\n",
    "                        \"NERtype\": NERtype, # (ORG, LOC, PER or OTHERS)\n",
    "                        \"URLs\" : url_dict\n",
    "                        ######################\n",
    "                    },\n",
    "                    \"objects\": { \n",
    "                        \"id_entity\": i,\n",
    "                        \"entity\": entity,\n",
    "                        \"objects\":objects\n",
    "                    },\n",
    "                    \"literals\": { \n",
    "                        \"id_entity\": i,\n",
    "                        \"entity\": entity,\n",
    "                        \"literals\": literals\n",
    "                    },\n",
    "                    \"types\": { \n",
    "                        \"id_entity\": i,\n",
    "                        \"entity\": entity,\n",
    "                        \"types\": types\n",
    "                    },\n",
    "                }\n",
    "            \n",
    "                predicates = item[\"claims\"]\n",
    "                for predicate in predicates:\n",
    "                    for obj in predicates[predicate]:\n",
    "                        datatype = obj[\"mainsnak\"][\"datatype\"]\n",
    "            \n",
    "                        if check_skip(obj, datatype):\n",
    "                            continue\n",
    "            \n",
    "                        if datatype == \"wikibase-item\" or datatype == \"wikibase-property\":\n",
    "                            value = obj[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "            \n",
    "                            if predicate == \"P31\" or predicate == \"P106\":\n",
    "                                types[\"P31\"].append(value)\n",
    "            \n",
    "                            if value not in objects:\n",
    "                                objects[value] = []\n",
    "                            objects[value].append(predicate)    \n",
    "                        else:\n",
    "                            value = get_value(obj, datatype)                \n",
    "                            lit = literals[DATATYPES_MAPPINGS[datatype]]\n",
    "            \n",
    "                            if predicate not in lit:\n",
    "                                lit[predicate] = []\n",
    "                            lit[predicate].append(value)   \n",
    "            \n",
    "                 \n",
    "            \n",
    "                for key in buffer:\n",
    "                    buffer[key].append(join[key])            \n",
    "            \n",
    "                if len(buffer[\"items\"]) == BATCH_SIZE:\n",
    "                    flush_buffer(buffer)\n",
    "    \n",
    "        except json.decoder.JSONDecodeError:\n",
    "            continue\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8114a-6765-4c4c-ab18-1a5c17c8aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25608/2214523 [1:58:22<308:07:32,  1.97it/s] "
     ]
    }
   ],
   "source": [
    "################################\n",
    "###  WITH SINGLE CLUSTERING\n",
    "################################\n",
    "\n",
    "wikidata_dump_path = './my-data/latest-all.json.bz2'\n",
    "initial_estimated_average_size = 800\n",
    "BATCH_SIZE = 100 # Number of entities to insert in a single batch\n",
    "compressed_file_size = os.path.getsize(wikidata_dump_path)\n",
    "initial_total_lines_estimate = compressed_file_size / initial_estimated_average_size\n",
    "\n",
    "DATATYPES_MAPPINGS = {\n",
    "    'external-id': 'STRING',\n",
    "    'quantity': 'NUMBER',\n",
    "    'globe-coordinate': 'STRING',\n",
    "    'string': 'STRING',\n",
    "    'monolingualtext': 'STRING',\n",
    "    'commonsMedia': 'STRING',\n",
    "    'time': 'DATETIME',\n",
    "    'url': 'STRING',\n",
    "    'geo-shape': 'GEOSHAPE',\n",
    "    'math': 'MATH',\n",
    "    'musical-notation': 'MUSICAL_NOTATION',\n",
    "    'tabular-data': 'TABULAR_DATA'\n",
    "}\n",
    "DATATYPES = list(set(DATATYPES_MAPPINGS.values()))\n",
    "\n",
    "buffer = {\n",
    "    \"items\": [],\n",
    "    \"objects\": [], \n",
    "    \"literals\": [], \n",
    "    \"types\": []\n",
    "}\n",
    "\n",
    "def check_skip(obj, datatype):\n",
    "    temp = obj.get(\"mainsnak\", obj)\n",
    "    if \"datavalue\" not in temp:\n",
    "        return True\n",
    "\n",
    "    skip = {\n",
    "        \"wikibase-lexeme\",\n",
    "        \"wikibase-form\",\n",
    "        \"wikibase-sense\"\n",
    "    }\n",
    "\n",
    "    return datatype in skip\n",
    "\n",
    "\n",
    "def get_value(obj, datatype):\n",
    "    temp = obj.get(\"mainsnak\", obj)\n",
    "    if datatype == \"globe-coordinate\":\n",
    "        latitude = temp[\"datavalue\"][\"value\"][\"latitude\"]\n",
    "        longitude = temp[\"datavalue\"][\"value\"][\"longitude\"]\n",
    "        value = f\"{latitude},{longitude}\"\n",
    "    else:\n",
    "        keys = {\n",
    "            \"quantity\": \"amount\",\n",
    "            \"monolingualtext\": \"text\",\n",
    "            \"time\": \"time\",\n",
    "        }\n",
    "        if datatype in keys:\n",
    "            key = keys[datatype]\n",
    "            value = temp[\"datavalue\"][\"value\"][key]\n",
    "        else:\n",
    "            value = temp[\"datavalue\"][\"value\"]\n",
    "    return value\n",
    "\n",
    "global initial_total_lines_estimate\n",
    "\n",
    "try:\n",
    "    organization_subclass = get_wikidata_item_tree_item_idsSPARQL([43229], backward_properties=[279])\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    country_subclass = get_wikidata_item_tree_item_idsSPARQL([6256], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    country_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    city_subclass = get_wikidata_item_tree_item_idsSPARQL([515], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    city_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    capitals_subclass = get_wikidata_item_tree_item_idsSPARQL([5119], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    capitals_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    admTerr_subclass = get_wikidata_item_tree_item_idsSPARQL([15916867], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    admTerr_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    family_subclass = get_wikidata_item_tree_item_idsSPARQL([17350442], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    family_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    sportLeague_subclass = get_wikidata_item_tree_item_idsSPARQL([623109], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    sportLeague_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    venue_subclass = get_wikidata_item_tree_item_idsSPARQL([8436], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    venue_subclass = set()\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    organization_subclass = list(set(organization_subclass) - set(country_subclass) - set(city_subclass) - set(capitals_subclass) - set(admTerr_subclass) - set(family_subclass) - set(sportLeague_subclass) - set(venue_subclass))\n",
    "    #print(len(organization_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    geolocation_subclass = get_wikidata_item_tree_item_idsSPARQL([2221906], backward_properties=[279])\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    food_subclass = get_wikidata_item_tree_item_idsSPARQL([2095], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    food_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    edInst_subclass = get_wikidata_item_tree_item_idsSPARQL([2385804], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    edInst_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    govAgency_subclass = get_wikidata_item_tree_item_idsSPARQL([327333], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    govAgency_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    intOrg_subclass = get_wikidata_item_tree_item_idsSPARQL([484652], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    intOrg_subclass = set()\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    timeZone_subclass = get_wikidata_item_tree_item_idsSPARQL([12143], backward_properties=[279])\n",
    "except json.decoder.JSONDecodeError:\n",
    "    timeZone_subclass = set()\n",
    "    pass\n",
    "   \n",
    "try:\n",
    "    geolocation_subclass = list(set(geolocation_subclass) - set(food_subclass) - set(edInst_subclass) - set(govAgency_subclass) - set(intOrg_subclass) - set(timeZone_subclass))\n",
    "    #print(len(geolocation_subclass))\n",
    "except json.decoder.JSONDecodeError:\n",
    "    pass\n",
    "\n",
    "with bz2.open(wikidata_dump_path, 'rt', encoding='utf-8') as f:\n",
    "    count = 1000\n",
    "    \n",
    "    ORG = []\n",
    "    PERS = []\n",
    "    LOC = []\n",
    "    OTHERS = []\n",
    "\n",
    "    pbar = tqdm(total=initial_total_lines_estimate)\n",
    "    for i, line in enumerate(f):\n",
    "        try:\n",
    "            # Parse JSON data from each line\n",
    "            item = json.loads(line[:-2])\n",
    "\n",
    "            entity = item['id']\n",
    "            labels = item.get(\"labels\", {})\n",
    "            english_label = labels.get(\"en\", {}).get(\"value\", \"\")\n",
    "            aliases = item.get(\"aliases\", {})\n",
    "            description = item.get('descriptions', {}).get('en', {})\n",
    "            category = \"entity\"\n",
    "            sitelinks = item.get(\"sitelinks\", {})\n",
    "            popularity = len(sitelinks) if len(sitelinks) > 0 else 1\n",
    "\n",
    "            \n",
    "            if entity in list(mapping.values()):\n",
    "                all_labels = {}\n",
    "                for lang in labels:\n",
    "                    all_labels[lang] = labels[lang][\"value\"]\n",
    "            \n",
    "                all_aliases = {}\n",
    "                for lang in aliases:\n",
    "                    all_aliases[lang] = []\n",
    "                    for alias in aliases[lang]:\n",
    "                        all_aliases[lang].append(alias[\"value\"])\n",
    "                    all_aliases[lang] = list(set(all_aliases[lang]))\n",
    "            \n",
    "                found = False\n",
    "                for predicate in item[\"claims\"]:\n",
    "                    if predicate == \"P279\":\n",
    "                        found = True\n",
    "            \n",
    "                if found:\n",
    "                    category = \"type\"\n",
    "                if entity[0] == \"P\":\n",
    "                    category = \"predicate\"\n",
    "        \n",
    "                line_size = len(line)\n",
    "                current_average_size = update_average_size(line_size)\n",
    "                pbar.total = round(compressed_file_size / current_average_size)\n",
    "                pbar.update(1)\n",
    "    \n",
    "                ###############################################################\n",
    "                # ORGANIZATION EXTRACTION\n",
    "                # All items with the root class Organization (Q43229) excluding country (Q6256), city (Q515), capitals (Q5119), \n",
    "                # administrative territorial entity of a single country (Q15916867), venue (Q17350442), sports league (Q623109) \n",
    "                # and family (Q8436)\n",
    "                \n",
    "                # LOCATION EXTRACTION\n",
    "                # All items with the root class Geographic Location (Q2221906) excluding: food (Q2095), educational institution (Q2385804), \n",
    "                # government agency (Q327333), international organization (Q484652) and time zone (Q12143)\n",
    "                \n",
    "                # PERSON EXTRACTION\n",
    "                # All items with the statement is instance of (P31) human (Q5) are classiﬁed as person.\n",
    "    \n",
    "                NERtype = None\n",
    "    \n",
    "                if item.get(\"type\") == \"item\" and \"claims\" in item:\n",
    "                    p31_claims = item[\"claims\"].get(\"P31\", [])\n",
    "                    \n",
    "                    if len(p31_claims) != 0:           \n",
    "                        for claim in p31_claims:\n",
    "                            mainsnak = claim.get(\"mainsnak\", {})\n",
    "                            datavalue = mainsnak.get(\"datavalue\", {})\n",
    "                            numeric_id = datavalue.get(\"value\", {}).get(\"numeric-id\")\n",
    "                            \n",
    "                            if numeric_id == 5:\n",
    "                                NERtype = \"PERS\" \n",
    "                            elif numeric_id in geolocation_subclass or any(k.lower() in description.get('value', '').lower() for k in [\"district\", \"city\", \"country\", \"capital\"]):\n",
    "                                NERtype = \"LOC\"\n",
    "                            elif numeric_id in organization_subclass:\n",
    "                                NERtype = \"ORG\"  \n",
    "                            else:\n",
    "                                NERtype = \"OTHERS\"\n",
    "                    else:\n",
    "                        NERtype = \"OTHERS\" \n",
    "                        \n",
    "                ################################################################   \n",
    "                ################################################################   \n",
    "                # URL EXTRACTION\n",
    "            \n",
    "                try:\n",
    "                    lang = labels.get(\"en\", {}).get(\"language\", \"\")\n",
    "                    tmp={}\n",
    "                    tmp[\"WD_id\"] = item['id']\n",
    "                    tmp[\"WP_id\"] = labels.get(\"en\", {}).get(\"value\", \"\")\n",
    "            \n",
    "                    url_dict={}\n",
    "                    url_dict[\"wikidata\"] = \"http://www.wikidata.org/wiki/\"+tmp[\"WD_id\"]\n",
    "                    url_dict[\"wikipedia\"] = \"http://\"+lang+\".wikipedia.org/wiki/\"+tmp[\"WP_id\"].replace(\" \",\"_\")\n",
    "                    url_dict[\"dbpedia\"] = \"http://dbpedia.org/resource/\"+tmp[\"WP_id\"].capitalize().replace(\" \",\"_\")\n",
    "                    \n",
    "            \n",
    "                except json.decoder.JSONDecodeError:\n",
    "                   pass\n",
    "                \n",
    "                ################################################################    \n",
    "        \n",
    "                objects = {}\n",
    "                literals = {datatype: {} for datatype in DATATYPES}\n",
    "                types = {\"P31\": []}\n",
    "                join = {\n",
    "                    \"items\": {\n",
    "                        \"id_entity\": i,\n",
    "                        \"entity\": entity,\n",
    "                        \"description\": description,\n",
    "                        \"labels\": all_labels,\n",
    "                        \"aliases\": all_aliases,\n",
    "                        \"types\": types,\n",
    "                        \"popularity\": popularity,\n",
    "                        \"kind\": category,   # kind (entity, type or predicate, disambiguation or category)\n",
    "                        ######################\n",
    "                        # new updates\n",
    "                        \"NERtype\": NERtype, # (ORG, LOC, PER or OTHERS)\n",
    "                        \"URLs\" : url_dict\n",
    "                        ######################\n",
    "                    },\n",
    "                    \"objects\": { \n",
    "                        \"id_entity\": i,\n",
    "                        \"entity\": entity,\n",
    "                        \"objects\":objects\n",
    "                    },\n",
    "                    \"literals\": { \n",
    "                        \"id_entity\": i,\n",
    "                        \"entity\": entity,\n",
    "                        \"literals\": literals\n",
    "                    },\n",
    "                    \"types\": { \n",
    "                        \"id_entity\": i,\n",
    "                        \"entity\": entity,\n",
    "                        \"types\": types\n",
    "                    },\n",
    "                }\n",
    "            \n",
    "                predicates = item[\"claims\"]\n",
    "                for predicate in predicates:\n",
    "                    for obj in predicates[predicate]:\n",
    "                        datatype = obj[\"mainsnak\"][\"datatype\"]\n",
    "            \n",
    "                        if check_skip(obj, datatype):\n",
    "                            continue\n",
    "            \n",
    "                        if datatype == \"wikibase-item\" or datatype == \"wikibase-property\":\n",
    "                            value = obj[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "            \n",
    "                            if predicate == \"P31\" or predicate == \"P106\":\n",
    "                                types[\"P31\"].append(value)\n",
    "            \n",
    "                            if value not in objects:\n",
    "                                objects[value] = []\n",
    "                            objects[value].append(predicate)    \n",
    "                        else:\n",
    "                            value = get_value(obj, datatype)                \n",
    "                            lit = literals[DATATYPES_MAPPINGS[datatype]]\n",
    "            \n",
    "                            if predicate not in lit:\n",
    "                                lit[predicate] = []\n",
    "                            lit[predicate].append(value)   \n",
    "            \n",
    "                 \n",
    "            \n",
    "                for key in buffer:\n",
    "                    buffer[key].append(join[key])            \n",
    "            \n",
    "                if len(buffer[\"items\"]) == BATCH_SIZE:\n",
    "                    flush_buffer(buffer)\n",
    "    \n",
    "        except json.decoder.JSONDecodeError:\n",
    "            continue\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a06f6-0932-4c54-9abc-714df8f1709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"./yago_wiki_classification.json\"\n",
    "\n",
    "data = {\n",
    "    \"ORG\": ORG,\n",
    "    \"LOC\": LOC,\n",
    "    \"PERS\": PERS,\n",
    "    \"OTHERS\": OTHERS\n",
    "}\n",
    "\n",
    "# Write the categorized data to a JSON file\n",
    "try:\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    print(f\"Data saved successfully to {json_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving data to JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6043e2-23dc-4a5d-8f49-9c8f6b598523",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = parser.parse_all_logs(log_dir=\"./\")\n",
    "first_log = logs[0]\n",
    "\n",
    "print(f\"Output file name: {first_log['output_filename']}\")\n",
    "print(f\"Standard file name: {first_log['standard_filename']}\")\n",
    "print(f\"Stopped early: {first_log['early_stop']}\")\n",
    "print(f\"Measured consumption: {first_log['actual']}\")\n",
    "print(f\"Predicted consumption: {first_log['pred']}\")\n",
    "print(f\"Measured GPU devices: {first_log['components']['gpu']['devices']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a850f-8f23-4096-9a22-e594d6ece098",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length_PERS = len(PERS)\n",
    "total_length_ORG = len(ORG)\n",
    "total_length_LOC = len(LOC)\n",
    "total_length_OTHERS = len(OTHERS)\n",
    "\n",
    "# Print the total lengths\n",
    "print(\"Total lengths:\")\n",
    "print(f\"Length of PERS: {total_length_PERS}\")\n",
    "print(f\"Length of ORG: {total_length_ORG}\")\n",
    "print(f\"Length of LOC: {total_length_LOC}\")\n",
    "print(f\"Length of OTHERS: {total_length_OTHERS}\")\n",
    "\n",
    "# Calculate the sum of lengths\n",
    "total_length = total_length_PERS + total_length_ORG + total_length_LOC + total_length_OTHERS\n",
    "\n",
    "# Print the sum of lengths\n",
    "print(f\"Total length: {total_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a9fd3-190e-43d4-93a6-acb0d79af0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in OTHERS:\n",
    "    if el in PERS:\n",
    "        print(f\"PERS and ORG --> Entity ID: {PERS.index(el)}\")\n",
    "    if el in LOC:\n",
    "        print(f\"LOC and ORG --> Entity ID: {LOC.index(el)}\")\n",
    "    if el in ORG:\n",
    "        print(f\"OTHERS and ORG --> Entity ID: {ORG.index(el)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1273d4-71d2-4e5d-9100-48ede8cc4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to sets for faster intersection operation\n",
    "ORG_set = set(ORG)\n",
    "PERS_set = set(PERS)\n",
    "LOC_set = set(LOC)\n",
    "OTHERS_set = set(OTHERS)\n",
    "\n",
    "# Initialize counters for each set\n",
    "ORG_counter = 0\n",
    "PERS_counter = 0\n",
    "LOC_counter = 0\n",
    "OTHERS_counter = 0\n",
    "\n",
    "# Find the overlapping items and update the counters\n",
    "for item in ORG_set.union(PERS_set, LOC_set, OTHERS_set):\n",
    "    num_overlaps = 0\n",
    "    if item in ORG_set:\n",
    "        print(\"item\")\n",
    "        num_overlaps += 1\n",
    "    if item in PERS_set:\n",
    "        num_overlaps += 1\n",
    "    if item in LOC_set:\n",
    "        num_overlaps += 1\n",
    "    if item in OTHERS_set:\n",
    "        num_overlaps += 1\n",
    "    \n",
    "    # Update the corresponding counter based on the number of overlaps\n",
    "    if num_overlaps == 1:\n",
    "        ORG_counter += 1\n",
    "    elif num_overlaps == 2:\n",
    "        PERS_counter += 1\n",
    "    elif num_overlaps == 3:\n",
    "        LOC_counter += 1\n",
    "    elif num_overlaps == 4:\n",
    "        OTHERS_counter += 1\n",
    "\n",
    "# Print the counts for each set\n",
    "print(\"Number of overlaps for each set:\")\n",
    "print(f\"ORG: {ORG_counter}\")\n",
    "print(f\"PERS: {PERS_counter}\")\n",
    "print(f\"LOC: {LOC_counter}\")\n",
    "print(f\"OTHERS: {OTHERS_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c9245",
   "metadata": {},
   "source": [
    "## URL Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4029e46-84a4-4177-a31b-e228d4149814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "# This Python file uses the following encoding: utf-8\n",
    "\n",
    "__author__ = 'jgeiss'\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# authors: Johanna Geiß, Heidelberg University, Germany                     #\n",
    "# email: geiss@informatik.uni-heidelberg.de                                 #\n",
    "# Copyright (c) 2017 Database Research Group,                               #\n",
    "#               Institute of Computer Science,                              #\n",
    "#               University of Heidelberg                                    #\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");         #\n",
    "#   you may not use this file except in compliance with the License.        #\n",
    "#   You may obtain a copy of the License at                                 #\n",
    "#                                                                           #\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0                              #\n",
    "#                                                                           #\n",
    "#   Unless required by applicable law or agreed to in writing, software     #\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,       #\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.#\n",
    "#   See the License for the specific language governing permissions and     #\n",
    "#   limitations under the License.                                          #\n",
    "#############################################################################\n",
    "# last updated 21.3.2017 by Johanna Geiß\n",
    "\n",
    "from pymongo import *\n",
    "from pymongo import errors\n",
    "import configparser\n",
    "\n",
    "\n",
    "\n",
    "wikidata_dump_path = './my-data/latest-all.json.bz2'\n",
    "\n",
    "with bz2.open(wikidata_dump_path, 'rt', encoding='utf-8') as f:\n",
    "    count = 0\n",
    "    \n",
    "             \n",
    "    for i, line in tqdm(enumerate(f), total=1000):\n",
    "        if count == 10000:\n",
    "            break\n",
    "        try:\n",
    "            count += 1\n",
    "            # Parse JSON data from each line\n",
    "            data = json.loads(line[:-2])\n",
    "         \n",
    "            labels = data.get(\"labels\", {})\n",
    "            lang = labels.get(\"en\", {}).get(\"language\", \"\")\n",
    "            entry={}\n",
    "            entry[\"WD_id\"] = data['id']\n",
    "            entry[\"WP_id\"] = labels.get(\"en\", {}).get(\"value\", \"\")\n",
    "\n",
    "            entry[\"WD_id_URL\"] = \"http://www.wikidata.org/wiki/\"+entry[\"WD_id\"]\n",
    "            entry[\"WP_id_URL\"] = \"http://\"+lang+\".wikipedia.org/wiki/\"+entry[\"WP_id\"].replace(\" \",\"_\")\n",
    "            entry[\"dbpedia_URL\"] = \"http://dbpedia.org/resource/\"+entry[\"WP_id\"].capitalize().replace(\" \",\"_\")\n",
    "            \n",
    "            print(\"------------------\")\n",
    "            print(entry[\"WD_id_URL\"])\n",
    "            print(entry[\"WP_id_URL\"])\n",
    "            print(entry[\"dbpedia_URL\"])\n",
    "            print(\"------------------\")\n",
    "    \n",
    "        except json.decoder.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4405d-3f61-4355-ac23-5e685e372807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from carbontracker import parser\n",
    "\n",
    "logs = parser.parse_all_logs(log_dir=\"./\")\n",
    "print(logs)\n",
    "first_log = logs[0]\n",
    "\n",
    "print(f\"Output file name: {first_log['output_filename']}\")\n",
    "print(f\"Standard file name: {first_log['standard_filename']}\")\n",
    "print(f\"Stopped early: {first_log['early_stop']}\")\n",
    "print(f\"Measured consumption: {first_log['actual']}\")\n",
    "print(f\"Predicted consumption: {first_log['pred']}\")\n",
    "print(f\"Measured GPU devices: {first_log['components']['gpu']['devices']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c39bc5-a679-46c2-8406-0726fc6737cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
